<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[自言自语]]></title>
  <link href="http://liubin.github.io/atom.xml" rel="self"/>
  <link href="http://liubin.github.io/"/>
  <updated>2016-07-20T00:26:00+08:00</updated>
  <id>http://liubin.github.io/</id>
  <author>
    <name><![CDATA[bin liu]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[2016年6月读书记录]]></title>
    <link href="http://liubin.github.io/blog/2016/07/09/06-reading/"/>
    <updated>2016-07-09T23:06:52+08:00</updated>
    <id>http://liubin.github.io/blog/2016/07/09/06-reading</id>
    <content type="html"><![CDATA[<p>度过5月低潮，6月的阅读时间又升上来了，本月基本上以微信读书为主。至于是什么原因呢？可能是因为一本书读起来就不想放下，一直读下去，直到读完。</p>

<p>6月一共阅读了6本，分别是《消费心理十四讲》、《袁腾飞讲先秦上古春秋》、《中国为什么有前途》、《白夜行》、《最神奇的经济学定律》和《国学讲演录》</p>

<h2>《白夜行》</h2>

<p><img src="https://img3.doubanio.com/lpic/s4610502.jpg" alt="白夜行" /></p>

<p>推荐指数：★★★★★</p>

<p>这可能是东野圭吾在国内最著名的小说之一了，也被翻拍成了影视作品。</p>

<p>作为侦探小说，情节还算不错。</p>

<p>我的感觉是，人生的长河，你总能找到同路人，相同的家庭环境，类似的遭遇或者不幸；不管是旋涡、阻挡，亦或是激流之后一湾浅滩的平静。每个人的人生都不同，但是总有重复相同经历的人。</p>

<h2>《袁腾飞讲先秦上古春秋》</h2>

<p><img src="https://img3.doubanio.com/lpic/s28013690.jpg" alt="袁腾飞讲先秦上古春秋" /></p>

<p>推荐指数：★★★★★</p>

<p>这是一本历史书，从人文之初、轩辕黄帝一直讲到了春秋晚期，包括三代夏商周的更迭，以及春秋时期各诸侯的争霸。
对于长久不学习历史的人来说，算是一个很好的补足，对已经遗忘的、在初中、高中所学历史的补足。我们的传统文化还是很悠久和博大精深的，我觉得无论年纪大小，都应该读一下。</p>

<p>龙的传人：</p>

<p>伏羲和女娲结婚时，女娲才16岁，比伏羲小15岁。伏羲龙身，女娲蛇身，因此后代被称为龙的传人。</p>

<p>炎黄子孙：</p>

<p>炎帝和黄帝同为华夏部落，所以我们也成为炎黄子孙。</p>

<h2>《中国为什么有前途》</h2>

<p><img src="https://img3.doubanio.com/lpic/s28562483.jpg" alt="中国为什么有前途" /></p>

<p>推荐指数：★★★★★</p>

<p>罗胖从政治、历史、经济和宗教等方面，针对各种消极、自卑和唱衰言论，东拉西扯、引经据典外加自己缜密的推断，论述了他眼中的中国为什么有前途。</p>

<p>尽管这一观点我不是很同意。</p>

<p>作为一个70年代出生，经历了30多年的改革开放，生活水平大幅提高，事业有成的罗胖，得出此结论并不奇怪，乐观派没什么不好，乐观派才能干成事。</p>

<p>然而现实实际是如何？近期的南海问题、韩国萨德、吃KFC成卖国贼等等，哪一个不是引起轩然大波，吸引力全社会各个阶层的关注甚至撕b？</p>

<p>我只是觉得，没朋友很孤独，尽管国家之间的友谊，更多时候是利害关系的外衣。</p>

<p>我们的朋友真的不多。</p>

<h2>《国学讲演录》</h2>

<p><img src="https://img3.doubanio.com/lpic/s28306721.jpg" alt="国学讲演录" /></p>

<p>推荐指数：★★★★★</p>

<p>本书作者是南怀瑾高足魏承思，是一本由讲稿整理而成的书，讨论了国学的概念、定义、范围，还对诸子百家学说进行了详细的介绍。包括儒、释、道，还有墨家和法家，以及魏晋、隋唐的佛学、宋明理学等。同时，也对四书五经、诸子学说与二十四史等经史子集进行了深入的说明，是对我们中学所学历史的丰富补充。</p>

<p>总之，对于像学习一下中国传统文化、国学的人来说，都可以说算的上一本非常好的入门，内容浅显易懂而又详实饱满，张杰组织和条理也都很清楚。</p>

<h2>《最神奇的经济学定律》</h2>

<p><img src="https://img3.doubanio.com/lpic/s6179345.jpg" alt="最神奇的经济学定律" /></p>

<p>推荐指数：★★★★☆</p>

<p>这不是晦涩难懂、偏重理论的一本关于经济学的书，而是结合了具体事例，分析了各种现象，并给出了各种适用场景和建议告诉我们在现实世界中，在哪里以及如何应用这些定律。</p>

<p>同时本书也引用了很多历史典故、有趣的事例等。</p>

<p>比如美国航天飞机火箭助推器的宽度，为什么是现在这个值么？答案就是：</p>

<blockquote><p>现代铁路两条铁轨之间的标准距离是4.85英尺。原来，早期的铁路是由建电车的人所设计的，而4．85英尺正是电车所用的轮距标准。那么，电车的标准又是从哪里来的呢？最先造电车的人以前是造马车的，所以电车的标准是沿用马车的轮距标准。马车又为什么要用这个轮距标准呢？英国马路辙迹的宽度是4．85英尺，所以，如果马车用其他轮距，它的轮子很快会在英国的老路上撞坏。这些辙迹又是从何而来的呢？从古罗马人那里来的。因为整个欧洲，包括英国的长途老路都是由罗马人为它的军队所铺设的，而4．85英尺正是罗马战车的宽度。任何其他轮宽的战车在这些路上行驶的话，轮子的寿命都不会很长。罗马人为什么以4．85英尺作为战车的轮距宽度呢？原因很简单，这是牵引一辆战车的两匹马屁股的宽度。故事到此还没有结束。美国航天飞机燃料箱的两旁有两个火箭推进器，因为这些推进器造好之后要用火车运送，路上又要通过一些隧道，而这些隧道的宽度只比火车轨道宽一点，因此火箭助推器的宽度是由铁轨的宽度所决定的。
所以，最后的结论是：路径依赖导致了美国航天飞机火箭助推器的宽度，竟然是两千年前便由两匹马屁股的宽度所决定。</p></blockquote>

<p>当然，本书不是讲故事，也还是介绍了很多经济学专门知识的，比如凯恩斯对宏观经济的看法、基尼系数等。</p>

<h2>《消费心理十四讲》</h2>

<p><img src="https://img1.doubanio.com/lpic/s27184788.jpg" alt="消费心理十四讲" /></p>

<p>推荐指数：★★★☆☆</p>

<p>本书主要讲的是如何让品牌深入人心，如何吸引顾客的注意力和兴趣、满足顾客、把商品卖给顾客。</p>

<p>书中介绍了购物时人的心理的各个阶段：</p>

<ul>
<li>1.注意目标</li>
<li>2.引起兴趣</li>
<li>3.产生购买欲望</li>
<li>4.信任</li>
<li>5.决定购买</li>
<li>6.满足</li>
</ul>


<p>围绕这几个阶段，作者在各个章节展开了详细的叙述，比如如何吸引用户的兴趣，如何取得用户的信任，如何影响用户做决定等等。</p>

<p>其中关于群体效应的章节中，作者介绍哦啊了潮流产生和发展的几个阶段和特征，我觉得挺有意思的：</p>

<ul>
<li>1.潮流开始时一定包含着某些创新元素，即以前没有过的。</li>
<li>2.潮流最开始兴起的原因是某些人为了表明自己与众不同。</li>
<li>3.潮流的下一个特征——模仿，其他人会模仿最初的尝试者。</li>
<li>4.模仿阶段之后，曾经拥有新装备的潮流发起个体，即最初的尝试者不再突出。</li>
</ul>


<p>具体的话可以找来这本书看看。</p>

<p>总之，这不是一本特别差的书。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[初试Docker swarm]]></title>
    <link href="http://liubin.github.io/blog/2016/06/21/try-new-docker-swarm/"/>
    <updated>2016-06-21T20:41:42+08:00</updated>
    <id>http://liubin.github.io/blog/2016/06/21/try-new-docker-swarm</id>
    <content type="html"><![CDATA[<p>DockerCon 2016今天凌晨开始了，Docker公司的CEO和CTO都做了慷慨激昂的演讲（其实是我瞎想象的，没听，只是看了一些别人整理的 highlight ）。</p>

<p>同时，1.12 RC2也出来了，很多 <a href="http://liubin.org/blog/2016/06/17/whats-new-in-docker-1-dot-12-dot-0/">新功能</a> 已经可以试用了， 这里我们就来试一下 <code>docker swarm</code> 命令吧，这也是 <code>swarm</code> 成为Docker子命令的第一个版本。</p>

<p>测试环境：</p>

<ul>
<li>OS：OS X</li>
<li>Docker：1.12.0-rc2</li>
<li>Docker Machine：0.8.0-rc1</li>
</ul>


<p>系统构成：</p>

<ul>
<li>master 1台</li>
<li>worker 2台</li>
</ul>


<h2>升级Docker</h2>

<p>使用Docker for Mac升级Docker很简单，这里不多说了；升级之后确认一下是最新版的Docker就可以了。</p>

<h2>创建3台Docker主机</h2>

<p>首先，使用Docker Machine创建3台主机，一台名为 <code>manager1</code> ，其余两台为 <code>worker1</code> 和 <code>worker2</code> ：</p>

<p>创建master节点：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker-machine create --driver virtualbox manager1</span></code></pre></td></tr></table></div></figure>


<p>创建2个worker节点：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker-machine create --driver virtualbox worker1
</span><span class='line'>$ docker-machine create --driver virtualbox worker2</span></code></pre></td></tr></table></div></figure>


<p>之后可以确认一下3台机器是否创建成功，以及ta们的IP地址：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker-machine ls
</span><span class='line'>NAME       ACTIVE   DRIVER       STATE     URL                         SWARM   DOCKER        ERRORS
</span><span class='line'>manager1   -        virtualbox   Running   tcp://192.168.99.100:2376           v1.12.0-rc2   
</span><span class='line'>worker1    -        virtualbox   Running   tcp://192.168.99.101:2376           v1.12.0-rc2   
</span><span class='line'>worker2    -        virtualbox   Running   tcp://192.168.99.102:2376           v1.12.0-rc2   
</span></code></pre></td></tr></table></div></figure>


<h2>创建Swarm集群</h2>

<p>首先，切换到 <code>manager1</code> 主机，使用 <code>docker swarm init</code> 命令创建一个集群：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ eval $(docker-machine env manager1)
</span><span class='line'>
</span><span class='line'>$ docker swarm init --listen-addr 192.168.99.100:2377
</span><span class='line'>Swarm initialized: current node (alq8w7fi34f41j3z4ise1vkd7) is now a manager.</span></code></pre></td></tr></table></div></figure>


<p>使用 <code>docker info</code> 确认一下当前节点信息，可以看到Swarm属性部分：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker info
</span><span class='line'>... ...
</span><span class='line'>Swarm: active
</span><span class='line'> NodeID: alq8w7fi34f41j3z4ise1vkd7
</span><span class='line'> IsManager: Yes
</span><span class='line'> Managers: 1
</span><span class='line'> Nodes: 1
</span><span class='line'> CACertHash: sha256:7a9d0eb1621afe2be07c5fd405b8f038c76be3a8dc7b2c73944a2d1ab9dffd76
</span><span class='line'>
</span><span class='line'>... ...</span></code></pre></td></tr></table></div></figure>


<p>在2台worker节点上，通过  <code>docker swarm join</code> 命令加入到刚才创建的集群中：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ eval $(docker-machine env worker1)
</span><span class='line'>$ docker swarm join 192.168.99.100:2377
</span><span class='line'>This node joined a Swarm as a worker.
</span><span class='line'>$ docker info
</span><span class='line'>... ...
</span><span class='line'>Swarm: active
</span><span class='line'> NodeID: 4l2a9ebgmcpwqlo0roye0n6m5
</span><span class='line'> IsManager: No
</span><span class='line'>... ...</span></code></pre></td></tr></table></div></figure>


<p>回到 <code>manager1</code> 节点，确认一下集群中节点的个数和状态。在 <code>MANAGER STATUS</code> 属性中，可以看到谁是Leader：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ eval $(docker-machine env manager1)
</span><span class='line'>$ docker node ls
</span><span class='line'>ID                           NAME      MEMBERSHIP  STATUS  AVAILABILITY  MANAGER STATUS
</span><span class='line'>4l2a9ebgmcpwqlo0roye0n6m5    worker1   Accepted    Ready   Active        
</span><span class='line'>alq8w7fi34f41j3z4ise1vkd7 *  manager1  Accepted    Ready   Active        Leader
</span><span class='line'>e0khh79c6owm0e14mli602q0a    worker2   Accepted    Ready   Active        </span></code></pre></td></tr></table></div></figure>


<h2>创建nginx服务</h2>

<p>首先，创建一个覆盖网络：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker network create -d overlay ngx_net
</span><span class='line'>8kiv8muduf60f66rs99ufo25f</span></code></pre></td></tr></table></div></figure>


<p>然后使用这个覆盖网络，创建nginx服务：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker service create --name nginx --replicas 1 --network ngx_net -p 80:80/tcp nginx
</span><span class='line'>78cmmh8ef4qcwmjjzgn3k45ch</span></code></pre></td></tr></table></div></figure>


<p>这样，就创建了一个具有一个副本（ <code>--replicas 1</code> ）的 <code>nginx</code> 服务，使用镜像 <code>nginx</code> 。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker service tasks nginx
</span><span class='line'>ID                         NAME     SERVICE  IMAGE  LAST STATE           DESIRED STATE  NODE
</span><span class='line'>394by1b72i44a44jms2xwk6ud  nginx.1  nginx    nginx  Preparing 9 seconds  Running        manager1</span></code></pre></td></tr></table></div></figure>


<p>注意上面的 <code>STATE</code> 字段中刚开始的服务状态为 <code>Preparing</code>，需要等一会才能变为 <code>Running</code> 状态，其中最费时间的应该是下载镜像的过程。</p>

<p>过一会再查看服务状态，就可以看到状态已经变为 <code>Running</code> 了，这是可以通过 <code>http://192.168.99.100/</code> 查看 Nginx服务。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker service tasks nginx
</span><span class='line'>ID                         NAME     SERVICE  IMAGE  LAST STATE              DESIRED STATE  NODE
</span><span class='line'>394by1b72i44a44jms2xwk6ud  nginx.1  nginx    nginx  Running About a minute  Running        manager1
</span><span class='line'>
</span><span class='line'># 通过curl查看服务是否正常运行
</span><span class='line'>$ curl http://192.168.99.100/
</span><span class='line'>...
</span></code></pre></td></tr></table></div></figure>


<h2>对服务进行扩展（scale）</h2>

<p>当然，如果只是通过service启动容器，swarm也算不上什么新鲜东西了。Service还提供了复制（类似k8s里的副本）功能。可以通过 <code>docker service scale</code> 命令来设置服务中容器的副本数：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker service scale nginx=5
</span><span class='line'>nginx scaled to 5</span></code></pre></td></tr></table></div></figure>


<p>和创建服务一样，增加scale数之后，将会创建新的容器，这些新启动的容器也会经历从准备到运行的过程，过一分钟左右，服务应该就会启动完成，这时候可以再来看一下 <code>nginx</code> 服务中的容器（task）：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker service tasks nginx
</span><span class='line'>ID                         NAME     SERVICE  IMAGE  LAST STATE         DESIRED STATE  NODE
</span><span class='line'>394by1b72i44a44jms2xwk6ud  nginx.1  nginx    nginx  Running 5 minutes  Running        manager1
</span><span class='line'>co0re9u7infoo9qiegm6yiqcn  nginx.2  nginx    nginx  Running 2 minutes  Running        worker1
</span><span class='line'>19dvayah8fjz3vykrl2oi12uu  nginx.3  nginx    nginx  Running 2 minutes  Running        worker1
</span><span class='line'>d8okdip767972p083tix4dk7d  nginx.4  nginx    nginx  Running 2 minutes  Running        manager1
</span><span class='line'>9rq59mf6bq5m411y6gdzb5pq6  nginx.5  nginx    nginx  Running 2 minutes  Running        worker2</span></code></pre></td></tr></table></div></figure>


<p>可以看到，之前 <code>nginx</code> 容器只在 <code>manager1</code> 上有一个实例，而现在又增加了4个实例。</p>

<p>我们可以在 <code>manager1</code> 上查看一下这台主机上运行的容器：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker ps
</span><span class='line'>CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES
</span><span class='line'>4bbc02bc426e        nginx:latest        "nginx -g 'daemon off"   4 minutes ago       Up 4 minutes        80/tcp, 443/tcp     nginx.4.d8okdip767972p083tix4dk7d
</span><span class='line'>1eda6f7d3029        nginx:latest        "nginx -g 'daemon off"   5 minutes ago       Up 5 minutes        80/tcp, 443/tcp     nginx.1.394by1b72i44a44jms2xwk6ud</span></code></pre></td></tr></table></div></figure>


<h2>容器异常停止时的处理</h2>

<p>如果一个服务中的一个任务突然终止了，Docker会怎么处理？这里我们就来模拟某一容器异常终止的情况。</p>

<p>在操作之前，我们在另一个窗口，准备好使用 <code>tail -f /var/log/docker.log</code> 命令来查看Docker守护进程的日志。</p>

<p>我们通过 <code>docker rm -f</code> 来删除一个容器（<code>4b</code> 表示的是我们第一个启动的 <code>4bbc02bc426e</code> 容器）：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker rm -f 4b
</span><span class='line'>4b
</span></code></pre></td></tr></table></div></figure>


<p>回到Docker守护进程的日志查看窗口，我们会看到类似这样的日志（有删减），从日志中，我们可以看到旧容器（id为 <code>4bbc02bc426e</code> ，task id为 <code>d8okdip767972p083tix4dk7d</code>）的删除和新容器（task id为 <code>cumjdktbadaxca66rt4hi63na</code>）的调度过程（删除了日志中的时间戳和日志级别等非重要信息，但保留了日志的时间顺序）：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 调用删除容器的API
</span><span class='line'>msg="Calling DELETE /v1.24/containers/4b?force=1" 
</span><span class='line'>
</span><span class='line'># d8的任务从RUNNING变为了FAILED状态
</span><span class='line'>msg="state changed" module=taskmanager state.desired=RUNNING state.transition="RUNNING-&gt;FAILED" task.id=d8okdip767972p083tix4dk7d 
</span><span class='line'>
</span><span class='line'># 将旧任务停止
</span><span class='line'>msg=assigned module=agent task.desiredstate=SHUTDOWN task.id=d8okdip767972p083tix4dk7d 
</span><span class='line'>
</span><span class='line'># 分配到新的节点，创建新的任务id： cumj
</span><span class='line'>msg="Assigning to node e0khh79c6owm0e14mli602q0a" task.id=cumjdktbadaxca66rt4hi63na 
</span><span class='line'>
</span><span class='line'># 旧任务状态更新为FAILED
</span><span class='line'>msg="(*Agent).UpdateTaskStatus" module=agent task.id=d8okdip767972p083tix4dk7d 
</span><span class='line'>msg="task status updated" method="(*Dispatcher).processTaskUpdates" module=dispatcher state.transition="FAILED-&gt;FAILED" task.id=d8okdip767972p083tix4dk7d 
</span><span class='line'>
</span><span class='line'># 新任务从ASSIGNED变为接受状态
</span><span class='line'>msg="task status updated" method="(*Dispatcher).processTaskUpdates" module=dispatcher state.transition="ASSIGNED-&gt;ACCEPTED" task.id=cumjdktbadaxca66rt4hi63na 
</span><span class='line'>
</span><span class='line'># 准备运行新任务
</span><span class='line'>msg="task status updated" method="(*Dispatcher).processTaskUpdates" module=dispatcher state.transition="ACCEPTED-&gt;PREPARING" task.id=cumjdktbadaxca66rt4hi63na 
</span><span class='line'>
</span><span class='line'># 运行新任务
</span><span class='line'>msg="task status updated" method="(*Dispatcher).processTaskUpdates" module=dispatcher state.transition="PREPARING-&gt;STARTING" task.id=cumjdktbadaxca66rt4hi63na 
</span><span class='line'>
</span><span class='line'># 新任务启动完成
</span><span class='line'>msg="task status updated" method="(*Dispatcher).processTaskUpdates" module=dispatcher state.transition="STARTING-&gt;RUNNING" task.id=cumjdktbadaxca66rt4hi63na 
</span></code></pre></td></tr></table></div></figure>


<p>从上面的日志我们不难看出，一个任务的生命周期的前半生，大概就是 <code>ASSIGNED</code> -> <code>ACCEPTED</code> -> <code>PREPARING</code> -> <code>STARTING</code> -> <code>RUNNING</code> 。</p>

<p>在 <code>manager1</code>主机上，我们看到这个容器已经删除了， <code>ps</code> 只能看到一个容器：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker ps
</span><span class='line'>CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES
</span><span class='line'>1eda6f7d3029        nginx:latest        "nginx -g 'daemon off"   6 minutes ago       Up 6 minutes        80/tcp, 443/tcp     nginx.1.394by1b72i44a44jms2xwk6ud</span></code></pre></td></tr></table></div></figure>


<p>再来查看一下 <code>nginx</code> 服务的任务列表，可以看到新创建的任务 <code>cumjdktbadaxca66rt4hi63na</code> 被调度到了 <code>worker2</code> 上运行：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker service tasks nginx
</span><span class='line'>ID                         NAME     SERVICE  IMAGE  LAST STATE          DESIRED STATE  NODE
</span><span class='line'>394by1b72i44a44jms2xwk6ud  nginx.1  nginx    nginx  Running 8 minutes   Running        manager1
</span><span class='line'>co0re9u7infoo9qiegm6yiqcn  nginx.2  nginx    nginx  Running 5 minutes   Running        worker1
</span><span class='line'>19dvayah8fjz3vykrl2oi12uu  nginx.3  nginx    nginx  Running 5 minutes   Running        worker1
</span><span class='line'>cumjdktbadaxca66rt4hi63na  nginx.4  nginx    nginx  Running 32 seconds  Running        worker2
</span><span class='line'>9rq59mf6bq5m411y6gdzb5pq6  nginx.5  nginx    nginx  Running 5 minutes   Running        worker2</span></code></pre></td></tr></table></div></figure>


<h2>删除一个节点？</h2>

<p>不难想象，如果一个节点都宕机了，则Docker应该会将在该节点运行的容器，调度到其他节点，以满足指定数量的副本保持运行状态。</p>

<p>下面我们就来模拟一下这种场景。</p>

<p>首先，我们删除一个节点 <code>worker2</code>：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker-machine rm worker2
</span><span class='line'>About to remove worker2
</span><span class='line'>Are you sure? (y/n): y
</span><span class='line'>Successfully removed worker2</span></code></pre></td></tr></table></div></figure>


<p>删除之后，Docker就会开始重新调度，最终调度结束（&lt; 1分钟）后，再查看该服务的任务状态，应该如下面这样，有5个 <code>nginx</code> 容器在剩下的两台机器上运行：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker service tasks nginx
</span><span class='line'>ID                         NAME     SERVICE  IMAGE  LAST STATE          DESIRED STATE  NODE
</span><span class='line'>394by1b72i44a44jms2xwk6ud  nginx.1  nginx    nginx  Running 22 minutes  Running        manager1
</span><span class='line'>co0re9u7infoo9qiegm6yiqcn  nginx.2  nginx    nginx  Running 19 minutes  Running        worker1
</span><span class='line'>19dvayah8fjz3vykrl2oi12uu  nginx.3  nginx    nginx  Running 19 minutes  Running        worker1
</span><span class='line'>991v97eg9q1hnnzxda6c9mmv7  nginx.4  nginx    nginx  Running 20 seconds  Running        manager1
</span><span class='line'>e9yztfmy5luaxnadz80e5j8nl  nginx.5  nginx    nginx  Running 20 seconds  Running        manager1</span></code></pre></td></tr></table></div></figure>


<p>除了上面用到的一些命令， <code>docker service</code> 还有以下一些子命令：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker service --help
</span><span class='line'>
</span><span class='line'>Usage:    docker service COMMAND
</span><span class='line'>
</span><span class='line'>Manage Docker services
</span><span class='line'>
</span><span class='line'>Options:
</span><span class='line'>      --help   Print usage
</span><span class='line'>
</span><span class='line'>Commands:
</span><span class='line'>  create      Create a new service
</span><span class='line'>  inspect     Inspect a service
</span><span class='line'>  tasks       List the tasks of a service
</span><span class='line'>  ls          List services
</span><span class='line'>  rm          Remove a service
</span><span class='line'>  scale       Scale one or multiple services
</span><span class='line'>  update      Update a service
</span><span class='line'>
</span><span class='line'>Run 'docker service COMMAND --help' for more information on a command.</span></code></pre></td></tr></table></div></figure>


<p>比如我们可以用 <code>docker service inspect</code> 来获得 <code>nginx</code> 服务的详情信息：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker service inspect nginx
</span><span class='line'>[
</span><span class='line'>    {
</span><span class='line'>        "ID": "78cmmh8ef4qcwmjjzgn3k45ch",
</span><span class='line'>        "Version": {
</span><span class='line'>            "Index": 32
</span><span class='line'>        },
</span><span class='line'>        "CreatedAt": "2016-06-21T08:31:21.427244594Z",
</span><span class='line'>        "UpdatedAt": "2016-06-21T08:33:50.75625288Z",
</span><span class='line'>        "Spec": {
</span><span class='line'>            "Name": "nginx",
</span><span class='line'>            "TaskTemplate": {
</span><span class='line'>                "ContainerSpec": {
</span><span class='line'>                    "Image": "nginx"
</span><span class='line'>                },
</span><span class='line'>                "Resources": {
</span><span class='line'>                    "Limits": {},
</span><span class='line'>                    "Reservations": {}
</span><span class='line'>                },
</span><span class='line'>                "RestartPolicy": {
</span><span class='line'>                    "Condition": "any",
</span><span class='line'>                    "MaxAttempts": 0
</span><span class='line'>                },
</span><span class='line'>                "Placement": {}
</span><span class='line'>            },
</span><span class='line'>            "Mode": {
</span><span class='line'>                "Replicated": {
</span><span class='line'>                    "Replicas": 5
</span><span class='line'>                }
</span><span class='line'>            },
</span><span class='line'>            "UpdateConfig": {},
</span><span class='line'>            "Networks": [
</span><span class='line'>                {
</span><span class='line'>                    "Target": "8kiv8muduf60f66rs99ufo25f"
</span><span class='line'>                }
</span><span class='line'>            ],
</span><span class='line'>            "EndpointSpec": {
</span><span class='line'>                "Mode": "vip",
</span><span class='line'>                "Ports": [
</span><span class='line'>                    {
</span><span class='line'>                        "Protocol": "tcp",
</span><span class='line'>                        "TargetPort": 80,
</span><span class='line'>                        "PublishedPort": 80
</span><span class='line'>                    }
</span><span class='line'>                ]
</span><span class='line'>            }
</span><span class='line'>        },
</span><span class='line'>        "Endpoint": {
</span><span class='line'>            "Spec": {},
</span><span class='line'>            "Ports": [
</span><span class='line'>                {
</span><span class='line'>                    "Protocol": "tcp",
</span><span class='line'>                    "TargetPort": 80,
</span><span class='line'>                    "PublishedPort": 80
</span><span class='line'>                }
</span><span class='line'>            ],
</span><span class='line'>            "VirtualIPs": [
</span><span class='line'>                {
</span><span class='line'>                    "NetworkID": "e9et32s47olva4e0uisamdqao",
</span><span class='line'>                    "Addr": "10.255.0.6/16"
</span><span class='line'>                },
</span><span class='line'>                {
</span><span class='line'>                    "NetworkID": "8kiv8muduf60f66rs99ufo25f",
</span><span class='line'>                    "Addr": "10.0.0.2/24"
</span><span class='line'>                }
</span><span class='line'>            ]
</span><span class='line'>        }
</span><span class='line'>    }
</span><span class='line'>]</span></code></pre></td></tr></table></div></figure>


<p>也可以通过 <code>docker service rm nginx</code> 命令，删除 <code>nginx</code> 服务（现在的版本删除服务前没有警告提示，请小心操作）。</p>

<h2>总结</h2>

<p>上手很简单，Docker swarm可以非常方便的创建类似k8s那样带有副本的服务，确保一定数量的容器运行，保证服务的高可用。</p>

<p>然而，光从官方文档来说，功能似乎又有些简单，从生产环境来说，下面这些方面都还有所欠缺（其实从Swarm v1就有这个问题）：</p>

<ul>
<li>没有配置文件，不好进行版本化管理，不方便部署</li>
<li>持久存储的缺失。Docker已经支持Volume Driver，k8s等也有存储卷插件在机制，真正的生产环境没有Volume支持估计是很难想象的。</li>
<li>是否能确保本身的高可用</li>
<li>调度策略还处于初级阶段</li>
</ul>


<p>不过，正如Docker让容器技术变得平民化一样，Docker Machine和Swarm，也将在各种基础设施上运行Docker和Docker集群变得更加简单，从这一点上来说，其意义也是很大的。</p>

<p>不过在开源社区和商业竞争的角度来看，Docker Swarm将会走向何方呢？</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[2016年5月读书记录]]></title>
    <link href="http://liubin.github.io/blog/2016/06/18/05-reading/"/>
    <updated>2016-06-18T19:07:29+08:00</updated>
    <id>http://liubin.github.io/blog/2016/06/18/05-reading</id>
    <content type="html"><![CDATA[<p>5月读完的，大概只有一本。</p>

<h2>《途客圈创业记：不疯魔，不成活》</h2>

<p><img src="https://img1.doubanio.com/lpic/s28482679.jpg" alt="途客圈创业记：不疯魔，不成活" /></p>

<p>推荐指数：★★★★★</p>

<p>和作者陈天有过一面之缘，还是在几年前国内第一次Docker Meetup，有幸和陈天同台分享了一下Docker方面的内容，我的偏向于原理介绍，他的更偏实战，很像他的风格。</p>

<p>这本书讲述了陈天自己从兴趣开始，如何自己写原型，参加demo day类似的活动，找合伙人、组建团队，找投资，做产品，涉及到了一个创意从想出点子，到实现、上线的过程。</p>

<p>如果你是初出道的创业者，刚只是有一些点子和想法而已，那么这本书绝对值得参考，前人的经验，能帮你避免犯一些没有必要的错误。</p>

<p>我个人有一些感触，这里列出几点简单介绍一下。</p>

<h3>管理团队</h3>

<p>管理团队很重要，以至于很多投资人的理念其实是投人、投团队，也就是人靠谱，给你钱干什么都行。</p>

<p>这方面主要问题是管理团队的构成、分工以及定位。在能力上最好是互补的，比如市场、销售、技术活产品等。</p>

<p>而定位很重要，本书作者的一大经验就是陈天作为创始人、大股东、产品负责人是事实上的核心，而CEO则有些被边缘化。所以说，每个人的定位要明确，一个萝卜一个坑，有什么事都能找到唯一一个、明确的负责人，员工有事了，知道什么事该找什么人。</p>

<p>一个公司如果对高层的分工都不明确，可以说是CEO没有从大局上来让公司员工能有一个统一的认识，没有明确的的定义出管理团队的架构。</p>

<p>项目也是，最烦一件事不知道找谁，每个人都想支一嘴。</p>

<h3>控制产品</h3>

<p>如果说99%的创业都会失败，我觉得其中90%的原因都是其产品并非“刚需”。你的刚需不一定是别人的刚需，产品还需要吃场和运营的验证。</p>

<p>这时候，又有一个词叫Pivot，愿意有“关键转折”或者“战略调整”的意思，在精益创业中一般指根据公司、产品的运营现状（尤其是运行出现问题或者出现重大机会，多指前者）时，改变公司的产品形式和方向、营销策略、公司战略等。</p>

<p>最简单的方法就是产品出来之后，根据用户和媒体的反响，以及各种运营数据来判断是否能达到预期，如果持续数据不太乐观，就必须要考虑产品的问题了。</p>

<p>第一版就抓到用户刚需，成为装机必备的软件，几率太低，多出产品都是通过不停的发布、反馈和调整来不断进行优化的。</p>

<p>在对产品进行调整时，即依赖于团队的能力、经验，坏的情况下，可能还会导致团队分歧、影响战斗力。</p>

<h3>控制节奏</h3>

<p>节奏包括产品的节奏，公司发展的规模等。不能太慢，互联网不是讲唯快不破么；也不能过快，繁华背后都会有隐忧，过快的发展可能会使危机不断地积蓄和发酵，大规模爆发时说不定会超出处理能力。</p>

<p>要有张有弛，控制节奏。就像跑马拉松，首先要上路，不能上来就找不到方向；其次要坚持，创业不是短跑，用尽全力会倒在强弩之末。</p>

<p>不过遗憾的是，途客圈没有完成下一轮融资，不得不被合并了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Docker 1.12.0将要发布的新功能]]></title>
    <link href="http://liubin.github.io/blog/2016/06/17/whats-new-in-docker-1-dot-12-dot-0/"/>
    <updated>2016-06-17T18:27:03+08:00</updated>
    <id>http://liubin.github.io/blog/2016/06/17/whats-new-in-docker-1-dot-12-dot-0</id>
    <content type="html"><![CDATA[<p>按计划，6/14 是1.12.0版本的 <a href="https://github.com/docker/docker/wiki">feature冻结</a> 的日子，再有两个星期Docker 1.12.0也该发布了。这里列出来的新功能，都是已经合并到主分支的功能，不出意外，下一个版本的Docker应该是能体验到了。</p>

<p>下周2016 DockerCon也该开始了，好像也有一场专门来讲Docker新特性的，不过在这之前，我们就可以抢先一步，浏览一下这些新功能、新特性。尤其是前两个，都是比较吸引人的功能。</p>

<h2>Swarmkit集成</h2>

<p>前几天Docker刚刚发布了 <a href="https://github.com/docker/swarmkit">Swarmkit</a> ，也就是Swarm V2。</p>

<p>同时，在这个版本的Docker中，Swarm/Swarmkit 相关命令也被整合到了Docker子命令中。这可能算得上是1.12.0版本中最大的变更点了。</p>

<p><a href="https://github.com/docker/docker/pull/23361">这个PR（Add dependency to docker/swarmkit）</a> 有600个文件变动。
除了传统的image和container对象，这个PR增加了task和service等资源类型。</p>

<p>相关几个子PR包括 <a href="https://github.com/docker/docker/pull/23362">23362</a> 、<a href="https://github.com/docker/docker/pull/23363">23363</a> 、 <a href="https://github.com/docker/docker/pull/23364">23364</a>。</p>

<p>使用新的Docker命令，可以这样直接创建Swarm集群：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker swarm init --listen-addr 192.168.99.100:2377
</span><span class='line'>Swarm initialized: current node (09fm6su6c24qn) is now a manager.</span></code></pre></td></tr></table></div></figure>


<p>查看节点：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker node ls
</span><span class='line'>ID              NAME      MEMBERSHIP  STATUS  AVAILABILITY  MANAGER STATUS  LEADER
</span><span class='line'>09fm6su6c24q *  manager1  Accepted    Ready   Active        Reachable       Yes</span></code></pre></td></tr></table></div></figure>


<p>然后这样来部署一个新的service：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker service create --scale 1 --name helloworld alpine ping docker.com
</span><span class='line'>2zs4helqu64f3k3iuwywbk49w
</span><span class='line'>
</span><span class='line'>$ docker service ls
</span><span class='line'>ID            NAME        SCALE  IMAGE   COMMAND
</span><span class='line'>2zs4helqu64f  helloworld  1      alpine  ping docker.com</span></code></pre></td></tr></table></div></figure>


<p>需要scale了？没关系，也可以在Docker中直接完成：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker service update --scale 5 helloworld
</span><span class='line'>helloworld
</span><span class='line'>
</span><span class='line'>$ docker service tasks helloworld
</span><span class='line'>ID                         NAME          SERVICE     IMAGE   DESIRED STATE  LAST STATE          NODE
</span><span class='line'>1n6wif51j0w840udalgw6hphg  helloworld.1  helloworld  alpine  RUNNING        RUNNING 2 minutes   manager1
</span><span class='line'>dfhsosk00wxfb7j0cazp3fmhy  helloworld.2  helloworld  alpine  RUNNING        RUNNING 15 seconds  worker2
</span><span class='line'>6cbedbeywo076zn54fnwc667a  helloworld.3  helloworld  alpine  RUNNING        RUNNING 15 seconds  worker1
</span><span class='line'>7w80cafrry7asls96lm2tmwkz  helloworld.4  helloworld  alpine  RUNNING        RUNNING 10 seconds  worker1
</span><span class='line'>bn67kh76crn6du22ve2enqg5j  helloworld.5  helloworld  alpine  RUNNING        RUNNING 10 seconds  manager1</span></code></pre></td></tr></table></div></figure>


<p>在一台机器上使用 <code>docker ps</code> :</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker ps
</span><span class='line'>
</span><span class='line'>CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
</span><span class='line'>910669d5e188        alpine:latest       "ping docker.com"   10 seconds ago      Up 10 seconds                           helloworld.5.bn67kh76crn6du22ve2enqg5j
</span><span class='line'>a0b6c02868ca        alpine:latest       "ping docker.com"   2 minutes  ago      Up 2 minutes                            helloworld.1.1n6wif51j0w840udalgw6hphg
</span></code></pre></td></tr></table></div></figure>


<p>我们也可以这样使用 <code>dcoekr service</code> 子命令。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker service create --scale 3 --name redis --update-delay 10s --update-parallelism 1 redis:3.0.6
</span><span class='line'>
</span><span class='line'>69uh57k8o03jtqj9uvmteodbb
</span><span class='line'>$ docker service tasks redis
</span><span class='line'>ID                         NAME     SERVICE  IMAGE        LAST STATE          DESIRED STATE  NODE
</span><span class='line'>3wfqsgxecktpwoyj2zjcrcn4r  redis.1  redis    redis:3.0.6  RUNNING 13 minutes  RUNNING        worker2
</span><span class='line'>8lcm041z3v80w0gdkczbot0gg  redis.2  redis    redis:3.0.6  RUNNING 13 minutes  RUNNING        worker1
</span><span class='line'>d48skceeph9lkz4nbttig1z4a  redis.3  redis    redis:3.0.6  RUNNING 12 minutes  RUNNING        manager1</span></code></pre></td></tr></table></div></figure>


<p>总之，新的Docker和Swarm结合在一起，管理集群和服务将会更方便。</p>

<h2>插件管理（Plugin repository，experimental版）</h2>

<p>PR地址： <a href="https://github.com/docker/docker/pull/23446">https://github.com/docker/docker/pull/23446</a></p>

<p>插件管理功能可能算是第二大变更点了。很多软件都支持插件机制，大家比较熟悉的从Wordpress到ElasticSearch等，都支持在软件内部通过plugin功能安装、管理插件。</p>

<p>Docker最近也增加了一些网络和卷管理的插件功能，这次还在体验版中增加了插件（基于容器）管理功能，可以通过 <code>docker plugin</code> 命令来管理插件。除了提供了一个统一的插件管理入口，还可以对插件的生命周期进行更好的管理，Docker君，我的插件写的比较不专业，请罩着我点。</p>

<p>这是一个大概的使用示意，通过 <code>docker plugin install</code> 可以安装插件， <code>docker plugin ls</code> 可以列出当前安装的插件：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker plugin install aragunathan/no-remove
</span><span class='line'>Plugin "aragunathan/no-remove:latest" requested the following privileges:
</span><span class='line'> - Networking: host
</span><span class='line'> - Mounting host path: /data
</span><span class='line'>Do you grant the above permissions? [y/N] y</span></code></pre></td></tr></table></div></figure>


<p>查看插件列表：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker plugin ls
</span><span class='line'>NAME                    VERSION             ACTIVE
</span><span class='line'>aragunathan/no-remove   latest              true</span></code></pre></td></tr></table></div></figure>


<p>目前 <code>docker plugin</code> 支持如下子命令：</p>

<ul>
<li>plugin ls</li>
<li>plugin enable</li>
<li>plugin inspect</li>
<li>plugin install</li>
<li>plugin rm</li>
</ul>


<h2>增加 <code>overlay2</code> 存储驱动（PR#22126 Overlay multiple lower directory support）</h2>

<p><a href="https://github.com/docker/docker/pull/22126">这个PR</a> 增加一个新的名为 <code>overlay2</code> 的驱动，以解决Docker在存储优化方面的不足，充分利用4.0内核的 <code>lower directories</code> 新特性，解决inode耗尽等问题。</p>

<p>这个PR中的描述也提到了新旧overlay驱动的性能对比数据，有兴趣的可以参考一下。</p>

<h2>Live restore</h2>

<p><a href="https://github.com/docker/docker/pull/23213">这个PR</a> 最大的好处就是提供了对daemonless容器的支持，即使daemon宕了，容器也不会受影响。</p>

<p>使用方法就是在启动 <code>dockerd</code> 的时候，增加 <code>--live-restore</code> 标志。</p>

<p>你是不是特别喜欢这个功能？</p>

<h2>Healthcheck</h2>

<p><code>docker run</code> 和 <code>Dockerfile</code> 新增加的 <a href="https://github.com/docker/docker/pull/23218">健康检查功能</a>。</p>

<p>比如在 <code>docker run</code> 中，可以这样：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker run --name=test -d \
</span><span class='line'>    --health-cmd='stat /etc/passwd || exit 1' \
</span><span class='line'>    --health-interval=2s \
</span><span class='line'>    busybox sleep 1d</span></code></pre></td></tr></table></div></figure>


<p>查看健康状态，返回 <code>healthy</code>：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ sleep 2; docker inspect --format='' test
</span><span class='line'>healthy</span></code></pre></td></tr></table></div></figure>


<p>故意删除 <code>/etc/passwd</code> 文件：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker exec test rm /etc/passwd</span></code></pre></td></tr></table></div></figure>


<p>再次查看节点健康状态：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ sleep 2; docker inspect --format='' test
</span><span class='line'>{
</span><span class='line'>  "Status": "unhealthy",
</span><span class='line'>  "FailingStreak": 3,
</span><span class='line'>  "Log": [
</span><span class='line'>    {
</span><span class='line'>      "Start": "2016-05-25T17:22:04.635478668Z",
</span><span class='line'>      "End": "2016-05-25T17:22:04.7272552Z",
</span><span class='line'>      "ExitCode": 0,
</span><span class='line'>      "Output": "  File: /etc/passwd\n  Size: 334       \tBlocks: 8          IO Block: 4096   regular file\nDevice: 32h/50d\tInode: 12          Links: 1\nAccess: (0664/-rw-rw-r--)  Uid: (    0/    root)   Gid: (    0/    root)\nAccess: 2015-12-05 22:05:32.000000000\nModify: 2015..."
</span><span class='line'>    },
</span><span class='line'>    {
</span><span class='line'>      "Start": "2016-05-25T17:22:06.732900633Z",
</span><span class='line'>      "End": "2016-05-25T17:22:06.822168935Z",
</span><span class='line'>      "ExitCode": 0,
</span><span class='line'>      "Output": "  File: /etc/passwd\n  Size: 334       \tBlocks: 8          IO Block: 4096   regular file\nDevice: 32h/50d\tInode: 12          Links: 1\nAccess: (0664/-rw-rw-r--)  Uid: (    0/    root)   Gid: (    0/    root)\nAccess: 2015-12-05 22:05:32.000000000\nModify: 2015..."
</span><span class='line'>    },
</span><span class='line'>    {
</span><span class='line'>      "Start": "2016-05-25T17:22:08.823956535Z",
</span><span class='line'>      "End": "2016-05-25T17:22:08.897359124Z",
</span><span class='line'>      "ExitCode": 1,
</span><span class='line'>      "Output": "stat: can't stat '/etc/passwd': No such file or directory\n"
</span><span class='line'>    }
</span><span class='line'>  ]
</span><span class='line'>}
</span></code></pre></td></tr></table></div></figure>


<h2>其他改进</h2>

<p>除了上述能单独拿出来的，要么比较重量级，要么非常实用的功能，Docker还有很多其他方面的改进。这里我们简单看看其中的一些。</p>

<h3><code>dockerd</code> 和 <code>docker</code> 二进制文件分离</h3>

<p><code>docker daemon</code> 改为了 <code>dockerd</code> ，这样以后就需要使用两个可执行程序了。</p>

<p>PR： <a href="https://github.com/docker/docker/pull/22386">https://github.com/docker/docker/pull/22386</a></p>

<h3>为 <code>btrfs</code> 存储驱动增加容器 <code>rootfs</code> 的限额功能</h3>

<p>类似这样，可以在Docker守护进程或者容器级别设置根文件系统的大小：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker daemon --storage-opt btrfs.min_space=xx
</span><span class='line'>$ docker run --storage-opt size=xx</span></code></pre></td></tr></table></div></figure>


<p>PR1：<a href="https://github.com/docker/docker/pull/19651">https://github.com/docker/docker/pull/19651</a>
PR2：<a href="https://github.com/docker/docker/pull/19367">https://github.com/docker/docker/pull/19367</a></p>

<h3><code>docker search</code> 增加 <code>--limit</code> 和 <code>filter</code> 参数</h3>

<ul>
<li><code>--limit</code> 参数</li>
</ul>


<p><code>docker search</code> 命令增加了一个 <code>--limit</code> 参数，可以设置查找镜像的返回结果个数。这个参数的默认值为25，可以接受的范围是0-100（实际上好像服务端最多只能返回100条记录）。</p>

<p>PR：<a href="https://github.com/docker/docker/pull/23107">https://github.com/docker/docker/pull/23107</a></p>

<ul>
<li><code>--filter</code> 参数</li>
</ul>


<p>比如可以指定只返回官方镜像，或者返回一定数量star的镜像：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker search --filter is-official=true ubuntu
</span><span class='line'>
</span><span class='line'>$ docker search --filter stars=30 ubuntu
</span></code></pre></td></tr></table></div></figure>


<p>PR：<a href="https://github.com/docker/docker/pull/22369">https://github.com/docker/docker/pull/22369</a></p>

<h3><code>docker ps</code> 命令增加 <code>--filter network=xxx</code>参数</h3>

<p>只列出指定网络模式的容器：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker run -d --net=bridge --name=onbridgenetwork busybox top
</span><span class='line'>$ docker run -d --net=none --name=onnonenetwork busybox top
</span><span class='line'>
</span><span class='line'>$ docker ps --filter network=bridge </span></code></pre></td></tr></table></div></figure>


<p>PR： <a href="https://github.com/docker/docker/pull/23300">https://github.com/docker/docker/pull/23300</a></p>

<h3><code>pid</code> 支持指定其他容器的pid</h3>

<p>在之前的版本中，<code>pid</code> 参数只支持 <code>host</code> 模式，现在也可以和其他容器共享PID命名空间了。这也可能是一个比较实用的功能。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker run --name my-redis -d redis
</span><span class='line'>
</span><span class='line'>$ # 在其他容器中使用strace进行调试
</span><span class='line'>
</span><span class='line'>$ docker run --it --pid=container:my-redis bash
</span><span class='line'>$ strace -p 1</span></code></pre></td></tr></table></div></figure>


<p>PR： <a href="https://github.com/docker/docker/pull/22481">https://github.com/docker/docker/pull/22481</a></p>

<h3><code>docker network ls</code> 新增了两种过滤类型</h3>

<p><code>docker network ls</code> 也增加了两种类型的过滤</p>

<ul>
<li>按驱动类型过滤</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker network ls --filter driver=bridge
</span><span class='line'>NETWORK ID          NAME                DRIVER
</span><span class='line'>db9db329f835        test1               bridge
</span><span class='line'>f6e212da9dfd        test2               bridge</span></code></pre></td></tr></table></div></figure>


<p>PR： <a href="https://github.com/docker/docker/pull/22319">https://github.com/docker/docker/pull/22319</a></p>

<ul>
<li>按label过滤</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ docker network ls -f "label=usage"
</span><span class='line'>NETWORK ID          NAME                DRIVER
</span><span class='line'>db9db329f835        test1               bridge              
</span><span class='line'>f6e212da9dfd        test2               bridge</span></code></pre></td></tr></table></div></figure>


<p>PR: <a href="https://github.com/docker/docker/pull/21495">https://github.com/docker/docker/pull/21495</a></p>

<h3>CLI子命令重构</h3>

<p>很多Docker 子命令都采用 <a href="https://github.com/spf13/cobra">cobra</a> 对CLI进行了重构，应该不算是什么大的改动。</p>

<h2>总结</h2>

<p>当然，还有类似小的一些改进，这里并没有都列出来，到时候大家看一下参考手册就能见到了，也许很多功能大家根本就不会用到：-）</p>

<p>到这里我们简单的就浏览了一下新版本的Docker中将会搭载的新功能，如果你觉得哪些是你想要的，就等着Docker 1.12.0的发布吧。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[2016年4月读书记录]]></title>
    <link href="http://liubin.github.io/blog/2016/05/26/04-reading/"/>
    <updated>2016-05-26T23:13:27+08:00</updated>
    <id>http://liubin.github.io/blog/2016/05/26/04-reading</id>
    <content type="html"><![CDATA[<p>这两个月效率非常低，也没什么兴致。4月读的书不多，总结也拖到了5月底，最近私事较多，希望6越以后能好转，至少可以不用为别的事分心。</p>

<p>4月读了3本书，2本电子书，1本纸版。</p>

<p>其中一本《HBase in action》的中文版，这是人邮异步社区送的电子版，在Kindle阅读器上读的，效果不是特别理想，这种书，还是得买纸版，或者在电脑的Kindle软件上才好吧。</p>

<p>另外有两本非技术书，一本是《互联网运营之道》，一本是《共享经济：互联网时代如何实现股东、员工与顾客的共赢》</p>

<h2>《HBase实战》</h2>

<p><img src="https://img3.doubanio.com/lpic/s27020560.jpg" alt="HBase实战" /></p>

<p>推荐指数：★★★★</p>

<p>这个是计算机书籍，讲的HBase的方方面面，从原理入门到线上运维和实际环境的配置等都有涉及，非常适合入门HBase。</p>

<p>从英文名字也可以看出，In Action系列一般来说都是非常值得信赖的。</p>

<h2>《共享经济：互联网时代如何实现股东、员工与顾客的共赢》</h2>

<p><img src="https://img1.doubanio.com/lpic/s28024129.jpg" alt="互联网运营之道" /></p>

<p>推荐指数：★★★★★</p>

<p>媒介：Kindle</p>

<p>这本书是误打误撞读到的。本来是想看看和共享经济相关的书，但被本书的标题迷惑了，实际副标题更体现了本书的主要思想，那就是如何通过信任来实现股东、员工与顾客的共赢。</p>

<p>本书的核心，就是围绕着信任两字来讲的。</p>

<p>随着社会和科技的进步，透明度也会提高，加强了人和人之间的互动，真正的实现了“坏事传千里”。随着人们之间的交往越来越高效，信任也正在逐渐成为人类文化的一个根本属性，如果按照传统的思维，企业提供高质量的产品，完善的售后，不一定就能在竞争中利于不败之地，而是需要一种全新的方式，体现自己的“值得信赖”。</p>

<p>书中举了很多例子来说明，如何让客户觉得企业可信，是站在自己的这一边的。</p>

<blockquote><p>我的一个朋友托马斯在网上订购了一套三件组合的桌子，其中两件顺利到货，但是第三件一星期之后还没送到。于是，托马斯打电话到公司询问，结果发现第三件被快递公司送错了地方，发到了另外一个配送中心，商品被送到了其他城市。在线零售客服很快解决了这个问题：“先生，发生这样的状况我们很抱歉。我们马上为您更换货物，用连夜快递为您配送剩下的一件，这样您明天就能收到货物。”我的朋友本来打算大发牢骚，但是客服及时地解决了问题，一下子让我的朋友心情缓和下来。当客服说“由于我们给您带来的不便，我们将会向您的信用卡返还25美元”时，我的朋友说这不是零售商的错，而是物流公司的错。客服说：“请您别担心，我们只是想确保您明天能够在您的新办公桌前办公。”这样的服务算是好的客户服务吗？这说明这家公司有良好的意图，还是有能力？谁在意呢？反正这样的公司就是人们能依靠的公司。这样的公司是完全值得人们依赖的公司。</p>

<p>无数研究表明，医疗事故投诉的最大导火索不是医生的技术，而是他们对病人的态度。不管医生的技术如何，病人们是不会控告那些被他们当作朋友的、具有同理心的医务人员的。但是，一旦医生（或公司）没能与病人建立友好的关系，或者没能表现出同理心，和他们相处时没有展示出“人性的面孔”，那么他们很可能就会遭到更多的投诉。</p>

<p>我们的房地产经纪人卡伦·凯利（Karen Kelly）是柯克兰集团（Corcoran Group）的，她带我们用几天时间看了40套公寓。最后当我们把选择的范围缩小到3套公寓时，我们突然接到一个朋友的电话，说他正在帮业主卖一套传统的合作公寓20。于是我们打电话给卡伦，问她该怎么做。她建议我们先去看看那套公寓，我们去后发现那套公寓非常不错。尽管卡伦从中得不到半分佣金，但她却带着很多有用的资料——包括建筑的历史、维修记录以及纳税信息，赶到我们这边。后来我们坚持要把这套公寓当作是她负责的，付给她买方应付的费用。因为即便她从这笔交易当中赚不到钱，她还是希望我们能够买到合适的公寓。从那以后，我们介绍了好几个人给她，包括买主和卖主。能帮我们的朋友在曼哈顿找到一个真正可以信任的房地产经纪人，我们会觉得自己为朋友帮上了忙。同时，我们当然也很希望看到卡伦获得成功！</p>

<p>一个值得依赖的汽车品牌会在保修期到期30天前给你发邮件或者打电话，这样一来，如果你有任何需要维修的地方，都能趁着保修期内及时地得到维修。</p></blockquote>

<p>还有几个例子，也很有趣，我忘了作者是要说明什么问题来着：</p>

<blockquote><p>在统计推理存在问题的案例当中，最臭名昭著的案例之一要数辛普森杀妻案。诉讼方认为，由于辛普森在过去经常对妻子妮可·辛普森实施暴力，所以他非常有可能谋杀了妻子。辩护律师轻易地推翻了这个论点，告诉陪审团说，上一年遭受丈夫家庭暴力的女性有400万，但是每2500人当中只有1人真正遭到谋杀。这一论点在当时显得非常具有说服力，无法驳倒，反映了诉讼方完全缺乏统计方面的知识（新闻媒体、法律评论员以及其他人在案件的展开过程中，评估案件时都反映出了同样的问题）。不论你对最后的裁决持什么样的观点，要是诉讼方当时指出另一项相关性更大的统计数据，案件的结果可能就不一样了。这项统计就是：上一年所有被丈夫殴打后又被谋杀的女性当中，90%都是被实施家暴的丈夫杀害的。</p>

<p>20世纪70年代，西班牙一名男子特意挑选了一张尾数为48的彩票，结果中奖了。他得意洋洋地告诉别人自己的“策略”，说：“我连续7天都梦到7这个数字，7乘以7就是48。”</p></blockquote>

<p>作者也认为企业应该抛弃“控制”，因为复杂系统没有自然科学那样的规律性和可预测性，尤其是不可预测的反馈系统：“跟推陀螺一样，如果你试图控制某个系统的行为，就很有可能失败，因为系统的反馈回路会产生意想不到的效果”。放弃控制，说到底就是要信任他人，并帮助他们相信你。如果希望你的员工对工作真正投入，你就必须准备好放弃一部分控制，相信他们能够把事情做好。</p>

<p>当然，本书也不是完全和共享无关。作者认为，随着社会的进步，人们更愿意和别人分享自己的知识和经验，更愿意与人交流，形成所谓的“社交经济”：不以经济目标为主，而是为了获得尊重、个人价值、社会地位和满足感等等非经济“利益”。这就是一种共享的文化，共享知识和数据，并享受这个过程。</p>

<p>企业必须积极关注顾客利益，甚至比顾客还关注顾客利益，才能真正的“俘获人心”，获得顾客的深度信任。企业也应该做到透明，而技术的进步也让社会更透明，“纸里包不住火”，该暴露的丑闻早晚大白于天下，如果<strong>顾客都不相信你，撒谎将没有任何意义</strong>。</p>

<p>企业也应该真诚的暴露自己的问题和缺点，没有完美的公司，如果你可以隐藏缺点，只是一味的吹嘘自己的有点，顾客就会认为企业一定在刻意隐瞒什么。有时候，为了赢得别人的信任，学会暴露自己的缺点很重要。</p>

<p>总之，真本书还是非常推荐读一下的，如果你真的是把客户当“上帝”的话。</p>

<h2>《互联网运营之道》</h2>

<p><img src="https://img1.doubanio.com/lpic/s28363838.jpg" alt="互联网运营之道" /></p>

<p>推荐指数：★★★☆☆</p>

<p>媒介：纸版</p>

<p>看书的介绍作者背景很不错，作者来自新浪，目前就职于创新工场。众所周知新浪微博的成功和他们的运营分不开，从一定程度上来说也可以认为是微博也是运营驱动的产品。</p>

<p>但拿到此书之后觉得有点亏，满打满算才190页，定价49，有点小贵，让我觉得有点哗众取宠想趁着风口多骗一些╭︿︿︿╮ {/ o  o /}   ( (oo) )     ︶︶︶。</p>

<p>其次是内容也不太实用。确实，运营这个事，如果看案例非常有意思，但是如果拿出一个让人信服，外行看了点头赞叹“原来如此”的系统化、理论化的原则原理或者方案，还是比较难的。每个公司都有不同的组织形式，工作流程和分工协作，别人的方式当然不能拿来直接用。</p>

<p>当然本书也不是一无是处，比如作者提到“目标用户是贯穿整个工作流程的主线”、“与其研究流式的的用户，不如研究活跃的用户”，通过本书，我才知道原来运营可以细分为内容运营、活动运营和用户运营（题外话：也有人建议将技术系的运维改为“技术运营”，仔细想想也有一定道理）。</p>

<p>通过本书，我的一个感想就是想清楚你的用户是谁，他们要干什么，然后围绕这两点，进行全方位的运营。</p>

<h2>这届初夏不行</h2>

<p>今年春末夏初，出了几件大事，不同类型、地区，基本都涉及到了人的安全问题，而且出现时机衔接如此紧密，这也是导致我分心的原因，所以整个4、5月都是在浑浑噩噩中度过。</p>

<p>想想4月的阅读情况，再想想现在已经是5月底，不知道如何清除初夏带来的心魔。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何使用 git diff 来对比Office文档？]]></title>
    <link href="http://liubin.github.io/blog/2016/04/26/how-to-use-git-to-diff-office-documents/"/>
    <updated>2016-04-26T12:51:35+08:00</updated>
    <id>http://liubin.github.io/blog/2016/04/26/how-to-use-git-to-diff-office-documents</id>
    <content type="html"><![CDATA[<p>我们知道用 <code>git diff</code> 命令比较文本文件还是比较容易的，Office文档的修改能比较么？</p>

<p>答案是可以的。下面我们就来看一下如何对Office文档进行比较。例子为在OS X上使用tika来将Office文本化之后再进行比较。</p>

<ul>
<li>安装tika</li>
</ul>


<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>brew install tika</span></code></pre></td></tr></table></div></figure>


<p>​
这可能需要一些时间，如果你的网速不快的话。</p>

<ul>
<li>创建脚本</li>
</ul>


<p>然后编辑一条用于比较Office文档的命令</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'># 文件名 ~/bin/diffoffice
</span><span class='line'>
</span><span class='line'>#!/bin/sh
</span><span class='line'>tika -t "$1"</span></code></pre></td></tr></table></div></figure>


<p>并将文件设置为可执行权限</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>chmod +x ~/bin/diffoffice</span></code></pre></td></tr></table></div></figure>


<ul>
<li>编辑 git 配置文件</li>
</ul>


<p>编辑 <code>~/.gitconfig</code> 文件</p>

<p>添加如下内容：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>[diff "office"]
</span><span class='line'>  binary = true
</span><span class='line'>  textconv = ~/bin/diffoffice</span></code></pre></td></tr></table></div></figure>


<ul>
<li>编辑代码仓库的属性文件</li>
</ul>


<p>在代码仓库的根目录下，创建 <code>.gitattributes</code> 文件，其内容如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>*.pptx diff=office
</span><span class='line'>*.docx diff=office
</span><span class='line'>*.xlsx diff=office</span></code></pre></td></tr></table></div></figure>


<p>上面操作完成之后，就可以对Office的“二进制文件”进行对比了。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ git diff keynote.pptx
</span><span class='line'>
</span><span class='line'>... ...
</span><span class='line'>
</span><span class='line'>index 68a6a9a..bf108f9 100644
</span><span class='line'>--- a/20160423-docker-monitoring/keynote.pptx
</span><span class='line'>+++ b/20160423-docker-monitoring/keynote.pptx
</span><span class='line'>@@ -175,7 +175,7 @@ SaaS
</span><span class='line'> 采集
</span><span class='line'> 存储
</span><span class='line'> 展示
</span><span class='line'>-报警（动作）
</span><span class='line'>+报警（事件处理）
</span><span class='line'> </span></code></pre></td></tr></table></div></figure>



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何选择Docker监控方案]]></title>
    <link href="http://liubin.github.io/blog/2016/04/24/how-to-choose-a-docker-monitor-solution/"/>
    <updated>2016-04-24T11:48:38+08:00</updated>
    <id>http://liubin.github.io/blog/2016/04/24/how-to-choose-a-docker-monitor-solution</id>
    <content type="html"><![CDATA[<p><em>这是2016/4/23关于Docker性能监控的一次Meetup的内容节选，完整内容请参见文末<a href="https://github.com/liubin/presentations/tree/master/20160423-docker-monitoring">链接</a></em></p>

<p>大家好，非常高兴来上海跟大家分享一下我们在Docker监控方面的一点点经验。</p>

<p>今天我要跟大家享主题是《如何选择Docker监控方案》。</p>

<p>这里我将主要对Docker监控的原理和常用工具以及主流的解决方案进行简单介绍，如果大家正准备对Docker进行监控，希望这次分享能为大家带来一些帮助，如果你们已经进行了对Docker的监控，我也希望能的大家交流一下经验，跟大家互相学习一下。</p>

<p>同时，最后我也会安利一下SaaS这种商业模式，甚至是一种消费观念。可以说，我这次代表的不是某具体厂商，而是代表我们同样做类似服务的SaaS行业。</p>

<h2>什么是监控</h2>

<p>为什么监控，监控什么内容？</p>

<p>我们要对自己系统的运行状态了如指掌，有问题及时发现，而不让让用户先发现我们系统不能使用，打电话过来到客服，客服再反映到开发，这个过程很长，而且对工程师来说，是一件比较没面子的事情。</p>

<p>我们也不能一问三不知，比如领导问我们这个月的MySQL并发到了什么情况？slowsql处于什么水平，平均响应时间超过200ms的占比有百分之多少？</p>

<p>回答不出来这个问题很尴尬，尽管你工作很辛苦，但是却没有拿得出来的成果。不要以为没出问题就没事了，你要换位想想，站在领导的角度，领导什么都不干，你提案，他签字，出了问题领导责任也很大啊。</p>

<h2>监控目的</h2>

<ul>
<li>减少宕机时间</li>
<li>扩展和性能管理</li>
<li>资源计划</li>
<li>识别异常事件</li>
<li>故障排除、分析</li>
</ul>


<p>我们为什么需要监控我们的服务？其中有一些显而易见的原因，比如需要监控工具来提醒我服务出现了故障，比如通过监控服务的负载来决定扩容或缩容。如果机器普遍负载不高，则可以考虑是否缩减一下机器规模，如果数据库连接经常维持在一个高位水平，则可以考虑一下是否可以进行拆库处理，优化一下架构。</p>

<p>此外，监控还可以帮助进行内部统制，尤其是对安全比较敏感的行业，比如证券银行等。比如服务器受到攻击时，我们需要分析事件，找到根本原因，识别类似攻击，发现没有发现的被攻击的系统，甚至完成取证等工作。</p>

<h2>Docker监控的挑战</h2>

<ul>
<li>Docker特点

<ul>
<li>像host但不是host</li>
<li>量大</li>
<li>生命周期短</li>
</ul>
</li>
<li>监控盲点（断层）</li>
<li>微服务</li>
<li>集群</li>
<li>全方位

<ul>
<li>Host（VM） + Services + Containers + Apps</li>
</ul>
</li>
</ul>


<p>容器为我们的开发和运维带来了更多的方向和可能性，我们也需要一种现代的监控方案来应对这种变化。</p>

<p>随着不可变基础设施概念的普及，云原生应用的兴起，云计算组件已经越来越像搭建玩具的积木块。很多基础设施生命周期变短，不光容器，云主机、VM也是。</p>

<p>在云计算出现之前，一台机器可能使用3、5年甚至更长都不会重装，主机名也不会变，而现在，我们可能升级一个版本，就重建一个云主机或者重新启动一个容器。监控对象动态变化，而且非常频繁。即使全部实现自动化，也会在负载和复杂度方面带来不利影响。</p>

<p>集群的出现，应用的拓扑结构也变得复杂，不同的应用的指标和日志格式也不统一，再加上如何应对多租户，也给监控带来了新挑战。</p>

<p>传统的监控内包括主机、网络和应用，但是Docker出现了，容器这一层容易被忽略，成为三不管地区，监控的盲点。</p>

<p>有人说，容器不就是个普通的OS么？装个Zabbix的探针不就行了么？</p>

<p>Docker host和Docker 容器都要装Zabbix探针。。。其实问题很多。</p>

<p>除了容器内部看到的cpu内存情况不准之外，而且容器生命周期短，重启之后host名，ip地址都会变，所以最好在Docker host上安装Zabbix agent。</p>

<p>如果每个容器都像OS那样监控，则metric数量将会非常巨大，而且这些数据很可能几分钟之后就无效率了（容器已经停止）。容器生命周期短暂，一旦容器结束运行，之前收集的数据将不再有任何意义。</p>

<p>主要的解决方式就是对以App或者Service为单位进行监控（通过Tag等方式）。</p>

<h2>Docker监控技术基础</h2>

<ul>
<li><code>docker stats</code></li>
<li>Remote API</li>
<li>伪文件系统</li>
</ul>


<p>我们可以通过 <code>docker stats</code> 命令或者Remote API以及Linux的伪文件系统来获取容器的性能指标。</p>

<p>使用API的话需要注意一下，那就是不要给Docker daemon带来性能负担。如果你一台主机有200个容器，如果非常频繁的采集系统性能可能会大量占据CPU时间。</p>

<p>最好的方式应该就是使用伪文件系统。如果你只是想通过shell来采集性能数据，则 <code>docker stats</code> 可能是最简单的方式了。</p>

<h2>docker stats命令</h2>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span>docker stats redis1 redis2
</span><span class='line'>CONTAINER           CPU %               MEM USAGE/LIMIT     MEM %               NET I/O
</span><span class='line'>redis1              0.07%               <span class="m">796</span> KB/64 MB        1.21%               <span class="m">788</span> B/648 B
</span><span class='line'>redis2              0.07%               2.746 MB/64 MB      4.29%               1.266 KB/648 B
</span></code></pre></td></tr></table></div></figure>


<p>该命令默认以流式方式输出，如果想打印出最新的数据并立即退出，可以使用 <code>no-stream=true</code> 参数。</p>

<h2>伪文件系统</h2>

<ul>
<li>CPU、内存、磁盘</li>
<li>网络</li>
</ul>


<p>文件位置大概在（跟系统有关，这是Systemd的例子）：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>/sys/fs/cgroup/<span class="o">{</span>memory,cpuacct,blkio<span class="o">}</span>/system.slice/<span class="k">${</span><span class="nv">docker</span><span class="p"> ps --no-trunc</span><span class="k">}</span>.scope
</span></code></pre></td></tr></table></div></figure>


<p>Docker各个版本对这三种方式的支持程度不同，取得metric的方式和详细程度也不同，其中网络metric是在1.6.1之后才能从伪文件系统得到。</p>

<h2>Memory</h2>

<p>内存的很多性能指标都来自于 <code>memory.stat</code> 文件</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>... ...
</span><span class='line'>cache 11492564992
</span><span class='line'>rss 1930993664
</span><span class='line'>swap 0
</span><span class='line'>pgfault 728281223
</span><span class='line'>... ...
</span><span class='line'>total_cache 11492564992
</span><span class='line'>total_rss 1930993664
</span><span class='line'>total_pgpgin 406632648
</span><span class='line'>total_pgpgout 403355412
</span><span class='line'>total_swap 0
</span><span class='line'>total_pgfault 728281223
</span><span class='line'>... ...
</span></code></pre></td></tr></table></div></figure>


<p>前面的不带total的指标，表示的是该cgroup中的process所使用的、不包括子cgroup在内的内存量，而total开头的指标则包含了这些进程使用的包括子cgroup数据。这里我们看到的数据都是一样的，由于这里并没有子cgroup。</p>

<p>两个比较重要的指标：</p>

<ul>
<li>RSS： resident set size</li>
</ul>


<p>进程的所有数据堆、栈和memory map等。rss可以进一步分类为active和inactive（active_anon and inactive_anon）。在内存不够需要swap一部分到磁盘的时候，会选择inactive 的rss进行swap 。</p>

<ul>
<li>cache memory</li>
</ul>


<p>缓存到内存中的硬盘文件的大小。比如你读写文件的时候，或者使用mapped file的时候，这个内存都会增加。这类内存也可以再细分为active和inactive的cache，即active_file和inactive_file。如果系统需要更多内存，则inactive的cache会被优先重用。</p>

<h2>CPU</h2>

<ul>
<li><code>cpuacct.stat</code>文件</li>
<li>docker.cpu.system</li>
<li>docker.cpu.user</li>
</ul>


<p>但是比较遗憾，Docker 不会报告nice，idle和iowait等事件。</p>

<p>System也叫kernel时间，主要是系统调用所耗费的部分，而user则指自己程序的耗费CPU，如果User时间高，则需要好好检查下自己的程序是否有问题，可能需要进行优化。</p>

<h2>Blkio</h2>

<p>优先从CFQ（Completely Fair Queuing 完全公平的排队）拿数据，拿不到从这两个文件拿：</p>

<p><code>blkio.throttle.io_service_bytes</code>，读写字节数
<code>blkio.throttle.io_serviced</code>，读写次数</p>

<p>Throttle这个单纯可能有误导，实际这些都不是限制值，而是实际值。</p>

<p>每个文件的第一个字段是 <code>major:minor</code> 这样格式的device ID。</p>

<h2>网络数据</h2>

<ul>
<li>iptables</li>
<li>伪文件系统</li>
<li><p>网络设备接口</p></li>
<li><p>Virtual Ethernet</p></li>
</ul>


<p>针网络的监控要精确到接口级别，即网卡级别。每个容器在host上都有一个对应的virtual Ethernet，我们可以从这个设备获得tx和rx信息。</p>

<p>不过找到容器在主机上对应的虚拟网卡比较麻烦。这时候可以在宿主机上通过 <code>ip netns</code> 命令从容器内部取得网络数据。</p>

<p>为了在容器所在网络命名空间中执行 <code>ip netns</code> 命令，我们首先需要找到这个容器进程的PID。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ CONTAINER_PID</span><span class="o">=</span><span class="sb">`</span>docker inspect -f <span class="s1">&#39;&#39;</span> <span class="nv">$CONTAINER_ID</span><span class="sb">`</span>
</span><span class='line'><span class="nv">$ </span>mkdir -p /var/run/netns
</span><span class='line'><span class="nv">$ </span>ln -sf /proc/<span class="nv">$CONTAINER_PID</span>/ns/net /var/run/netns/<span class="nv">$CONTAINER_ID</span>
</span><span class='line'><span class="nv">$ </span>ip netns <span class="nb">exec</span> <span class="nv">$CONTAINER_ID</span> netstat -i
</span></code></pre></td></tr></table></div></figure>


<p>或者：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ CONTAINER_PID</span><span class="o">=</span><span class="sb">`</span>docker inspect -f <span class="s1">&#39;&#39;</span> nginx <span class="sb">`</span>
</span><span class='line'><span class="nv">$ </span>cat /proc/<span class="nv">$CONTAINER_PID</span>/net/dev
</span></code></pre></td></tr></table></div></figure>


<p>实际上Docker的实现也是从伪文件系统中读取网络metric的：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nv">$ </span><span class="nb">pwd</span>
</span><span class='line'>/sys/class/net/veth559b656/statistics
</span><span class='line'>
</span><span class='line'><span class="nv">$ </span>ls
</span><span class='line'>collisions     rx_crc_errors   rx_frame_errors   rx_packets         tx_compressed   tx_heartbeat_errors
</span><span class='line'>multicast      rx_dropped      rx_length_errors  tx_aborted_errors  tx_dropped      tx_packets
</span><span class='line'>rx_bytes       rx_errors       rx_missed_errors  tx_bytes           tx_errors       tx_window_errors
</span><span class='line'>rx_compressed  rx_fifo_errors  rx_over_errors    tx_carrier_errors  tx_fifo_errors
</span></code></pre></td></tr></table></div></figure>


<h2>Docker监控方案实现</h2>

<ul>
<li>自己动手 + 开源软件</li>
<li>SaaS</li>
</ul>


<h2>评价标准</h2>

<ul>
<li>功能

<ul>
<li>满足</li>
<li>信息详细程度</li>
<li>查询的灵活程度</li>
<li>报警 + API</li>
</ul>
</li>
<li>灵活性

<ul>
<li>定制</li>
</ul>
</li>
<li>成本

<ul>
<li>学习、开发</li>
<li>维护</li>
</ul>
</li>
<li>运维

<ul>
<li>部署复杂程度</li>
</ul>
</li>
<li>高可用</li>
</ul>


<p>需要考虑的基本要素如上所示，不多述。</p>

<h2>自己动手</h2>

<ul>
<li>灵活性强</li>
<li>成本高</li>
</ul>


<p>这里的成本包括开发成本，开发成本可能包括招人和培训，开发时间和填坑时间。开发完了还需要维护成本，而且随着Docker的升级，可能还需要对metric的采集实现进行升级，以及各种bugfix。</p>

<h2>自己动手打造监控方案</h2>

<ul>
<li>采集</li>
<li>存储</li>
<li>展示</li>
<li>报警（动作）</li>
</ul>


<p>StatsD 是 Flickr 公司首先提出来的，后来由 Esty 公司发扬光大的一个轻量级的指标采集模块。</p>

<p>简单来讲，StatsD 就是一个简单的网络守护进程，基于 Node.js 平台（Esty实现，其实也有其他语言版本），通过 UDP 或者 TCP 方式侦听各种统计信息，包括计数器和定时器，可以用来采集操作系统、不同数据库、中间件的数据指标，进行缓存、聚合，并发送到Graphite 等存储和可视化系统中。</p>

<p>StatsD 具有以下优点：</p>

<ul>
<li>简单</li>
</ul>


<p>首先安装部署简单，且StatsD 协议是基于文本的，可以直接写入和读取，方便实现各种客户端和SDK。</p>

<p>Cloud Insight的探针也是采用这些方式，我们有些SDK也是基于StatsD的，目前有Ruby、Python和Java的，在<a href="https://github.com/cloudinsight">GitHub</a>上可以看到。</p>

<ul>
<li>低耦合性</li>
</ul>


<p>StatsD 守护进程采取 UDP 这种无状态的协议，收集指标和应用程序本身之间没有依赖，不会阻塞应用，不管StatsD的状态是运行中，还是没在运行，都不会影响应用程序，应用程序也不关心StatsD是否收到数据。</p>

<ul>
<li>易集成</li>
</ul>


<p>StatsD非常容易整合其他组件，可以自己编写采集业务逻辑，发送到StatsD守护进程即可。也就是说用户的工作很简单，只需要按定义好的规则采集数据发送到Stats，然后用Graphite存储、展示，通过使用Riemann进行报警。</p>

<h2>Tcollector</h2>

<ul>
<li>来源于OpenTSDB</li>
</ul>


<p>Tcollector 是一个采集指标数据并保存到OpenTSDB的框架，你可以使用该框架自己编写采集的业务逻辑。类似StatsD，运行在客户端，收集本地的metric信息，推送到OpenTSDB。</p>

<h2>Collectd</h2>

<ul>
<li>System statistics collection daemon</li>
<li>存储到RRD</li>
<li>插件机制（input/output）</li>
<li>简单报警功能</li>
</ul>


<p>Collectd即是一个守护进程，也是一个框架，类似StatsD，它性能非常好，采用C语言编写。Collectd不直接支持从Docker中取数据，但是我们可以自己编写插件来采集性能指标数据。</p>

<p>Collectd有强大的插件机制，已经实现了包括amqp、rrdtool、graphite、http、kafka、redis、mongodb、OpenTSDB以及CSV文件等在内的各种插件。</p>

<p>在4.3版本之后还支持简单的基于阈值检查的报警机制。</p>

<h2>cAdvisor（Container Advisor）</h2>

<p><img src="http://liubin.github.io/images/2016/04/docker-monitor/cadvisor.png" alt="" /></p>

<p>cAdvisor是一个用于收集、聚合处理和输出容器运行指标的守护进程。而且cAdvisor基本算是一个获取Docker性能数据的标配了吧。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>sudo docker run <span class="se">\</span>
</span><span class='line'>  --volume<span class="o">=</span>/:/rootfs:ro <span class="se">\</span>
</span><span class='line'>  --volume<span class="o">=</span>/var/run:/var/run:rw <span class="se">\</span>
</span><span class='line'>  --volume<span class="o">=</span>/sys:/sys:ro <span class="se">\</span>
</span><span class='line'>  --volume<span class="o">=</span>/var/lib/docker/:/var/lib/docker:ro <span class="se">\</span>
</span><span class='line'>  --publish<span class="o">=</span>8080:8080 <span class="se">\</span>
</span><span class='line'>  --detach<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
</span><span class='line'>  --name<span class="o">=</span>cadvisor <span class="se">\</span>
</span><span class='line'>  google/cadvisor
</span></code></pre></td></tr></table></div></figure>


<p>一句命令就可以启动cAdvisor容器，访问8080端口即可看到性能指标数据。cAdvisor可以通过storage_driver参数将数据存到influxdb，同时也可以将metric输出为Prometheus的格式，所以很多自定义Docker监控系统都会采取cAdvisor + Prometheus 的组合。</p>

<h2>存储TSDB</h2>

<ul>
<li>OpenTSDB</li>
<li>Influxdb</li>
<li>RRDTool</li>
<li>Graphite</li>
</ul>


<p>关于时序列数据库，可以看附录中相关的介绍文章。推荐使用OpenTSDB或者Influxdb，简单对比一下各自特点如下：</p>

<ul>
<li>OpenTSDB

<ul>
<li>Java &amp; HBase</li>
<li>易扩展（集群功能强大）</li>
<li>机器多，运维稍显麻烦</li>
</ul>
</li>
<li>Influxdb

<ul>
<li>Golang</li>
<li>集群功能不太成熟</li>
<li>有类SQL的查询语句</li>
<li>单台即可工作</li>
</ul>
</li>
</ul>


<p>这两者都支持自由模式和多维度，非常适合用于采用tag机制的数据模式建模。</p>

<h2>开源可视化工具</h2>

<ul>
<li>Graphite</li>
<li>Influxdb + Grafana</li>
<li>Prometheus</li>
</ul>


<p>光有数据是不够的，raw data没有任何意义，我们需要良好的可视化组件来展示数据和数据的内在意义，发挥数据的作用。</p>

<p>我们也可以将数据存储和展示交给其他开源软件。</p>

<p>如果你的数据采集和存储都是自己来完成的，只想使用一个外部的图形化界面的话，选Grafana应该没错，Grafana展现形式非常丰富，配置也很灵活。</p>

<p><img src="http://liubin.github.io/images/2016/04/docker-monitor/grafana.png" alt="" /></p>

<h2>开源方案</h2>

<ul>
<li>cAdvisor（经典）+ InfluxDB + Grafana</li>
<li>Zabbix/Nagios/Hawkular</li>
<li>Fluentd</li>
<li>Prometheus</li>
<li>Riemann</li>
<li>ATSD（Axibase Time Series Database）</li>
</ul>


<p>Hawkular 是一个来自于RedHat开源的监控解决方案，也包括报警等系统，可以说功能非常强大。</p>

<p>Hawkular基于Cassandra存储，它认为这虽然增加了运维的复杂程度，但是扩展变得容易（参考前面关于OpenTSDB和Influxdb的对比）。</p>

<h2>Zabbix</h2>

<ul>
<li>最经典（SaaS软件的最大敌人）</li>
<li>架构简单、清晰</li>
<li>文档丰富</li>
<li>包括采集、触发、告警</li>
<li>Agent支持用户自定义监控项</li>
<li>通过SNMP、ssh、telnet、IPMI、JMX监控</li>
<li>一套HTTP + JSON的接口</li>
</ul>


<p>现在Zabbix已经实现了探针的自动注册，也支持了基于角色的监控对象自动发现，但是你还是需要管理这些自动配置的项目。而且监控的服务多了，Zabbix探针在监控对象上运行的脚本也会变多，需要更多的进程，可能会对正常业务产生影响。</p>

<p>在Zabbix中支持Docker，可以使用 Zabbix Docker Monitoring ，首先需要下载两个xml的模板文件，导入到管理界面，然后在docker host，也就是zabbix的agent的机器上，安装zabbix模块（.so），然后还得在Docker主机上启动cadvisor容器。</p>

<h2>Graphite</h2>

<p>主要功能：</p>

<ul>
<li>存储数值型时序列数据</li>
<li>根据请求对数据进行可视化（画图）</li>
</ul>


<p>Graphite是一个经典的时序列数据存储，容易扩展，提供了功能强大的画图Web API以及大量的函数和输出方式。Graphite有自己的可视化实现，也可以支持Grafana。</p>

<p>Graphite本身不带数据采集功能，你需要选择其他第三方插件，比如Collectd等。</p>

<p><img src="http://liubin.github.io/images/2016/04/docker-monitor/graphite.png" alt="" /></p>

<p>Graphite架构自下而上分为3个模块：</p>

<ul>
<li>whisper：创建、更新RRD文件</li>
<li>carbon：以守护进程的形式运行，接收数据写入请求

<ul>
<li>carbon-cache：数据存储</li>
<li>carbon-relay：分区和复制，位于carbon-cache之前，类似carbon-cache的负载均衡</li>
<li>carbon-aggregator：数据集计，用于减轻carbon-cache的负载</li>
</ul>
</li>
<li>graphite-web：用于读取、展示数据的Web应用</li>
</ul>


<p>Whisper使用了类似RRDtool的RRD文件格式，不像C/S结构的软件，whisper没有服务进程，只是作为library来使用，直接对文件进行create/update/fetch等操作。</p>

<h2>Prometheus</h2>

<ul>
<li>一体化、仪表盘和告警</li>
<li>多维度</li>
<li>灵活查询语言</li>
<li>非分布式、单机自治</li>
<li>基于HTTP的pull模式（push需要中间网关）</li>
<li>LevelDB</li>
</ul>


<p><img src="http://liubin.github.io/images/2016/04/docker-monitor/prometheus-arch.png" alt="" /></p>

<p>Prometheus是一个全套监控和预测方案，包括数据采集、存储、查询和可视化，以及报警功能。由社交音乐平台SoundCloud在2012年开发，最近也非常火。</p>

<p>在集群流行的时候，很少有软件专为单机、本地存储而设计。Prometheus就是这样一个软件，它采用了基于LevelDB的本地存储，并没有使用成熟的面向列的数据库。不过Prometheus 也在实验将数据存储到OpenTSDB。</p>

<p>Prometheus 采用了pull模式，即服务器通过探针端的exporter来主动拉取数据，而不是探针主导上报。</p>

<p>Prometheus部署和运维起来可能比较麻烦，需要很多组件单独安装，比如dashboard（PromDash），虽然这虽然显得更加开放和包容。不过使用Docker的话将会简单很多，通过一个Docker Compose配置文件就能建立全功能的Prometheus监控环境，网上有很多这样的例子。</p>

<h2>Heapster</h2>

<ul>
<li>经典组合：heapster + Influxdb + grafana</li>
<li>Sink：Kafka、stdout、gcm（Google Cloud Monitoring）、hawkular、monasca、riemann、opentsdb</li>
</ul>


<p>Heapster是k8s的一个子项目，用于获取集群的性能数据。现在Heapster原生支持k8s和CoreOS，也可以很容易扩展来支持其他集群管理软件。</p>

<p>Heapster除了支持，基本的metric之外，还支持事件类型的数据，比如容器生命周期事件。</p>

<h2>Riemann</h2>

<ul>
<li>事件处理</li>
<li>Clojure实现</li>
</ul>


<p>Riemann 是一个分布式监控（数据处理）系统，但它做的事情其实非常简单，就是接收事件->按定义规则处理->转发或存储到外部系统。</p>

<p>我们可以将Riemann 与时间序列数据库，或者基于 StastD 的方案集成使用，来弥补其他方案在报警、事件流处理这方面上的不足。</p>

<p>Riemann采用Clojure语言编写，这是一门Lisp方言，函数式编程语言，对于大多数习惯于过程式或者面向对象的现代人来说，理解起来有一定难度，有一定的学习曲线。</p>

<h2>开源软件的问题点</h2>

<ul>
<li>灵活性受限于upstream</li>
<li>维护成本高</li>
<li>定制难度大</li>
<li>技术栈</li>
</ul>


<p>要选择自己熟悉或者能投入精力去熟悉的技术栈产品，否则有问题没人调查，监控产品将沦为摆设。</p>

<h2>SaaS</h2>

<ul>
<li>turnkey解决方案</li>
<li>维护成本 ~ Zero</li>
<li>适合中小企业</li>
</ul>


<p>对于中小型企业尤其创业公司来说，自主开发或者直接利用现有的开源工具进行监控都有一些问题，主要是成本和风险的问题。对于中小企业，应该先把精力集中在发展核心业务，能外包的就先不自己做。而且很多中小公司大家都是全栈，没有专门的运维人员，都是临时抱佛脚，随时都会变成救火队员。</p>

<p>SaaS最大的优点是什么？那就是免运维，开箱即用，修改的代码少甚至不需要修改代码，或者只需要简单的安装一个agent就可以工作了。很多SaaS软件的开场白都是运行一条 <code>yum install</code> ，然后倒上一杯咖啡等几分钟，就能看到数据了。</p>

<p>你的初期投入非常少，上手非常快，而且成本比较低（如果你的公司已经有数百上千服务器了，则这部分成本可能会变高，就跟是自建机房还是用云主机的对比一样）。</p>

<h2>SaaS</h2>

<ul>
<li>传统APM

<ul>
<li>New Relic</li>
<li>AppDynamics</li>
<li>Dynatrace（Ruxit）</li>
</ul>
</li>
<li>基础设施监控

<ul>
<li>Datadog</li>
<li>SysDig</li>
<li>Cloud Insight</li>
<li>clusterup</li>
<li>Scout</li>
</ul>
</li>
</ul>


<p>RancherLab公司有人写了篇文章，本讲稿的最后有链接，大家可以参考下。这篇文章名为《Comparing Seven Monitoring Options for Docker》，即对比了七种不同的监控Docker的方案，包括使用 <code>docker stats</code> 命令, cAdvisor, Prometheus ，Sensu，以及saas服务 Scout, Sysdig Cloud and DataDog等方案，作为结论作者觉得Datadog是这其中最优秀的方案。</p>

<blockquote><p><em>RancherLab有一个产品叫RancheOS，是一个专门为了运行Docker准备的微型Linux版本，它的口号是“The perfect place to run Docker”。跟CoreOS类似，但是貌似功能不如CoreOS多，也没有CoreOS有名，也没有CoreOS中fleet、flannel和etcd这样的组件，尤其是etcd，可以说是CoreOS的副产品，但是几乎成了Docker业界标准的kv store和服务发现组件了。</em></p></blockquote>

<h2>Datadog</h2>

<ul>
<li>国外最好</li>
<li>功能很强大</li>
<li>安装很简单</li>
</ul>


<p>国外最流行的SaaS解决方案是Datadog，国内可能比较成熟、规模较大的应该算是Cloud Insight了。</p>

<p>这类服务用户只需要注册一个账号，按照安装过程通过一条命令来安装探针即可在web展示端看到数据。</p>

<p>要说到Datadog的不足，那就是在国外，网络延迟需要考虑，万一哪天不科学了也需要有所准备。</p>

<p>价格方面Datadog也比较贵。免费plan支持5台机器，而且只保留一天的数据，而且没有报警功能。收费版15美元一台主机，支持报警功能，数据存储13个月。</p>

<p>说道SaaS，不得不提客服，直接面对非母语客服人员交流起来肯定会有诸多不顺吧。</p>

<h2>Cloud Insight</h2>

<ul>
<li>实时数据</li>
<li>历史数据</li>
<li>仪表盘</li>
<li>混合监控</li>
<li>报警功能</li>
</ul>


<p>当然，最便宜的还是Cloud Insight，有多便宜呢，官方定价的话3个探针以下是免费的，支持超过3台主机的话，平均每天1快钱。</p>

<p>这只是官方定价，实际上还会便宜，貌似联系客服就可以知道有多便宜了。</p>

<p>Cloud Insight还支持ChatOps集成，包括国内的 BearyChat 和简聊。随着devops文化的普及，相信这些工具的重要性也会与日俱增。</p>

<p>Cloud Insight的图表功能也很丰富，能对任何指标以图表的方式展示，还能在图表上叠加事件，比如报警通知、服务启动停止等，能在观察到metric变动趋势的同时，看到相应的时间，了解metric发生变动的原因。比如CPU load超过一定值时，可能触发报警，这时你能在图表上看到相应的事件，同样，如果CPU load一直不是很低，但是从某一时间点开始变低了，你可能也能从一次新的代码部署中了解原因。</p>

<h2>Sysdig</h2>

<ul>
<li>免费工具</li>
<li>SaaS服务 Sysdig Cloud</li>
<li>拓扑可视化</li>
</ul>


<p>可以认为sysdig是strace + tcpdump + htop + iftop + lsof + 众多linux常用的系统监控命令的合体。</p>

<p>如果你熟悉tcpdump，那么你知道它能还原整个网络流量，而sysdig则是操作系统级别的监控工具，能捕捉到所有OS事件和数据。</p>

<p>而且sysdig原生支持Linux container，包括Docker和LXC，提供了基本的指标监控信息。除了性能指标，sysdig还能采集trace等日志信息，用于以后的问题分析和解决。</p>

<p>Sysdig Cloud是sisdig的SaaS版，除了基本的单机sysdig功能之外，还提供了跨平台跨基础设施的组件间依赖关系的可视化。</p>

<h2>Librato</h2>

<ul>
<li>数据聚合平台</li>
<li>简单探针</li>
<li>图表和报警</li>
<li>价格不贵</li>
</ul>


<p>Librato是一个数据聚合平台，而不是严格意义的监控系统。</p>

<p>Librato很容易从AWS CloudWatch和Heroku获得数据，如果是自己监控主机或者Docker，需要使用Collectd框架。它也有很多插件，可以从StatsD、Riemann等数据源采集数据。</p>

<p>Librato的探针虽然功能不是强大，但是他提供了丰富的实时在线数据处理功能，用户可以使用DSL对任意时间序列数据组合进行数学运算，比如加减乘除、比率导数等。还支持和时间窗口滑动功能，即跟过去某一段时间进行比较。</p>

<p>Librato也支持报警，基于metric和条件，设置报警信息。</p>

<p>Librato是按照metric的个数和时间分辨率来收费的，在官网的主页上有一个大概的估算，如果你有20个metric，并且时间间隔为60秒，则一台服务器的价格只有2美元1个月，这比datadog要便宜。</p>

<h2>Axibase（ATSD）</h2>

<ul>
<li>非开源TSDB</li>
<li>支持报警</li>
<li>预测功能</li>
</ul>


<p><img src="http://liubin.github.io/images/2016/04/docker-monitor/atsd.png" alt="" /></p>

<p>作为TSDB，ATSD支持长时间存储高精度的metric数据。ATSD支持多种数据采集工具和协议，比如tcollector, Collectd，当然ATSD也支持从多台Docker主机手机指标数据，并长期保存，进行可视化和分析。</p>

<p>除了传统的时间序列数据，ATSD还支持属性（Properties）和消息这两种类型的数据。属性一般用于保存meta data，这有点类似标签。</p>

<p>和OpenTSDB一样，ATSD也支持tag，我们可以使用这些tag进行过滤和聚合。</p>

<p>ATSD内置了自动回归推断算法（holt-winters，arima），可以提早预测故障。预测功能的准确性取决于数据的采集频率，保存时间（也就是数据量大小）和算法。</p>

<p>最大的遗憾，就是ATSD不是开源，也不是免费的软件，不过他们提供了一个社区版可以免费使用，但是你只能在一个节点上安装ATSD，而且不能用于盈利性服务，也不能对软件进行修改以及再发布。</p>

<p>如果我们只是评估一下，或者想自己构建监控方案，它的产品设计还是非常值得我们来借鉴一下。</p>

<h2>SaaS的挑战</h2>

<ul>
<li>数据敏感性</li>
</ul>


<p>采用SaaS，意味着你的数据都将会保存到公网，可能会带来心理不安全感。实际上SaaS反而会更安全些，尤其是对中小公司没有专门的安全运维团队的情况下。</p>

<ul>
<li>成本（迁移和使用成本）</li>
</ul>


<p>一般来说这是一个一次性投入成本。</p>

<ul>
<li>内部抵抗（观念、个人爱好）</li>
</ul>


<p>来自技术人员自身的抵抗，不是每个人都喜欢自己变得轻松，使用SaaS可能会给一些人带来工作上的不充实感。</p>

<h2>趋势</h2>

<ul>
<li>标签机制</li>
</ul>


<p>一种观点：监控服务状态胜过监控个别容器，通过tag机制对服务整体的性能指标进行聚合。</p>

<p>Tag可以是任何维度，比如BU，地区，服务，甚至个别容器。</p>

<p>Docker和Kubernetes等都支持label机制，即tag机制。</p>

<ul>
<li>docker daemon &ndash;label com.example.group=&ldquo;webserver&rdquo;</li>
<li>docker run &ndash;label com.example.group=&ldquo;webserver&rdquo;</li>
<li><p>Dockerfile: LABEL com.example.group=&ldquo;webserver&rdquo;</p></li>
<li><p>通过API打通</p></li>
</ul>


<p>通过API化实现共赢。开源软件比如fluentd、Collectd等，都支持插件功能。包括Docker本身，也在1.11版本中，采用了runC作为容器运行时，在上面通过containerD来统一控制，来支持符合OCI标准的容器。</p>

<ul>
<li>Total解决方案</li>
</ul>


<p>包括从探针到展示、告警，就是现在类似Datadog和Cloud Insight这样的产品，以及支持中间件的详细程度，就像一个大市场，什么都能买到，不管你用什么软件，平台都能提供监控。</p>

<p>这就像是去了酒吧突然想吃碗拉面，然后竟然酒吧能给你做出来的那种感觉。</p>

<p>另一个层面就是从RUEM（实时用户体验管理）到基础设施层的 <strong>打通</strong> 。比如你看到某URL的用户HTTP响应较慢，如果不能跟后端的APM打通，你尽管能识别出问题，但是你不知道如何解决。如果和后端的APM以及基础设施监控打通，你就能定位到HTTP响应慢时，相应的后端代码的位置，并根据后端代码的位置从而进一步找到MySQL的监控数据以及系统异常事件，立刻知道问题的根本原因所在并解决问题，可以说效率应该能提高几个数量级。</p>

<p>系统监控工具如果能够做到 All in One，真的对解决人力和时间成本上有非常大的帮助。</p>

<ul>
<li>拓扑可视化</li>
</ul>


<p>跨组件、跨基础设施和应用，自动识别组件以及组件之间的依赖关系，以帮助更好的发现问题和解决问题。</p>

<ul>
<li>Weave Scope</li>
<li>Ruxit</li>
<li>Sysdig</li>
</ul>


<p>参考：</p>

<ul>
<li><a href="https://github.com/liubin/presentations/tree/master/20160423-docker-monitoring">本次分享全部资料</a></li>
<li><a href="http://rancher.com/comparing-monitoring-options-for-docker-deployments/">Comparing Seven Monitoring Options for Docker</a></li>
<li><a href="https://www.datadoghq.com/blog/how-to-collect-docker-metrics/">How to collect Docker metrics</a></li>
<li><a href="http://liubin.org/blog/2016/02/18/tsdb-intro/">时序列数据库武斗大会</a></li>
<li><a href="https://github.com/kiyoto/fluent-plugin-docker-metrics">Fluentd Docker Metrics Input Plugin</a></li>
<li><a href="https://docs.docker.com/v1.8/articles/runmetrics/">Docker Runtime metrics</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[2016年3月读书记录]]></title>
    <link href="http://liubin.github.io/blog/2016/04/05/03-reading/"/>
    <updated>2016-04-05T23:39:45+08:00</updated>
    <id>http://liubin.github.io/blog/2016/04/05/03-reading</id>
    <content type="html"><![CDATA[<p>本以为3月很忙，应该看不了几本，不过实际结果还是有点小惊喜的。这也说明，时间挤挤还是能挤出来一点的，不要再抱怨时间不够了。</p>

<p>三月读完6本书，主要是下面三种媒介：</p>

<ul>
<li><p>纸版书：</p>

<ul>
<li>《有鹿来：京都的日常》</li>
<li>《京都古书店风景》</li>
<li>《门外汉的京都》</li>
</ul>
</li>
<li><p>Kindle</p>

<ul>
<li>《互联网+战略版：传统企业，互联网在踢门》</li>
<li>《免费:商业的未来》</li>
</ul>
</li>
<li><p>微信读书App</p>

<ul>
<li>《超预期 小米的产品设计及营销方法》</li>
</ul>
</li>
</ul>


<p>相对于电子版，纸版书的优势还是很明显的：装帧、印刷工艺和质感，都是一本书不可或缺的因素。书不只是一个文字的有序组合。</p>

<p>电子版的书最大的问题在于排版太差，各设备阅读体验不统一。比如上面的《超预期 小米的产品设计及营销方法》，根本分不清标题的级别，每一章一个大标题，整章内字体都是同一个字号，段落间的间距也都不一样，这样读起来很难整体把握一本书的整体大概和脉络。</p>

<h2>《有鹿来：京都的日常》</h2>

<p><img src="https://img3.doubanio.com/lpic/s28362530.jpg" alt="有鹿来：京都的日常" /></p>

<p>推荐指数：★★★★★</p>

<p>忘了是搜什么和日本相关的书，这本也出现在了推荐列表里。第一次才知道了这个作者：苏枕书。不知道是不是笔名，但是一直以为ta是一个中年男性。后来查了一下，原来是一位女作家，而且非常年轻，出生于1986年，在中国读完法律本科，到京都大学继续攻读。</p>

<p>在本书中，作者以居住、旅行和学习为主线，介绍了京都的方方面面，有美食、生活习俗、古刹和名山。即使你没去过京都，也都能从其温柔秀美的文字中体会到京都的静、京都的美，以及京都的古香古色。</p>

<p>作者会带你散步哲学之路，感受到近代文豪的气息；你也可以跟随作者攀爬吉田山，在半山腰的朋友书店挑选几本中意的书；在游完真如堂后，再到金戒光明寺的法然院墓地，瞻仰一下谷崎润一郎的寂字碑；当然，作者也没忘记介绍著名的大文字山和五山送火。</p>

<p>作者对古代艺术也很熟悉和喜爱，因此本书也讲到了有邻馆、泉屋博物馆等博物馆和美术馆。如果你喜欢日本文化，也可以跟着作者了解一下日本的澡堂（钱汤），如何学习花道，岁末年初，日本仍在延续的祭祀和庆典活动。</p>

<p>相比作者在历史、地理和文学方面的深厚功底，其在建筑、佛教和植物方面的知识也让人赞叹。别说日本的花草了，就算是中国北方常见的花木，我也说不上三五种，而作者罗列起来，经常是五六个起，多则十几种，这么多花都能叫上名字，也需要花些时间来记忆了。</p>

<p>至于书名的“有鹿来”，大概由于这段记述吧：</p>

<blockquote><p>去年初夏，下学回来的夜里，漫天星辰，凉风可喜。遂往屋后山坡散步。四围静寂，人家灯火已暗。忽闻群犬争吠，又闻一阵急促的脚步声。完全猝不及防地，眼前转角处竟刹那现身一头大鹿，鹿角巍巍，前蹄腾起，健壮貌美。似乎有一瞬对视，我惊呆，鹿也惊呆，飞快回身，消失在黑暗山影中，复一片犬吠。待我回过神，追去两步，早已行迹杳然。</p></blockquote>

<p>书中有彩色插图，建议买纸版阅读。</p>

<h2>《京都古书店风景》</h2>

<p><img src="https://img1.doubanio.com/lpic/s28265377.jpg" alt="京都古书店风景" /></p>

<p>推荐指数：★★★★☆</p>

<p>此书作者和上面的《有鹿来：京都的日常》同为苏枕书，作为法律专业学生、作家，作者自然对买书别有一番感悟。本书就是作者在京都求学期间，对京都比较有名的古书店的介绍。</p>

<p>100多年前，很多中国人赴日求学，很多人都到过京都，京都的古书店也有很多和中国有关的书籍和友情。作者除了经常去这些书店买书，还以书为纽带和很多书店的老板成为了朋友，时常往来、互相惦记，遇到经营不善或者后继无人而不得不闭店的时候，作者也不尽扼腕。</p>

<p>实体书店不好做，日本中国都类似。而日本的旧书还有回收行业，只要有价值，总会再次被发现；而国内很多好书估计在第一代主人用过之后，可能都被当做废品回收了，也不尽让人惋惜。</p>

<p>如果你有悠长的假期，想去京都体验一下浓厚的文化氛围和历史积淀，那么本书可能会对你有所参考，所以4星推荐。</p>

<p>和上一本一样，书中有彩色插图，建议买纸版阅读。</p>

<h2>《门外汉的京都》</h2>

<p><img src="https://img1.doubanio.com/lpic/s10773674.jpg" alt="门外汉的京都" /></p>

<p>推荐指数：★★★★★</p>

<p>如果说《有鹿来：京都的日常》是偏记事的抒情散文，则本书可以认为是偏诗歌性质的抒情散文。两书风格迥异，不过都堪称唯美。《有鹿来：京都的日常》文风清新爽朗，作者自造了很多词汇，而《门外汉的京都》则显得厚重老成，白话文夹杂了一些简单的文言文。</p>

<p>本书叙事风格也有点半游记的形式，毕竟作者最喜爱的城市估计就是京都了。作者游历过的城市颇多，而专门成书者，除了故乡台北，也就唯有京都了。</p>

<p>竹篱茅舍，流水长墙，读着作者笔下的京都，宛如自己也身在其境：</p>

<blockquote><p>“这也是为什么老来要住京都，太多的风流蕴藉之事，灯宵月夕，雪际花时，你皆可扮上一个动作，披上一片布幔，挥动一件道具，而数百年来中国早已失落的雅观风致，或在你的履践中，不自禁地消受了。”</p></blockquote>

<p>书中有插图，虽是黑白，仍建议买纸版阅读。</p>

<h2>《免费:商业的未来》</h2>

<p><img src="https://img1.doubanio.com/lpic/s3970994.jpg" alt="" /></p>

<p>推荐指数：★★★★★</p>

<p>对作者而言，该书始于《长尾理论》一书没有讨论完的话题。在《长尾理论》一书中，主要探讨了在商品种类应有尽有，我们的选择空间除了热门商品之外还有无限大的可能性时，出现的新型消费者需求。而互联网上无穷大的货架空间使得长尾式多样化的产品销售成为可能。而那些不收费的商家是如何赚得盆满钵满？这到底是怎么出现的，又会如何发展？本书主要围绕着免费经济和免费经济体制进行了论述。</p>

<p>受免费策略影响最大的产业莫过于媒体、软件、游戏、音乐和电影届了。本书则列举了相关行业的大量实例，说明了如何在受到互联网技术的威胁、影响下，如何适应潮流，改变销售和盈利的策略，如何应对盗版问题，如何开创新市场，发展新业务领域。其实我们国家已经有了很好地例子了，比如唱片行业，靠卖CD已经很难盈利，所以他们改变了传统的出专辑的方式，将单曲放到网上供人免费下载、播放，而歌手和乐队则由此提高知名度，公司则可以通过巡演、广告、参加各种商业活动来获得利润。</p>

<p>如作者所述，在20世纪免费是一种强有力的推销手段，而在21世纪它已经成为一种全新的经济模式。</p>

<p>在本书中作者还总结了免费的4种模式，如果你是创业者，在收费问题上有所疑虑的话，可以参考本书中的一些结论和实例。</p>

<p>免费的4种模式：</p>

<ul>
<li>1.直接交叉补贴</li>
</ul>


<p>典型代表为吉列剃须刀，刀架虽然免费，吉列却可以从刀片上赚到钱。</p>

<ul>
<li>2.三方市场</li>
</ul>


<p>经济学家称这种模式为“双边市场”，在这种市场系统中，第三方付费来参与前两方之间的商品交换。用户可以获得免费报纸，而广告商则向发行商付费。</p>

<ul>
<li>3.免费加收费</li>
</ul>


<p>免费加收费模式（Freemium）这个说法是由风险资本家弗雷德·威尔逊创造的，也是在网络生存空间中最常见的商业模式之一。比如网盘你可能得到5G的免费空间，如果你的文件太多，则需要付费购买高级的套餐来获得更多的存储空间。</p>

<ul>
<li>4.基于利他主义的免费服务</li>
</ul>


<p>包括礼品经济和劳动交换等，以维基百科等为代表。</p>

<p>“非货币经济：货币不起作用的地方，什么管用？”这一章比较有意思，主要讲了和货币经济相对应的注意力经济和声誉经济，以及礼物经济，去了解一下人们为什么热衷于投入到没有经济报酬的活动中去：社团、相互扶持、个人发展及自我实现。</p>

<h2>《互联网+战略版：传统企业，互联网在踢门》</h2>

<p><img src="https://img1.doubanio.com/lpic/s28108417.jpg" alt="互联网+战略版：传统企业，互联网在踢门" /></p>

<p>推荐指数：★★★★★</p>

<p>说个可能不太合适的例子，老家农村有很多暴发户，其中多数受教育不高，其对子女的期望就是上大学。其实这些人不知道如何去教育、辅导子女，只是知道上大学才有文化、更有前途。</p>

<p>传统企业也有点类似，面对蓬勃发展的互联网，越来越多的线上线下、新兴和传统的结合，大家都感到有一种莫名的危机感和恐惧，惊呼狼来了。然而，这些传统企业却不知道如何防守才能守得住。不，确切的说，他们应该以攻为守。传统企业和互联网企业就像围城，里面的要出去，外面的要进来。</p>

<p>“印刷术、电信技术（电报和电话）、互联网，历史上，新型通信技术与新型能源系统的结合预示着重大经济转型时代的来临”。这个观点很好，值得创业者关注，我觉得还可以加上一条，就是人和人之间的沟通方式。</p>

<p>而互联网的出现，尤其是移动互联网的迅速普及，给传统商业带来巨大的冲击。管理学大师彼得·德鲁克说：互联网消除了距离，这是它最大的影响。而互联网商业的目的之一，就是要消灭一切基于信息不对称的商业模式。</p>

<p>传统企业要想在互联网大潮中得以幸存，首先就是要转型，先革自己的命，认清趋势，放弃原来基于信息不对称的既得利益，利用专业知识，结合新的互联网技术，寻找新的价值点和增长点。</p>

<p>书中，作者还给出了一个有意思的建议：</p>

<blockquote><p>我曾经总结过一个简单的互联网创业的行业方向：（1）找一个利润高到你恨的行业；（2）这个行业赚的是基于信息不对称的钱；（3）不涉及国家垄断的战略资源。</p></blockquote>

<p>我在想，为什么现在配个眼镜怎么还得去潘家园呢？</p>

<h2>《超预期 小米的产品设计及营销方法》</h2>

<p><img src="https://img1.doubanio.com/lpic/s28014459.jpg" alt="超预期 小米的产品设计及营销方法" /></p>

<p>推荐指数：★★★★★</p>

<p>本书从小米的创建开始，以其发展历程为主线，分析了小米的成功要素，其结论之一就是开发超预期的产品。</p>

<p>我虽然也觉得小米的饥饿营销不太让人舒服，但是雷军和小米的战略思想还是其成功地关键要素，那就是如书名所示，“超预期”，超过用户的预期，“口碑的真谛是超预期，之后超预期的产品才会产生口碑”。</p>

<p>雷军的五大军规：</p>

<blockquote><p>第一条：懂得顺势而为，绝不要做逆天而动的事情；第二条：颠覆创新，用真正的互联网精神重新思考；第三条：人欲即天理；第四条：广结善缘；第五条：专注，少就是多。</p></blockquote>

<p>黎万强总结的“参与感三三法则”：</p>

<blockquote><p>“三个战略：做爆品，做粉丝，做自媒体；三个战术：开放参与节点，设计互动方式，扩散口碑事件。”</p></blockquote>

<p>雷军说：“我觉得整个互联网公司把用户体验、用户口碑一步一步推到极致，这才是互联网给传统产业带来的最重要的思想。”在互联网时代，一切行业都是服务业，所有公司都是服务公司。书中举了海底捞的例子，由于海底捞提供了超出用户预期的服务，所以将普通消费者转化成了品牌粉丝。有人说在海底捞吃饭的客人想打包没吃完的西瓜，服务员会给你包好整个西瓜让你带回家，正是这些细节打动了用户的心。</p>

<p>“所以，我觉得要想做出成功的产品，除了产品本身要好之外，还需要做好服务，做好品牌。不过这些只是做出一个好产品、好公司的必要条件，而不是说满足这三点，公司就一定能成功。”</p>

<p>最后分享一个雷军提出的“四步请客法”：</p>

<blockquote><p>要把一个客人请到一定要花4次的时间：第一步，你要提前一周至两周跟客人打电话说明情况；第二步，要提前一周给客人寄请柬或发传真；第三步，要提前一天跟客人做确认；第四步，离请客时间还有半小时，要再给客人打电话确认。这样，一般客人都会到，如果他不到的话，那他就欠了你天大的人情，下次你打一次电话他就一定会来。</p></blockquote>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[为什么你的简历投出之后渺无音讯？]]></title>
    <link href="http://liubin.github.io/blog/2016/03/29/engineers-resume/"/>
    <updated>2016-03-29T22:02:59+08:00</updated>
    <id>http://liubin.github.io/blog/2016/03/29/engineers-resume</id>
    <content type="html"><![CDATA[<p>很多人在向心仪的公司投了简历之后，渺无音讯，犹如石沉大海一般，不禁感叹有些公司只会看学历、看背景，以“貌”取人。</p>

<p>殊不知，如果你仔细反省一下，可能确实是个人达不到用人单位的要求，与目标职位不匹配；而另一种情况就是你自己的能力并未从简历中体现出来。简历筛选者也许收到了数以百计的简历，花在单一简历上的时间自然不多，如果你的简历中没有什么让人眼前一亮的东西，又怎么会得到面试机会？如果是因为简历写的不好而失去面试机会，有多可惜？</p>

<p>所以，这里大叔想简单介绍一下大叔认为的软件工程师简历中应该注意的一些事。</p>

<h2>简历风格</h2>

<p>首先，你需要知道写简历的目的，你需要在你的简历中透露出你想传递给阅读者的消息是：一、我的经验和能力适合这个职位，满足这个职位的要求，二、我非常希望得到此职位。这是简历的中心思想，所有的内容都要围绕这2点来展开。</p>

<p>我们先来看看一份简历的基本结构和要点。</p>

<h3>结构清晰</h3>

<p>简历一般由个人基本情况（姓名、联系方式等）、教育情况、工作经历、专业技能、个人PR等部分组成。</p>

<p>从排版上讲，段落要清晰、错落有致。可以通过不同的段落、字体大小、左右对齐、空行甚至图表等进行分割，让人一眼就能看出各部分的不同、各部分的主旨。通篇同样大小的字体，挤在一块容易让人抓不住重点，且容易疲劳。</p>

<p>在篇幅上，最好不要超过2-3页（根据工作经验多少可能会不一样）。一定要在写简历的时候换位思考：如果我是面试官，我会一字不差、认认真真读完这几页简历么？面试官会对我们的这个经验感兴趣么？要是问起我的这个项目中我干了什么、如何解决的这个问题，我该如何回答？</p>

<h3>语句通顺、言简意赅</h3>

<p>简历行文应该条理清楚、语句通顺。相信各位一定有过这样的经历，在看完某简历之后，暗暗感叹这人语文应该是体育老师教的吧？</p>

<p>其次，就是言简意赅、一字千金，各种口语、助词、甚至形容词，能省则省，千万别出现什么“委以重任”、“不负众望”甚至“力挽狂澜”的词汇，简历不是演讲，不需要煽情，这不是TV show，像什么“我劝天公重抖擞”类似的用语，千万不要出现在简历中。</p>

<p>简历有点类似英语考试的作文题，有时候适用减分法则，就是你写多了，反而会带来负面影响，降低简历筛选通过的几率。</p>

<p>另外老生常谈，就是尽量避免使用“精通”等词汇。</p>

<h3>无错别字、术语正确</h3>

<p>无错别字、标点符号运用得当也是简历的最基本要求。然而很多简历都存在这个问题。这应该是大家不重视语文或写作，以及计算机、智能机普及所带来的负面影响。这个也没什么好的办法，只能自己认认真真多检查几遍。</p>

<p>除了汉字，还有各种英文的专业术语大小写问题也需要额外注意，比如Java、MySQL这样的词汇，你能写对么？甚至更较真来说，WiFi和Wi-Fi哪个才是正确的写法？</p>

<h2>简历基本内容</h2>

<p>看完了简历整体要求，再来看看简历的主要内容。</p>

<h3>Cover letter（应聘动机）</h3>

<p>Cover letter可能算是舶来品，有最好。Cover letter主要可以表述为什么我非要投简历给你们、我是如何希望得到这份工作。比如我喜欢你们公司的开发方式、公司环境，或者你们的工作内容是我非常感兴趣、是我想深入研究的领域等等。</p>

<p>总之，要给简历审查者一种亲近、热爱该职位的感觉。Cover Letter贵在真诚。</p>

<h3>工作经历和项目经历</h3>

<p>这是简历中非常重要的两部分内容。</p>

<p>工作经历可以看出一个人曾经在什么地方工作过，每个公司呆了多少年，进而初步（大多数人都会这样）判断出这个人的水平和稳定性。一个人如果6个月跳槽一次，那么也大致可以判断出此人要么是水平太差，要么是工作态度有问题。</p>

<p>这一部分最好按时间倒叙来写，而且要有主有次，不要千篇一律，不分重点，以提高简历阅读者的效率，加深对应聘者的印象。</p>

<p>介绍项目经历的时候，要时刻提醒自己：我的经历和技能表现的是否和目标职位十分匹配？</p>

<p>如果你过去的工作经验和目标职位非常相像，那么可以重点来写一下这部分，扬长避短。否则的话可以重点写一下最近公司的状况。</p>

<p>项目经历应该包括的信息如下：参与时间、所处角色、主要工作内容和相关技术细节。相对枯燥的描述，一些数字和实例可能更容易让人理解。比如如果你是开发经理，你可以介绍一下团队成员有几人，如果你是运维，你可以介绍一下有多少台服务器，多少台数据库服务器，负载均衡用的什么、消息队列用的什么等。</p>

<h3>自我PR（自我评价）</h3>

<p>所谓PR，即公共关系，即自我包装、自我营销。</p>

<p>在国内，很少有人把PR和个人简历联系起来，有些国家自我PR算是简历的一个组成部分，甚至面试过程中面试官都准备一个环节专门让应聘者进行自我PR。</p>

<p>这一部分是1%和99%的区别，即大部分都流于形式、千篇一律，几乎每个人都会写上“有责任心”、“认真负责”、“良好的团队协作意识”等，在面试官看来，会条件反射式的惯性忽略。</p>

<p>而优秀的另外1%，则会立即抓住面试官的眼球，相比更多概括性的描述，举出实例更好。比如你说你认真负责，有哪些表现？你说你热爱技术，在哪些领域下足了苦工？</p>

<h2>简历中的补充信息</h2>

<p>此外，作为软件工程师来说，简历中添加一些额外的专业信息，都会成为加分项，增加面试的机会。</p>

<h3>技术博客</h3>

<p>技术博客除了能看出应试者的涉猎范围、对技术的痴迷程度以及技术水平之外，也能看出一个人持之以恒的个性、独自钻研的能力和写作能力。写文章不是工程师的天职，如今却也算得上是工程师的竞争优势。</p>

<h3>GitHub</h3>

<p>我们以在世界最大的同性交友网站为骄傲。不过以我的经验来看，如果一个人在GitHub上的粉丝很多，项目获得的star也很多，基本找工作都是不需要投简历的；相反，大多数人的GitHub数据都很一般，有一些人的提交还以更新blog为主。</p>

<p>甚至也不乏造假者，即将别人的仓库拿下来，删除提交信息，自己重新提交。总之，挖掘GitHub信息需要耐心。</p>

<h3>社区活动</h3>

<p>如果一个人经常参加各种技术社区活动，可以说明这个人：</p>

<ul>
<li>比较喜欢钻研技术</li>
<li>可能会擅长交流</li>
<li>分享精神</li>
</ul>


<p>因此可以从这方面对候选人进行技术和个人性格上进行考察。</p>

<p>也有很多人找工作根本不必事前准备简历，而是完全通过社区的关系来决定工作，简历只不过是作为公司手续上的备案资料而已。</p>

<h3>社交账号</h3>

<p>社交账号比如豆瓣、Twitter等。微博也可以，不过Twitter还能顺便考察一下科学上网的能力，能科学上网的软件工程师一般来说效率都会高很多。</p>

<h3>业余项目</h3>

<p>如果你有一些在工作之余开发的项目，也不妨列出来，即使用户不多、知名度不大。业余项目至少说明了你的动手能力和技术基础，对重视此因素的面试官来说非常容易加分。</p>

<h3>为企业定制</h3>

<p>如果可能，最好针对不同的应聘公司和职位，对简历进行一些定制，以着重强调自己和应聘职位在能力和经验（比如电商行业、对Redis特别熟等）上的匹配程度，也能增加面试的机会。</p>

<h2>关于发送简历</h2>

<p>最后，说完了简历中的核心内容，再说一下和内容无关的一些注意点。</p>

<h3>文件名</h3>

<p>千万别将简历命名为“个人简历.pdf”或者"新建Microsoft Word文档.docx"这样的名字。建议将文件名命名的更有意义，比如“张三-6年经验-Java开发”，这样在招聘方保存了多份简历的时候，也能快速的查找、定位简历。</p>

<p>此条建议也同样适用于邮件标题。</p>

<h3>文件格式</h3>

<p>因为你不知道简历阅读者使用的是什么操作系统，用的哪种办公软件，所以简历格式最好使用PDF格式保存，你知道PDF的P代表什么意思么？</p>

<p>随着越来越多的开发者开始使用OS X和Linux，如果你是从62job、神州英才这样的网站下载的简历，可能就不太走运了。因为很可能打开后格式错乱，有些人可能熟悉如何解决这类问题，而有些人则很可能因此而错过你的简历。</p>

<p>所以文件格式尽量用PDF的，或者使用在线简历。</p>

<h3>发送邮箱地址</h3>

<p>正式发送简历之前，最好先给自己发送一封，看看你的发件人是不是显示的真名，尤其是使用类似QQ邮箱这样的免费邮箱的时候，有可能你的邮箱发送者是你的昵称，这样也很容易被面试官忽略，甚至如果你使用的昵称比较另类，反而会引起人的反感，这样你的简历还没看，就先被减了一半的分数。</p>

<p>发送之前再确认两点：附件是否已经上传、标题是否已经填写。</p>

<h3>简历发给谁最重要？</h3>

<p>简历发给谁也很重要，有时候你会从多个渠道看到同一个职位的招聘信息，比如传统招聘网站、技术社区或者朋友圈，这时候，发给所应聘职位的直接领导，远比发给hr@xx.com和jobs@yy.com这样的邮箱好得多。</p>

<p>一般来说熟人推荐要比海投获得面试的机率高很多。</p>

<h2>结束语</h2>

<p>简历贵在简和精，你所看到的本文，原来有现在的两倍长，能删则删，删到不能删。</p>

<p>最后，祝你好运。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Cookpad近期微服务经验总结]]></title>
    <link href="http://liubin.github.io/blog/2016/03/16/microservice-at-cookpad/"/>
    <updated>2016-03-16T23:54:31+08:00</updated>
    <id>http://liubin.github.io/blog/2016/03/16/microservice-at-cookpad</id>
    <content type="html"><![CDATA[<p>译者注：</p>

<h2>关于版权</h2>

<p>本文首发于Cookpad公司技术博客<a href="http://techlife.cookpad.com/entry/2016/03/16/100043">《クックパッドにおける最近のMicroservices事例》</a>，本译文已获得原作者基于<strong>禁止商业用途</strong>的许可，有转载需求请自行联系原作者，责任自负，因转载出现的任何问题皆与本站和本人无关。</p>

<h2>关于Cookpad介绍</h2>

<p>Cookpad是日本最大的在线菜谱分享公司，上市企业；这都不算啥，说到Rails，日本人没有不知道Cookpad的，可以说Cookpad将Rails用到了极致，相信他们在微服务方面的经验也能为我们带来帮助。</p>

<p><em>以下是正文</em></p>

<hr>


<p>大家好，我是Cookpad技术部的吉川。</p>

<p>最近微服务这个概念很流行，其技术也逐渐变得系统化、结构化。另一方面就是关于微服务概念上或者抽象的内容比较多，很难让人对微服务有一个具体的印象。</p>

<p>Cookpad公司的技术博客在1年半之前已经对 <a href="http://techlife.cookpad.com/entry/2014/09/08/093000">Cookpad和微服务</a> 进行了介绍。我们也将当时公司内部使用的工具Garage进行了 <a href="https://github.com/cookpad/garage">开源</a> ，现在Cookpad的系统已经比当时有了更大的发展。</p>

<p>所以，在前几天的 <a href="http://connpass.com/event/26178/">Microservices Casual Talks</a> 上，我们也对Cookpad最近关于微服务的使用经验进行了分享。</p>

<p>这是当时的 <a href="https://speakerdeck.com/adorechic/how-microservices-are-linked-at-cookpad">演示幻灯片（日文）</a>。<em>打不开的话自备工具</em></p>

<script async class="speakerdeck-embed" data-id="cd8a946838714932932c892aa3609241" data-ratio="1.33333333333333" src="//speakerdeck.com/assets/embed.js"></script>


<p>本文并不打算对微服务一些抽象难懂的概念进行解说，而是更专注于具体实例。本文应该会对那些理解一些微服务的基本概念，而实际中又不知道如何应用的人有很大帮助，因此我们决定通过本博客再来进行一下介绍。</p>

<h2>服务粒度</h2>

<p>大家常说微服务就是职责单一的服务，但是单一职责又需要具体到什么地步才算单一呢？Cookpad的服务主要分为3种类型。</p>

<h3>用户服务</h3>

<p>根据产品关注点的分类。一个根本原则是微服务需要根据业务领域来划分。Cookpad提供了包括美味料理、料理教室、料理视频、Cookpad博客、大家的咖啡等在内的众多服务。</p>

<p><img src="http://liubin.github.io/images/2016/03/cookpad-micro-services/p1.png" alt="" /></p>

<p>尽管大多数服务都采用了Rails进行开发（也有一部分服务只有手机客户端），但是每个团队的特点都不一样。比如ES6的话既使用了React.js，也使用了CoffeeScript；有的团队使用了Rubocop，有的则没有使用。</p>

<p>由于产品的不同，目标用户也不太一样，因此我们可以很灵活地选择所使用的技术。如果能够很方便地使用其他Domain的model，则很容易产生协同效应。换句话说，即使最终用户看起来服务千变万化，但是从公司内部的其他服务来看，使用的是一个统一的Model。</p>

<h3>View服务</h3>

<p>Domain model相同但是展现形式不一样。</p>

<p><img src="http://liubin.github.io/images/2016/03/cookpad-micro-services/p2.png" alt="" /></p>

<p>从形式上很像 <a href="https://www.thoughtworks.com/radar/techniques/bff-backend-for-frontends">BFF(Backend for frontends)</a> 模式，但是由于Cookpad需要兼容各种各样的设备，因此同一个domain model需要以不同版本（<em>这里的版本不是指alpha、beta这样的版本号，而是类似个人版、商业版这样的概念 &ndash; 译者注</em>）的形式来提供。OEM版就是一个例子，提供的东西是一样的，但是却以不同版本的UI或者用户系统来提供服务。</p>

<h3>共通基础服务</h3>

<p>指的是为各种服务提供功能的服务。比如下面这些都是共通服务：</p>

<ul>
<li>OAuth provider</li>
<li>结算</li>
<li>Push通知、邮件服务</li>
<li>活动</li>
<li>各种日志</li>
<li>敏感（个人）信息存储</li>
<li>视频</li>
</ul>


<h2>服务之间的集成</h2>

<h3>RESTful Hypermedia API</h3>

<p>微服务之间如何通信一直以来都是一个值得讨论的话题。虽然我们认为一般都会通过HTTP使用REST API，但是应该也有人会选择Protocol Buffers或者Thrift这样基于RPC的方式。</p>

<p>Cookpad微服务之间的通信采用了 <a href="http://techlife.cookpad.com/entry/2014/09/08/093000">基于Garage的RESTful Hypermedia API</a> 方案。在之前的博客中我们已经介绍过Garage了，这里就略过了。在这篇博客中，我们会对一些Garage解决不了的问题进行介绍。</p>

<h3>并行处理和容错</h3>

<p>服务之间的集成越来越多，带来了两个问题。第一个问题是性能开销。一体化应用的话只需要连接到数据库把数据取回来就可以了，但是如果只是将这个功能采用REST API来实现的话，性能开销会变大。为了提高吞吐量，需要做很多努力，就微服务架构来说，调用方在发出请求之后，将会进入单纯的IO等待状态，非常适合采用并行处理的方式。因此对服务进行合适粒度的拆分，各服务的责任更独立，更容易采取并行处理的方式。</p>

<p>第二个问题是容错。如果某一服务阻塞了，等待该服务超时的客户端也会被阻塞，进而导致阻塞的连锁反应。好不容易将服务拆分了，当然不想轻易地出现这样的故障影响正常运行。</p>

<p>或者将请求并行来处理，或者进行重试，在超过一定数量的错误发生后停止对该服务的请求。我们采用 <a href="https://github.com/cookpad/expeditor">Expeditor</a> 实现了该需求。熟悉这些需求的人可能已经想到了，这就是 <a href="https://github.com/Netflix/Hystrix">Netflix/Hystrix</a> 的Ruby版。当然现在还没有Hystrix那么多功能，但是一些基本功能，比如有依赖关系的Asynchronous Execution和Fallback、Retry、Circuit Breaker都已经实现了。</p>

<h3>服务间的测试</h3>

<p>REST API集成的问题之一就是API的兼容性。</p>

<p>通常在CI能够发挥作用的测试级别的测试中，发给其他服务的请求都是stub的形式，不能确认是否有不兼容该服务接口的变动混入。使用Protocol Buffers这样方式的话，由于需要共享proto文件，可能不会出什么问题。而使用REST API的方式进行集成的话，也有一种使用JSON Schema的方法。不过由于是Ruby + HTTP风格的文化，相比使用类型系统进行管理的开发风格，我们的工程师们更习惯于进行动态测试这种风格。这也是 <a href="http://techlife.cookpad.com/entry/2015/10/09/125108">Rack::VCR</a> 产生的背景。但是使用各服务自己的CI来保证兼容性的话，如果服务之间的构建频率不一致，在Cookpad这样发布非常频繁的公司，很可能会出现在发布之后才能发现API不兼容的问题（<em>即发布之后API提供方的API才检测到调用方的调用有问题 &ndash; 译者注</em>）。因此我们决定转向 <a href="http://techlife.cookpad.com/entry/2016/01/04/094705">Consumer-Driven Contract testing</a> ，现在已经迁移到 <a href="https://github.com/realestate-com-au/pact">Pact</a> 了。</p>

<p><img src="http://liubin.github.io/images/2016/03/cookpad-micro-services/p3.png" alt="" /></p>

<p>这样，如果客户端破坏了API的兼容性，会被提供方（provider）的CI会检测到，从而防止不兼容的修改被发布。</p>

<h3>服务间日志的事务关联</h3>

<p>服务分开之后，日志追踪会变得很困难。特别是错误日志，当一个服务发生错误时，在调用方发现了错误的话，如果在被调用方不能追查到发生了什么错误的话，就很难找到问题的根本原因。一般的解决方式是为请求设置一个ID，以此来对各服务中的调用进行分析。特别是Rails默认就支持X-Request-Id HTTP头，没有ID的话也会自动设置一个。而且我们的各服务通过使用 <a href="https://github.com/cookpad/garage_client">GarageClient</a> 进行集成，GarageClient会在发起请求时设置X-Request-Id并将这个ID传递下去。</p>

<p>Cookpad错误日志管理采用了 <a href="https://github.com/getsentry/sentry">Sentry</a> ，错误日志通过将请求ID作为标签来进行管理。</p>

<h2>服务的运行环境、配置关联</h2>

<p>随着服务的增多，给基础设施也带来了很大的压力。Cookpad本来使用的配置管理工具是Puppet，随着模块的增多，操作也变得复杂，同样的应用程序，有时还得区分是作为在线应用服务使用还是作为批处理作业使用来分开管理，总之会出现各种复杂的场景。</p>

<p>现在除了一部分巨型Rails应用程序以外，包括测试环境和生产环境在内，Cookpad几乎所有的应用都跑在Docker中。</p>

<h3>构建pipeline</h3>

<p>各服务的修改合并代码之后，就会启动CI，测试通过后构建新的Docker镜像。这个新的Docker镜像会自动部署到staging环境中。同时生产环境使用的也是这个镜像，而且没有为批处理作业和在线服务准备不同的环境，只需要拉取最新的镜像运行即可。当然这个镜像也可以在开发者本地运行。在Scale out或者进行渗透测试需要创建独立的运行环境的时候，采用Docker可以快速部署。</p>

<h3>部署</h3>

<p>Cookpad的Docker运行环境是ECS，实际部署的时候会将容器和ELB结合起来一起配置、注入环境变量等操作。<a href="https://github.com/eagletmt/hako">Hako</a> 就是一个这样能将部署过程中各种步骤连接起来的一个工具。有了Hako，在第一次部署的时候可以自动创建ELB，使用Route53设置域名指向，而以前这些工作都需要基础设施工程师单独一个个的去设置。利用这种机制，在生产环境下，<strong>一个应用程序对应一个ELB</strong>，在测试环境下，一个ELB则可以对应多个应用程序，进行非常灵活的设置。</p>

<h3>配置管理</h3>

<p>即使是同一个镜像，DB连接信息、API key等也不同，都依赖于具体的环境。Hako支持环境变量注入功能，这在一定程度上可以进行环境变量管理工作，但是需要安全处理的信息则使用了 <a href="https://github.com/sorah/etcenv">etcenv</a> 和 <a href="https://github.com/sorah/etcvault">etcvault</a> 来进行管理。后端存储是etcd，不过由于etcd没有ACL管理功能，因此数据都采用了加密后存储的方式。<code>etcenv</code> 有一个UI工具 <a href="https://github.com/sorah/etcweb">etcweb</a> ，可以通过Web进行管理。</p>

<h2>公司级别的支持</h2>

<p>采用了微服务架构，团队也随着服务而独立。不同团队之间的协作方法，全体的决策方式等也逐渐发生着变化。</p>

<h3>技术领域课题共有会</h3>

<p>各团队的独立性越高，对其他不同团队的具体工作内容就越难以把握。各自业务固有的烦恼也会增加。由此会出现很多问题，比如有一些共通难题，如果团队内部认为只有自己才有这个烦恼的话，就不会将这个问题提到公共层面，而实际上隔壁的团队也许早已经解决了这个问题。因此Cookpad各团队的leader和基础设施、共通服务的工程师每个月都会聚到一起通过会议的方式来讨论一些共通话题。</p>

<p>在这个会议上各个团队会提出自己目前遇到的问题，如果一些问题已经有了解决方案，则将解决方案在公司范围内共享，如果没有解决方案，则会选择一个合适的团队专门负责来解决这个问题。此外对全局都可能带来影响的需求变更也会拿到会上讨论。这样就会发现很多问题，比如有些事自己认为不是问题，可是大家都在为此烦恼；或者自己认为大家都在使用的服务实际上并没有人用，自己却还努力在维护。</p>

<h3>共通基础技术工程师</h3>

<blockquote><p><em>译者注：即公司内部开发公共服务的工程师</em></p></blockquote>

<p>随着团队变得多样化，有的团队有擅长共通基础的成员，有的则没有；有的团队新产品较多，所以对公司内部最新的共通基础技术都很了解，而有的团队则对公司的共通基础技术认识不足，甚至还有重复制造轮子的现象。也有一些团队根本没有精力去对共通基础技术进行改善。</p>

<p>所以Cookpad将共通基础团队的成员分配给各个服务，作为各个团队的共通基础技术工程师。一个人对应多个服务，而不是专属于某一服务团队，所以他们可以称为是团队的外部共通基础技术工程师。共通基础技术工程师使用服务团队的协作（Chat）工具，谈论各种话题，有时候也全身心投入开发环境的准备工作中。</p>

<h2>总结</h2>

<p>本文我们对Cookpad近期在微服务方面的使用心得进行了介绍。Docker带来的可移植性给公司内部的开发风格带来了很大的改变，加速了微服务的落地。同时随着Pact等工具的出现以及公司层面的支持，Cookpad的开发风格在这一年有了显著的进步。</p>

<p>有了微服务各个团队也更能将精力集中在本职工作上。集中精力在产品上，也就是相当于集中精力在用户身上一样。根据产品的不同选择最合适的技术，团队成员对自己的产品负责，可以自己主导产品开发。</p>

<p>这里我们只是对Cookpad中微服务的概要进行了介绍，后面我想可能还会带来对Hako或者Pact等工具的介绍。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[时序列数据库武斗大会之KairosDB篇]]></title>
    <link href="http://liubin.github.io/blog/2016/03/12/tsdb-kairosdb/"/>
    <updated>2016-03-12T23:24:46+08:00</updated>
    <id>http://liubin.github.io/blog/2016/03/12/tsdb-kairosdb</id>
    <content type="html"><![CDATA[<h2>简介</h2>

<p>按照官方的说明，KairosDB是一个“Fast Time Series Database on Cassandra”，即基于Cassandra的告诉时序列数据库。</p>

<h2>特点</h2>

<h3>数据采集</h3>

<p>数据可以通过多种协议写入KairosDB，比如Telnet的按行写入，HTTP API，Graphite以及批处理导入。此外，还可以使用或者自己编写插件。</p>

<h3>存储</h3>

<p>KairosDB 采用了 Cassandra 作为数据存储方式，Cassandra 也是一个比较流行的NoSQL数据库，很多开源软件基于此数据库。</p>

<h3>Rest API</h3>

<p>KairosDB提供了REST API，已完成对metric名称，tag等的查询，当然，也少不了存储和查询数据点（data points）。</p>

<h3>自定义数据类型（Custom Data）</h3>

<p>KairosDB支持存储和聚合自定义数据类型。默认情况下KairosDB支持long、double和字符串的value，这比OpenTSDB要丰富一些。</p>

<h3>分组和聚合</h3>

<p>作为数据分析系统，分组和聚合则是必不可少的功能。
<a href="http://kairosdb.github.io/docs/build/html/restapi/Aggregators.html">KairosDB的聚合（也就是down samples）</a>功能，支持的标准函数有min、max、sum、count、mean、histogram、gaps等，而且都非常实用。</p>

<p>比如percentile，可以计算一个指标值大概的百分比位置，非常适合存储类似“你打败了xx%的人”这种需求场景。</p>

<h3>支持工具</h3>

<p>KairosDB提供了进行数据导入导出的命令行工具。根据官方文档的说明，在一台分配了2Gig内存的SSD Cassandra上，1秒钟能导入  13万条数据。</p>

<h3>插件机制</h3>

<p>KairosDB也提供多种基于Guice的插件机制来进行扩展（data point监听器，数据存储，协议处理等。）</p>

<p>KairosDB是从OpenTSDB fork过来的，因此最初它是支持HBase的，不过现在HBase已经不能完全支持KairosDB所需的特性，将来会取消对HBase的支持。</p>

<h1>入门KairosDB</h1>

<h2>安装KairosDB</h2>

<p>这里我们以当前最新的1.1.1版本为例进行说明。</p>

<p>首先，需要确保你的JAVA_HOME已经设置好了，且Java版本高于1.6。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ echo $JAVA_HOME
</span><span class='line'>/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home</span></code></pre></td></tr></table></div></figure>


<p>然后需要到<a href="https://github.com/kairosdb/kairosdb/releases">GitHub</a>上去下载安装包。我用的是OS X系统，因此我选择了<a href="https://github.com/kairosdb/kairosdb/releases/download/v1.1.1/kairosdb-1.1.1-1.tar.gz">kairosdb-1.1.1-1.tar.gz</a> （注意：点击这个链接即可下载）</p>

<p>解压后可以看看它的配置文件<code>conf/kairosdb.properties</code>，有一些东西适合OpenTSDB一样的，比如4242端口。</p>

<p>KairosDB集成了jetty，你可以通过jetty访问WEB UI，而且还支持添加SSL支持，这样安全性上比OpenTSDB高了一个层级。</p>

<p>配置文件中还能对Cassandra进行设置，比如服务器地址、keyspace等。不过默认的话KairosDB使用H2作为数据存储，这样在开发环境下我们就不必配置Cassandra了。这里我们也以H2为例来初步认识一下KairosDB，这也是KairosDB的默认配置。</p>

<p>所以在这个例子里，我们不必修改配置文件，直接启动KairosDB即可：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ bin/kairosdb.sh run
</span><span class='line'># 或者
</span><span class='line'>$ bin/kairosdb.sh start</span></code></pre></td></tr></table></div></figure>


<p>其中<code>run</code>参数会以前台运行的方式启动KairosDB，而<code>start</code>则以后台进程的方式启动KairosDB。</p>

<p>停止KairosDB只需要运行<code>bin/kairosdb.sh stop</code>就可以了。</p>

<h2>写入数据</h2>

<p>和OpenTSDB一样，KairosDB也支持基于telnet和HTTP API的方式写入数据。</p>

<h3>Telnet</h3>

<p>Telnet的方式数据格式很简单：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>put &lt;metric_name&gt; &lt;time-stamp&gt; &lt;value&gt; &lt;tag&gt; &lt;tag&gt;... \n</span></code></pre></td></tr></table></div></figure>


<p>这里我们就不做演示了。</p>

<h3>HTTP API</h3>

<p>只需要发送JSON数据到<code>http://localhost:8080/api/v1/datapoints</code>就可以了。</p>

<p>这是我们写入测试数据的方法：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ curl -v -H "Content-type: application/json" -X POST  http://localhost:8080/api/v1/datapoints -d '
</span><span class='line'>[{
</span><span class='line'>    "name": "cpu.load.1",
</span><span class='line'>    "timestamp": 1453109876000,
</span><span class='line'>    "type": "double",
</span><span class='line'>    "value": 0.32,
</span><span class='line'>    "tags":{"host":"test-1"}
</span><span class='line'>},
</span><span class='line'>{
</span><span class='line'>    "name": "cpu.load.1",
</span><span class='line'>    "timestamp": 1453109876000,
</span><span class='line'>    "type": "double",
</span><span class='line'>    "value": 0.21,
</span><span class='line'>    "tags":{"host":"test-2"}
</span><span class='line'>}]
</span><span class='line'>'
</span><span class='line'>* Connected to localhost (::1) port 8080 (#0)
</span><span class='line'>&gt; POST /api/v1/datapoints HTTP/1.1
</span><span class='line'>&gt; Host: localhost:8080
</span><span class='line'>&gt; User-Agent: curl/7.43.0
</span><span class='line'>&gt; Accept: */*
</span><span class='line'>&gt; Content-type: application/json
</span><span class='line'>&gt; Content-Length: 262
</span><span class='line'>&gt; 
</span><span class='line'>* upload completely sent off: 262 out of 262 bytes
</span><span class='line'>&lt; HTTP/1.1 204 No Content
</span><span class='line'>&lt; Access-Control-Allow-Origin: *
</span><span class='line'>&lt; Pragma: no-cache
</span><span class='line'>&lt; Cache-Control: no-cache
</span><span class='line'>&lt; Expires: 0
</span><span class='line'>&lt; Content-Type: application/json; charset=UTF-8
</span><span class='line'>&lt; Server: Jetty(8.1.16.v20140903)
</span><span class='line'>&lt; 
</span><span class='line'>* Connection #0 to host localhost left intact
</span></code></pre></td></tr></table></div></figure>


<p>从服务器返回结果我们可以看到，HTTP 204状态码，也是KairosDB成功写入数据的结果。</p>

<h2>查询数据</h2>

<p>同样KairosDB提供了查询用API：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ curl -H "Content-type: application/json" -X POST  http://localhost:8080/api/v1/datapoints/query -d '
</span><span class='line'>{
</span><span class='line'>  "metrics": [
</span><span class='line'>    {
</span><span class='line'>      "tags": {},
</span><span class='line'>      "name": "cpu.load.1",
</span><span class='line'>      "group_by": [
</span><span class='line'>        {
</span><span class='line'>          "name": JSON"tag",
</span><span class='line'>          "tags": [
</span><span class='line'>            "host"
</span><span class='line'>          ]
</span><span class='line'>        }
</span><span class='line'>      ],
</span><span class='line'>      "aggregators": [
</span><span class='line'>        {
</span><span class='line'>          "name": "sum",
</span><span class='line'>          "align_sampling": true,
</span><span class='line'>          "sampling": {
</span><span class='line'>            "value": "1",
</span><span class='line'>            "unit": "minutes"
</span><span class='line'>          }
</span><span class='line'>        }
</span><span class='line'>      ]
</span><span class='line'>    }
</span><span class='line'>  ],
</span><span class='line'>  "cache_time": 0,
</span><span class='line'>  "start_absolute": 1453046400000,
</span><span class='line'>  "end_absolute": 1453132800000,
</span><span class='line'>  "time_zone": "Asia/Chongqing"
</span><span class='line'>}' | jq .</span></code></pre></td></tr></table></div></figure>


<p>注意上面命令最后的jq，这是用来对JSON数据进行格式化的工具。</p>

<p>最终结果可能像下面一样：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>  "queries": [
</span><span class='line'>    {
</span><span class='line'>      "sample_size": 2,
</span><span class='line'>      "results": [
</span><span class='line'>        {
</span><span class='line'>          "name": "cpu.load.1",
</span><span class='line'>          "group_by": [
</span><span class='line'>            {
</span><span class='line'>              "name": "tag",
</span><span class='line'>              "tags": [
</span><span class='line'>                "host"
</span><span class='line'>              ],
</span><span class='line'>              "group": {
</span><span class='line'>                "host": "test-1"
</span><span class='line'>              }
</span><span class='line'>            },
</span><span class='line'>            {
</span><span class='line'>              "name": "type",
</span><span class='line'>              "type": "number"
</span><span class='line'>            }
</span><span class='line'>          ],
</span><span class='line'>          "tags": {
</span><span class='line'>            "host": [
</span><span class='line'>              "test-1"
</span><span class='line'>            ]
</span><span class='line'>          },
</span><span class='line'>          "values": [
</span><span class='line'>            [
</span><span class='line'>              1453109876000,
</span><span class='line'>              0.32
</span><span class='line'>            ]
</span><span class='line'>          ]
</span><span class='line'>        },
</span><span class='line'>        {
</span><span class='line'>          "name": "cpu.load.1",
</span><span class='line'>          "group_by": [
</span><span class='line'>            {
</span><span class='line'>              "name": "tag",
</span><span class='line'>              "tags": [
</span><span class='line'>                "host"
</span><span class='line'>              ],
</span><span class='line'>              "group": {
</span><span class='line'>                "host": "test-2"
</span><span class='line'>              }
</span><span class='line'>            },
</span><span class='line'>            {
</span><span class='line'>              "name": "type",
</span><span class='line'>              "type": "number"
</span><span class='line'>            }
</span><span class='line'>          ],
</span><span class='line'>          "tags": {
</span><span class='line'>            "host": [
</span><span class='line'>              "test-2"
</span><span class='line'>            ]
</span><span class='line'>          },
</span><span class='line'>          "values": [
</span><span class='line'>            [
</span><span class='line'>              1453109876000,
</span><span class='line'>              0.21
</span><span class='line'>            ]
</span><span class='line'>          ]
</span><span class='line'>        }
</span><span class='line'>      ]
</span><span class='line'>    }
</span><span class='line'>  ]
</span><span class='line'>}
</span></code></pre></td></tr></table></div></figure>


<h2>WEB UI</h2>

<p>KairosDB自带了一个Web界面，你可以通过 <a href="http://localhost:8080">http://localhost:8080</a> 访问。不过这个UI主要是以开发为目的的，可以看到查询的JSON文本，方便调试，比较直观。默认的UI使用了Flot来画图，如果你愿意，也可以使用Highcharts替换。</p>

<h2>Library</h2>

<p>KairosDB目前有一个单独的<a href="https://github.com/kairosdb/kairosdb-client">Java Client</a>，在官网还有一些其他语言的客户端，比如Python、PHP等。</p>

<p>由于是Java客户端，所以还是很容易上手的。比如写入数据：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>MetricBuilder builder = MetricBuilder.getInstance();
</span><span class='line'>builder.addMetric("metric1")
</span><span class='line'>        .addTag("host", "server1")
</span><span class='line'>        .addTag("customer", "Acme")
</span><span class='line'>        .addDataPoint(System.currentTimeMillis(), 10)
</span><span class='line'>        .addDataPoint(System.currentTimeMillis(), 30L);
</span><span class='line'>HttpClient client = new HttpClient("http://localhost:8080");
</span><span class='line'>Response response = client.pushMetrics(builder);
</span><span class='line'>client.shutdown();</span></code></pre></td></tr></table></div></figure>


<p>读取数据：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>QueryBuilder builder = QueryBuilder.getInstance();
</span><span class='line'>builder.setStart(2, TimeUnit.MONTHS)
</span><span class='line'>       .setEnd(1, TimeUnit.MONTHS)
</span><span class='line'>       .addMetric("metric1")
</span><span class='line'>       .addAggregator(AggregatorFactory.createAverageAggregator(5, TimeUnit.MINUTES));
</span><span class='line'>HttpClient client = new HttpClient("http://localhost:8080");
</span><span class='line'>QueryResponse response = client.query(builder);
</span><span class='line'>client.shutdown();
</span></code></pre></td></tr></table></div></figure>


<p>这应该会非常方便，开发起来比OpenTSDB要快不少了。</p>

<h2>其他API</h2>

<p>KairosDB竟然支持metric删除功能，这个功能会有多少人需要呢？</p>

<p>列出metric名、tag列表、列出tag值，说不定有人会喜欢，比如在输入框自动提示灯功能，可能需要这些元数据。</p>

<h3>列出指标名</h3>

<p>这里除了<code>cpu.load.1</code>是我们自己写入的metric，其余的都是KairosDB自己的指标数据。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ curl http://localhost:8080/api/v1/metricnames | jq .
</span><span class='line'>
</span><span class='line'>  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
</span><span class='line'>                                 Dload  Upload   Total   Spent    Left  Speed
</span><span class='line'>100   501    0   501    0     0  45058      0 --:--:-- --:--:-- --:--:-- 50100
</span><span class='line'>{
</span><span class='line'>  "results": [
</span><span class='line'>    "kairosdb.datastore.query_time",
</span><span class='line'>    "kairosdb.protocol.telnet_request_count",
</span><span class='line'>    "kairosdb.http.ingest_count",
</span><span class='line'>    "kairosdb.datastore.query_row_count",
</span><span class='line'>    "cpu.load.1",
</span><span class='line'>    "kairosdb.protocol.http_request_count",
</span><span class='line'>    "kairosdb.http.ingest_time",
</span><span class='line'>    "kairosdb.jvm.thread_count",
</span><span class='line'>    "kairosdb.jvm.total_memory",
</span><span class='line'>    "kairosdb.jvm.max_memory",
</span><span class='line'>    "kairosdb.metric_counters",
</span><span class='line'>    "kairosdb.jvm.free_memory",
</span><span class='line'>    "kairosdb.datastore.query_sample_size",
</span><span class='line'>    "kairosdb.datastore.query_collisions",
</span><span class='line'>    "kairosdb.http.query_time",
</span><span class='line'>    "kairosdb.http.request_time"
</span><span class='line'>  ]
</span><span class='line'>}
</span></code></pre></td></tr></table></div></figure>


<h3>列出tag key</h3>

<p>这个API能列出系统中所有的tag key。不过遗憾的是它不支持只列出某一给定指标的所有tag key。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ curl http://localhost:8080/api/v1/tagnames | jq .
</span><span class='line'>
</span><span class='line'>  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
</span><span class='line'>                                 Dload  Upload   Total   Spent    Left  Speed
</span><span class='line'>100    67    0    67    0     0   4188      0 --:--:-- --:--:-- --:--:--  4466
</span><span class='line'>{
</span><span class='line'>  "results": [
</span><span class='line'>    "method",
</span><span class='line'>    "metric_name",
</span><span class='line'>    "query_index",
</span><span class='line'>    "request",
</span><span class='line'>    "host"
</span><span class='line'>  ]
</span><span class='line'>}
</span></code></pre></td></tr></table></div></figure>


<h3>列出tag value</h3>

<p>这个API能列出系统中所有的tag value。同样遗憾的是它也不支持只列出某一给定指标的所有tag value。</p>

<p>所以这两个API几乎可以说是然并卵、无鸟用。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ curl http://localhost:8080/api/v1/tagvalues | jq .
</span><span class='line'>
</span><span class='line'>  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
</span><span class='line'>                                 Dload  Upload   Total   Spent    Left  Speed
</span><span class='line'>100   163    0   163    0     0   5011      0 --:--:-- --:--:-- --:--:--  5093
</span><span class='line'>{
</span><span class='line'>  "results": [
</span><span class='line'>    "1",
</span><span class='line'>    "lius-MacBook-Pro.local",
</span><span class='line'>    "tagnames",
</span><span class='line'>    "/datapoints/query",
</span><span class='line'>    "test-1",
</span><span class='line'>    "test-2",
</span><span class='line'>    "metricnames",
</span><span class='line'>    "query",
</span><span class='line'>    "tags",
</span><span class='line'>    "version",
</span><span class='line'>    "datapoints",
</span><span class='line'>    "putm",
</span><span class='line'>    "cpu.load.1"
</span><span class='line'>  ]
</span><span class='line'>}
</span></code></pre></td></tr></table></div></figure>


<h2>总结</h2>

<p>KairosDB毕竟是OpenTSDB的一个fork，因此根本上的功能都差不多，而且随着OpenTSDB对Cassandra的支持，感觉KairosDB也该相比OpenTSDB没有什么太大的优势。</p>

<h2>相关阅读</h2>

<p>这是本系列文章的其他部分：</p>

<ul>
<li><a href="http://liubin.github.io/blog/2016/02/18/tsdb-intro/">时序列数据库武斗大会之什么是TSDB</a></li>
<li><a href="http://liubin.github.io/blog/2016/02/25/tsdb-list-part-1/">时序列数据库武斗大会之TSDB名录 Part 1</a></li>
<li><a href="http://liubin.github.io/blog/2016/03/01/tsdb-list-part-2/">时序列数据库武斗大会之TSDB名录 Part 2</a></li>
<li><a href="http://liubin.github.io/blog/2016/03/05/tsdb-opentsdb/">时序列数据库武斗大会之OpenTSDB篇</a></li>
<li>时序列数据库武斗大会之KairosDB篇</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[时序列数据库武斗大会之OpenTSDB篇]]></title>
    <link href="http://liubin.github.io/blog/2016/03/05/tsdb-opentsdb/"/>
    <updated>2016-03-05T00:25:30+08:00</updated>
    <id>http://liubin.github.io/blog/2016/03/05/tsdb-opentsdb</id>
    <content type="html"><![CDATA[<h2>什么是 OpenTSDB</h2>

<p>OpenTSDB ，可以认为是一个时系列数据（库），它基于HBase存储数据，充分发挥了HBase的分布式列存储特性，支持数百万每秒的读写，它的特点就是容易扩展，灵活的tag机制。</p>

<h2>架构简介</h2>

<p>这里我们简单看一下它的架构，如下图所示：</p>

<p><img src="http://77gaj2.com1.z0.glb.clouddn.com/2015/07/09/opentsdb/opentsdb_dataflow.jpg/zoom1" alt="" /></p>

<p>其最主要的部件就是TSD了，这是接收数据并存储到HBase处理的核心所在。而带有C（collector）标志的Server，则是数据采集源，将数据发给 TSD服务。</p>

<h2>安装 OpenTSDB</h2>

<p>为了安装 OpenTSDB ，都需要以下条件和软件：</p>

<ul>
<li>Linux操作系统</li>
<li>JRE 1.6 or later</li>
<li>HBase 0.92 or later</li>
</ul>


<h3>安装GnuPlot</h3>

<p>如果你还想使用自带的界面，则需要安装GnuPlot 4.2及以后版本，以及gd和gd-devel等。这里我们选择了GnuPlot 5.0.1的版本。</p>

<p>根据情况执行（没有就装），安装所需软件</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ sudo yum install -y gd gd-devel libpng libpng-devel</span></code></pre></td></tr></table></div></figure>


<p>之后安装GnuPlot：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ tar zxvf gnuplot-5.0.1.tar.gz
</span><span class='line'>$ cd gnuplot-5.0.1
</span><span class='line'>$ ./configure
</span><span class='line'>$ make
</span><span class='line'>$ sudo make install</span></code></pre></td></tr></table></div></figure>


<h3>安装HBase</h3>

<p>首先，确保设置了JAVA_HOME：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ echo $JAVA_HOME
</span><span class='line'>/usr</span></code></pre></td></tr></table></div></figure>


<p>这个不多说了，非常简单，只需要按照 <a href="https://hbase.apache.org/book.html#quickstart">https://hbase.apache.org/book.html#quickstart</a> 这里所说，下载、解压、修改配置文件、启动即可。</p>

<p>这时候，再设置HBASE_HOME：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ echo $HBASE_HOME
</span><span class='line'>/opt/hbase-1.0.1.1</span></code></pre></td></tr></table></div></figure>


<p>之后便可启动hbase：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ /opt/hbase-1.0.1.1/bin/start-hbase.sh
</span><span class='line'>starting master, logging to /opt/hbase-1.0.1.1/logs/hbase-vagrant-master-localhost.localdomain.out</span></code></pre></td></tr></table></div></figure>


<h3>安装 OpenTSDB</h3>

<p>这个也很简单，如果build失败，那肯定是缺少Make或者Autotools等东西，用包管理器安装即可。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ git clone git://github.com/OpenTSDB/opentsdb.git
</span><span class='line'>$ cd opentsdb
</span><span class='line'>$ ./build.sh</span></code></pre></td></tr></table></div></figure>


<p>创建表OpenTSDB所需要的表结构：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ env COMPRESSION=NONE ./src/create_table.sh
</span><span class='line'>2016-01-08 06:17:58,045 WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform… using builtin-java classes where applicable
</span><span class='line'>HBase Shell; enter ‘help‘ for list of supported commands.
</span><span class='line'>Type “exit” to leave the HBase Shell
</span><span class='line'>Version 1.0.1.1, re1dbf4df30d214fca14908df71d038081577ea46, Sun May 17 12:34:26 PDT 2015
</span><span class='line'>
</span><span class='line'>create ‘tsdb-uid’,
</span><span class='line'>{NAME =&gt; ‘id’, COMPRESSION =&gt; ‘NONE’, BLOOMFILTER =&gt; ‘ROW’},
</span><span class='line'>{NAME =&gt; ‘name’, COMPRESSION =&gt; ‘NONE’, BLOOMFILTER =&gt; ‘ROW’}
</span><span class='line'>0 row(s) in 1.3180 seconds
</span><span class='line'>
</span><span class='line'>Hbase::Table – tsdb-uid
</span><span class='line'>
</span><span class='line'>create ‘tsdb’,
</span><span class='line'>{NAME =&gt; ‘t’, VERSIONS =&gt; 1, COMPRESSION =&gt; ‘NONE’, BLOOMFILTER =&gt; ‘ROW’}
</span><span class='line'>0 row(s) in 0.2400 seconds
</span><span class='line'>
</span><span class='line'>Hbase::Table – tsdb
</span><span class='line'>
</span><span class='line'>create ‘tsdb-tree’,
</span><span class='line'>{NAME =&gt; ‘t’, VERSIONS =&gt; 1, COMPRESSION =&gt; ‘NONE’, BLOOMFILTER =&gt; ‘ROW’}
</span><span class='line'>0 row(s) in 0.2160 seconds
</span><span class='line'>
</span><span class='line'>Hbase::Table – tsdb-tree
</span><span class='line'>
</span><span class='line'>create ‘tsdb-meta’,
</span><span class='line'>{NAME =&gt; ‘name’, COMPRESSION =&gt; ‘NONE’, BLOOMFILTER =&gt; ‘ROW’}
</span><span class='line'>0 row(s) in 0.4480 seconds
</span><span class='line'>
</span><span class='line'>Hbase::Table – tsdb-meta</span></code></pre></td></tr></table></div></figure>


<p>在habse shell里，可以看到表已经创建成功。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>&gt; list
</span><span class='line'>TABLE
</span><span class='line'>tsdb
</span><span class='line'>tsdb-meta
</span><span class='line'>tsdb-tree
</span><span class='line'>tsdb-uid
</span><span class='line'>4 row(s) in 0.0160 seconds</span></code></pre></td></tr></table></div></figure>


<p>表创建之后，即可启动tsd服务，只需要运行如下命令：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ build/tsdb tsd</span></code></pre></td></tr></table></div></figure>


<p>如果看到输出：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>2016-01-09 05:51:10,875 INFO [main] TSDMain: Ready to serve on /0.0.0.0:4242</span></code></pre></td></tr></table></div></figure>


<p>即可认为启动成功。</p>

<h2>保存数据到OpenTSDB</h2>

<p>在安装并启动所有服务之后，我们就来尝试发送1条数据吧。</p>

<p>最简单的保存数据方式就是使用telnet。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>$ telnet localhost 4242
</span><span class='line'>
</span><span class='line'>put sys.cpu.user 1436333416 23 host=web01 user=10001</span></code></pre></td></tr></table></div></figure>


<p>这时，从 OpenTSDB 自带界面都可以看到这些数据。
由于sys.cpu.sys的数据只有一条，所以 OpenTSDB 只能看到一个点。</p>

<p>下图为 OpenTSDB 自带的查询界面，访问 <a href="http://localhost:4242">http://localhost:4242</a> 即可。</p>

<p><img src="http://77gaj2.com1.z0.glb.clouddn.com/2015/07/09/opentsdb/opentsdb-ui.png/zoom1" alt="" /></p>

<h3>OpenTSDB中的数据存储结构</h3>

<p>我们来看看 OpenTSDB 的重要概念uid，先从HBase中存储的数据开始吧，我们来看一下它都有哪些表，以及这些表都是干什么的。</p>

<h4>tsdb：存储数据点</h4>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hbase(main):003:0&gt; scan 'tsdb'
</span><span class='line'>ROW                           COLUMN+CELL                                                                         
</span><span class='line'> \x00\x00\x01U\x9C\xAEP\x00\x column=t:q\x80, timestamp=1436350142588, value=\x17                                 
</span><span class='line'> 00\x01\x00\x00\x01\x00\x00\x                                                                                     
</span><span class='line'> 02\x00\x00\x02                                                                                                   
</span><span class='line'>1 row(s) in 0.2800 seconds
</span></code></pre></td></tr></table></div></figure>


<p>可以看出，该表只有一条数据，我们先不管rowid，只来看看列，只有一列，值为0x17，即十进制23，即该metric的值。</p>

<p>左面的row key则是 OpenTSDB 的特点之一，其规则为：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>metric + timestamp + tagk1 + tagv1… + tagkN + tagvN</span></code></pre></td></tr></table></div></figure>


<p>以上属性值均为对应名称的uid。</p>

<p>我们上面添加的metric为：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>sys.cpu.user 1436333416 23 host=web01 user=10001</span></code></pre></td></tr></table></div></figure>


<p>一共涉及到5个uid，即名为sys.cpu.user的metric，以及host和user两个tagk及其值web01和10001。</p>

<p>上面数据的row key为：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>\x00\x00\x01U\x9C\xAEP\x00\x00\x01\x00\x00\x01\x00\x00\x02\x00\x00\x02</span></code></pre></td></tr></table></div></figure>


<p>具体这个row key是怎么算出来的，我们来看看tsdb-uid表。</p>

<h4>tsdb-uid：存储name和uid的映射关系</h4>

<p>下面tsdb-uid表的数据，各行之间人为加了空行，为方便显示。</p>

<p>tsdb-uid用来保存名字和UID（metric，tagk，tagv）之间互相映射的关系，都是成组出现的，即给定一个name和uid，会保存（name,uid）和（uid,name）两条记录。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hbase(main):004:0&gt; scan 'tsdb-uid'
</span><span class='line'>ROW                           COLUMN+CELL                                                                         
</span><span class='line'> \x00                         column=id:metrics, timestamp=1436350140242, value=\x00\x00\x00\x00\x00\x00\x00\x01  
</span><span class='line'> \x00                         column=id:tagk, timestamp=1436350141423, value=\x00\x00\x00\x00\x00\x00\x00\x02     
</span><span class='line'> \x00                         column=id:tagv, timestamp=1436350141475, value=\x00\x00\x00\x00\x00\x00\x00\x02     
</span><span class='line'>
</span><span class='line'> \x00\x00\x01                 column=name:metric_meta, timestamp=1436350142592, value={"type":"METRIC","displayNam
</span><span class='line'>                              e":"","description":"","notes":"","created":1436350140,"custom":null}               
</span><span class='line'> \x00\x00\x01                 column=name:metrics, timestamp=1436350140348, value=sys.cpu.user                    
</span><span class='line'> \x00\x00\x01                 column=name:tagk, timestamp=1436350141357, value=host                               
</span><span class='line'> \x00\x00\x01                 column=name:tagk_meta, timestamp=1436350142592, value={"type":"TAGK","displayName":"
</span><span class='line'>                              ","description":"","notes":"","created":1436350141,"custom":null}                   
</span><span class='line'> \x00\x00\x01                 column=name:tagv, timestamp=1436350141385, value=web01                              
</span><span class='line'> \x00\x00\x01                 column=name:tagv_meta, timestamp=1436350142592, value={"type":"TAGV","displayName":"
</span><span class='line'>                              ","description":"","notes":"","created":1436350141,"custom":null}                   
</span><span class='line'>
</span><span class='line'> \x00\x00\x02                 column=name:tagk, timestamp=1436350141462, value=user                               
</span><span class='line'> \x00\x00\x02                 column=name:tagk_meta, timestamp=1436350142592, value={"type":"TAGK","displayName":"
</span><span class='line'>                              ","description":"","notes":"","created":1436350141,"custom":null}                   
</span><span class='line'> \x00\x00\x02                 column=name:tagv, timestamp=1436350141480, value=10001                              
</span><span class='line'> \x00\x00\x02                 column=name:tagv_meta, timestamp=1436350142592, value={"type":"TAGV","displayName":"
</span><span class='line'>                              ","description":"","notes":"","created":1436350141,"custom":null}                   
</span><span class='line'>
</span><span class='line'> 10001                        column=id:tagv, timestamp=1436350141495, value=\x00\x00\x02                         
</span><span class='line'>
</span><span class='line'> host                         column=id:tagk, timestamp=1436350141363, value=\x00\x00\x01                         
</span><span class='line'>
</span><span class='line'> sys.cpu.user                 column=id:metrics, timestamp=1436350140408, value=\x00\x00\x01                      
</span><span class='line'>
</span><span class='line'> user                         column=id:tagk, timestamp=1436350141466, value=\x00\x00\x02                         
</span><span class='line'>
</span><span class='line'> web01                        column=id:tagv, timestamp=1436350141396, value=\x00\x00\x01                         
</span><span class='line'>
</span><span class='line'>8 row(s) in 0.7280 seconds</span></code></pre></td></tr></table></div></figure>


<p>我们一共看到了8行数据。</p>

<p>前面我们在tsdb表中已经看到，metric数据的row key为\x00\x00\x01U\x9C\xAEP\x00\x00\x01\x00\x00\x01\x00\x00\x02\x00\x00\x02
，我们将其分解下，用+号连起来（从name到uid的映射为最后5行）：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'> \x00\x00\x01 + U + \x9C\xAE + P + \x00\x00\x01 + \x00\x00\x01 + \x00\x00\x02  + \x00\x00\x02
</span><span class='line'>sys.cpu.user       1436333416           host    =      web01          user     =    10001
</span></code></pre></td></tr></table></div></figure>


<p>可以看出，这和我们前面说到的row key的构成方式是吻合的。</p>

<p>需要着重说明的是时间戳的存储方式。</p>

<p>虽然我们指定的时间是以秒为单位的，但是，row key中用到的却是以一小时为单位的，即：1436333416 – 1436333416 % 3600 = 1436331600 。</p>

<p>1436331600转换为16进制，即0x55 0x9c 0xae 0x50，而0x55即大写字母U，0x50为大写字母P，这就是4个字节的时间戳存储方式。相信下面这张图能帮助各位更好理解这个意思，即一小时只有一个row key，每秒钟的数据都会存为一列，大大提高查询的速度。</p>

<p><img src="http://77gaj2.com1.z0.glb.clouddn.com/2015/07/09/opentsdb/row-key-storage.png/zoom1" alt="" /></p>

<p>反过来，从uid到name也一样，比如找uid为\x00\x00\x02的tagk，我们从上面结果可以看到，该row key（\x00\x00\x02）有4列，而column=name:tagk的value就是user，非常简单直观。</p>

<p>重要：我们看到，上面的metric也好，tagk或者tagv也好，uid只有3个字节，这是 OpenTSDB 的默认配置，三个字节，应该能表示1600多万的不同数据，这对metric名或者tagk来说足够长了，对tagv来说就不一定了，比如tagv是ip地址的话，或者电话号码，那么这个字段就不够长了，这时可以通过修改源代码来重新编译 OpenTSDB 就可以了，同时要注意的是，重编以后，老数据就不能直接使用了，需要导出后重新导入。</p>

<h4>tsdb-meta：元数据表</h4>

<p>我们再看下第三个表tsdb-meta，这是用来存储时间序列索引和元数据的表。这也是一个可选特性，默认是不开启的，可以通过配置文件来启用该特性，这里不做特殊介绍了。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>hbase(main):005:0&gt; scan 'tsdb-meta'
</span><span class='line'>ROW                           COLUMN+CELL                                                                         
</span><span class='line'> \x00\x00\x01\x00\x00\x01\x00 column=name:ts_ctr, timestamp=1436350141578, value=\x00\x00\x00\x00\x00\x00\x00\x01 
</span><span class='line'> \x00\x01\x00\x00\x02\x00\x00                                                                                     
</span><span class='line'> \x02                                                                                                             
</span><span class='line'> \x00\x00\x01\x00\x00\x01\x00 column=name:ts_meta, timestamp=1436350142589, value={"tsuid":"0000010000010000010000
</span><span class='line'> \x00\x01\x00\x00\x02\x00\x00 02000002","displayName":"","description":"","notes":"","created":1436350141,"custom"
</span><span class='line'> \x02                         :null,"units":"","dataType":"","retention":0,"max":"NaN","min":"NaN"}               
</span><span class='line'>1 row(s) in 0.1320 seconds</span></code></pre></td></tr></table></div></figure>


<h4>tsdb-tree：树形表</h4>

<p>第4个表是tsdb-tree，用来以树状层次关系来表示metric的结构，只有在配置文件开启该特性后，才会使用此表，这里我们不介绍了，可以自己尝试。</p>

<h3>通过HTTP接口保存数据</h3>

<p>保存数据除了我们前面用到的telnet方式，也可以选择HTTP API或者批量导入工具import（ <a href="http://opentsdb.net/docs/build/html/user_guide/cli/import.html">http://opentsdb.net/docs/build/html/user_guide/cli/import.html</a> ），这里我们再对HTTP API进行简单示例说明。</p>

<p>假设我们有如下数据，保存为文件mysql.json：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">[</span>
</span><span class='line'>    <span class="p">{</span>
</span><span class='line'>        <span class="nt">&quot;metric&quot;</span><span class="p">:</span> <span class="s2">&quot;mysql.innodb.row_lock_time&quot;</span><span class="p">,</span>
</span><span class='line'>        <span class="nt">&quot;timestamp&quot;</span><span class="p">:</span> <span class="mi">1435716527</span><span class="p">,</span>
</span><span class='line'>        <span class="nt">&quot;value&quot;</span><span class="p">:</span> <span class="mi">1234</span><span class="p">,</span>
</span><span class='line'>        <span class="nt">&quot;tags&quot;</span><span class="p">:</span> <span class="p">{</span>
</span><span class='line'>           <span class="nt">&quot;host&quot;</span><span class="p">:</span> <span class="s2">&quot;web01&quot;</span><span class="p">,</span>
</span><span class='line'>           <span class="nt">&quot;dc&quot;</span><span class="p">:</span> <span class="s2">&quot;beijing&quot;</span>
</span><span class='line'>        <span class="p">}</span>
</span><span class='line'>    <span class="p">},</span>
</span><span class='line'>    <span class="p">{</span>
</span><span class='line'>        <span class="nt">&quot;metric&quot;</span><span class="p">:</span> <span class="s2">&quot;mysql.innodb.row_lock_time&quot;</span><span class="p">,</span>
</span><span class='line'>        <span class="nt">&quot;timestamp&quot;</span><span class="p">:</span> <span class="mi">1435716529</span><span class="p">,</span>
</span><span class='line'>        <span class="nt">&quot;value&quot;</span><span class="p">:</span> <span class="mi">2345</span><span class="p">,</span>
</span><span class='line'>        <span class="nt">&quot;tags&quot;</span><span class="p">:</span> <span class="p">{</span>
</span><span class='line'>           <span class="nt">&quot;host&quot;</span><span class="p">:</span> <span class="s2">&quot;web01&quot;</span><span class="p">,</span>
</span><span class='line'>           <span class="nt">&quot;dc&quot;</span><span class="p">:</span> <span class="s2">&quot;beijing&quot;</span>
</span><span class='line'>        <span class="p">}</span>
</span><span class='line'>    <span class="p">},</span>
</span><span class='line'>    <span class="p">{</span>
</span><span class='line'>        <span class="nt">&quot;metric&quot;</span><span class="p">:</span> <span class="s2">&quot;mysql.innodb.row_lock_time&quot;</span><span class="p">,</span>
</span><span class='line'>        <span class="nt">&quot;timestamp&quot;</span><span class="p">:</span> <span class="mi">1435716627</span><span class="p">,</span>
</span><span class='line'>        <span class="nt">&quot;value&quot;</span><span class="p">:</span> <span class="mi">3456</span><span class="p">,</span>
</span><span class='line'>        <span class="nt">&quot;tags&quot;</span><span class="p">:</span> <span class="p">{</span>
</span><span class='line'>           <span class="nt">&quot;host&quot;</span><span class="p">:</span> <span class="s2">&quot;web02&quot;</span><span class="p">,</span>
</span><span class='line'>           <span class="nt">&quot;dc&quot;</span><span class="p">:</span> <span class="s2">&quot;beijing&quot;</span>
</span><span class='line'>        <span class="p">}</span>
</span><span class='line'>    <span class="p">},</span>
</span><span class='line'>    <span class="p">{</span>
</span><span class='line'>        <span class="nt">&quot;metric&quot;</span><span class="p">:</span> <span class="s2">&quot;mysql.innodb.row_lock_time&quot;</span><span class="p">,</span>
</span><span class='line'>        <span class="nt">&quot;timestamp&quot;</span><span class="p">:</span> <span class="mi">1435716727</span><span class="p">,</span>
</span><span class='line'>        <span class="nt">&quot;value&quot;</span><span class="p">:</span> <span class="mi">6789</span><span class="p">,</span>
</span><span class='line'>        <span class="nt">&quot;tags&quot;</span><span class="p">:</span> <span class="p">{</span>
</span><span class='line'>           <span class="nt">&quot;host&quot;</span><span class="p">:</span> <span class="s2">&quot;web01&quot;</span><span class="p">,</span>
</span><span class='line'>           <span class="nt">&quot;dc&quot;</span><span class="p">:</span> <span class="s2">&quot;tianjin&quot;</span>
</span><span class='line'>        <span class="p">}</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure>


<p>之后执行如下命令：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="err">$</span> <span class="err">curl</span> <span class="err">-X</span> <span class="err">POST</span> <span class="err">-H</span> <span class="err">“Content-Type:</span> <span class="err">application/json”</span> <span class="err">http://localhost:</span><span class="mi">4242</span><span class="err">/api/put</span> <span class="err">-d</span> <span class="err">@mysql.json</span>
</span></code></pre></td></tr></table></div></figure>


<p>即可将数据保存到 OpenTSDB 了。</p>

<h2>查询数据</h2>

<p>看完了如何保存数据，我们再来看看如何查询数据。</p>

<p>查询数据可以使用query接口，它既可以使用get的query string方式，也可以使用post方式以JSON格式指定查询条件，这里我们以后者为例，对刚才保存的数据进行说明。</p>

<p>首先，保存如下内容为search.json：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="p">{</span>
</span><span class='line'>    <span class="nt">&quot;start&quot;</span><span class="p">:</span> <span class="mi">1435716527</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;queries&quot;</span><span class="p">:</span> <span class="p">[</span>
</span><span class='line'>        <span class="p">{</span>
</span><span class='line'>            <span class="nt">&quot;metric&quot;</span><span class="p">:</span> <span class="s2">&quot;mysql.innodb.row_lock_time&quot;</span><span class="p">,</span>
</span><span class='line'>            <span class="nt">&quot;aggregator&quot;</span><span class="p">:</span> <span class="s2">&quot;avg&quot;</span><span class="p">,</span>
</span><span class='line'>            <span class="nt">&quot;tags&quot;</span><span class="p">:</span> <span class="p">{</span>
</span><span class='line'>                <span class="nt">&quot;host&quot;</span><span class="p">:</span> <span class="s2">&quot;*&quot;</span><span class="p">,</span>
</span><span class='line'>                <span class="nt">&quot;dc&quot;</span><span class="p">:</span> <span class="s2">&quot;beijing&quot;</span>
</span><span class='line'>            <span class="p">}</span>
</span><span class='line'>        <span class="p">}</span>
</span><span class='line'>    <span class="p">]</span>
</span><span class='line'><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>执行如下命令进行查询：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class='json'><span class='line'><span class="err">$</span> <span class="err">curl</span> <span class="err">-s</span> <span class="err">-X</span> <span class="err">POST</span> <span class="err">-H</span> <span class="s2">&quot;Content-Type: application/json&quot;</span> <span class="err">http://localhost:</span><span class="mi">4242</span><span class="err">/api/query</span> <span class="err">-d</span> <span class="err">@search.json</span> <span class="err">|</span> <span class="err">jq</span> <span class="err">.</span>
</span><span class='line'><span class="p">[</span>
</span><span class='line'>  <span class="p">{</span>
</span><span class='line'>    <span class="nt">&quot;metric&quot;</span><span class="p">:</span> <span class="s2">&quot;mysql.innodb.row_lock_time&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;tags&quot;</span><span class="p">:</span> <span class="p">{</span>
</span><span class='line'>      <span class="nt">&quot;host&quot;</span><span class="p">:</span> <span class="s2">&quot;web01&quot;</span><span class="p">,</span>
</span><span class='line'>      <span class="nt">&quot;dc&quot;</span><span class="p">:</span> <span class="s2">&quot;beijing&quot;</span>
</span><span class='line'>    <span class="p">},</span>
</span><span class='line'>    <span class="nt">&quot;aggregateTags&quot;</span><span class="p">:</span> <span class="p">[],</span>
</span><span class='line'>    <span class="nt">&quot;dps&quot;</span><span class="p">:</span> <span class="p">{</span>
</span><span class='line'>      <span class="nt">&quot;1435716527&quot;</span><span class="p">:</span> <span class="mi">1234</span><span class="p">,</span>
</span><span class='line'>      <span class="nt">&quot;1435716529&quot;</span><span class="p">:</span> <span class="mi">2345</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>  <span class="p">},</span>
</span><span class='line'>  <span class="p">{</span>
</span><span class='line'>    <span class="nt">&quot;metric&quot;</span><span class="p">:</span> <span class="s2">&quot;mysql.innodb.row_lock_time&quot;</span><span class="p">,</span>
</span><span class='line'>    <span class="nt">&quot;tags&quot;</span><span class="p">:</span> <span class="p">{</span>
</span><span class='line'>      <span class="nt">&quot;host&quot;</span><span class="p">:</span> <span class="s2">&quot;web02&quot;</span><span class="p">,</span>
</span><span class='line'>      <span class="nt">&quot;dc&quot;</span><span class="p">:</span> <span class="s2">&quot;beijing&quot;</span>
</span><span class='line'>    <span class="p">},</span>
</span><span class='line'>    <span class="nt">&quot;aggregateTags&quot;</span><span class="p">:</span> <span class="p">[],</span>
</span><span class='line'>    <span class="nt">&quot;dps&quot;</span><span class="p">:</span> <span class="p">{</span>
</span><span class='line'>      <span class="nt">&quot;1435716627&quot;</span><span class="p">:</span> <span class="mi">3456</span>
</span><span class='line'>    <span class="p">}</span>
</span><span class='line'>  <span class="p">}</span>
</span><span class='line'><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure>


<p>可以看出，我们保存了<code>dc=tianjin</code>的数据，但是并没有在此查询中返回，这是因为，我们指定了<code>dc=beijing</code>这一条件。</p>

<p>值得注意的是，tags参数在新版本2.2中，将不被推荐，取而代之的是filters参数。</p>

<h2>总结</h2>

<p>可以看出来， OpenTSDB 还是非常容易上手的，尤其是单机版，安装也很简单。有HBase作为后盾，查询起来也非常快，很多大公司，类似雅虎等，也都在用此软件。</p>

<p>但是，大规模用起来，多个TDB以及多存储节点等，应该都需要专业、细心的运维工作了。</p>

<h2>相关阅读</h2>

<p>这是本系列文章的其他部分：</p>

<ul>
<li><a href="http://liubin.github.io/blog/2016/02/18/tsdb-intro/">时序列数据库武斗大会之什么是TSDB</a></li>
<li><a href="http://liubin.github.io/blog/2016/02/25/tsdb-list-part-1/">时序列数据库武斗大会之TSDB名录 Part 1</a></li>
<li><a href="http://liubin.github.io/blog/2016/03/01/tsdb-list-part-2/">时序列数据库武斗大会之TSDB名录 Part 2</a></li>
<li>时序列数据库武斗大会之OpenTSDB篇</li>
<li><a href="http://liubin.github.io/blog/2016/03/12/tsdb-kairosdb/">时序列数据库武斗大会之KairosDB篇</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[时序列数据库武斗大会之TSDB名录 Part 2]]></title>
    <link href="http://liubin.github.io/blog/2016/03/01/tsdb-list-part-2/"/>
    <updated>2016-03-01T20:56:37+08:00</updated>
    <id>http://liubin.github.io/blog/2016/03/01/tsdb-list-part-2</id>
    <content type="html"><![CDATA[<p>在前面<a href="http://liubin.github.io/blog/2016/02/25/tsdb-list-part-1/">《时序列数据库武斗大会之TSDB名录 Part 1》</a>我们已经介绍了一些常见的TSDB，这里我们再对剩余的一些TSDB做些简单介绍。</p>

<h2>10. Geras</h2>

<table>
<thead>
<tr>
<th> - </th>
<th> - </th>
<th> - </th>
</tr>
</thead>
<tbody>
<tr>
<td> 主页 </td>
<td> <a href="http://1248.io/geras.php">http://1248.io/geras.php</a> </td>
<td>  </td>
</tr>
<tr>
<td> License </td>
<td> 商业 </td>
<td>  </td>
</tr>
</tbody>
</table>


<p>Geras是一个专注于IoT领域（当然不仅限于传感器采集到的数据）可扩展的、分布式的时序列数据库，用于帮助用户进行快速分析。Geras是一个SaaS服务，但是你也可以购买软件自己部署、托管。Geras提供了免费版，它不对数据存储的时间和数据量做任何限制，只是不提供SLA而已。不过他们的<a href="http://geras.1248.io/">SaaS主页</a>我却一直没打开过，貌似该DNS记录已经不存在了，官方相关资料也不多，真怀疑这个项目已经废弃了，该产品已经演化为新产品。</p>

<p>Geras速度非常快，它支持对任何时间精度进行Rollup，也支持保存原始数据的精度。它专门为写操作进行了优化，可以接收海量设备的数据输入。</p>

<p>Geras运行在容错、分布式数据存储之上，支持水平扩展，可以在不停止服务的前提下对系统容量进行调整。</p>

<p>Geras也提供了一套可视化界面，方便的对设备、传感器等进行管理，对metric进行图表的可视化等。</p>

<p>Geras支持多种技术来进行数据存储、查询和展示，比如HTTPS、JSON、RESTful、SenML、MQTT、HyperCat，设备数据可以通过HTTP POST或者轻量MQTT发布。</p>

<h2>11. Akumuli</h2>

<table>
<thead>
<tr>
<th> - </th>
<th> - </th>
<th> - </th>
</tr>
</thead>
<tbody>
<tr>
<td> 主页 </td>
<td> <a href="https://github.com/Akumuli/akumuli">https://github.com/Akumuli/akumuli</a> </td>
<td>  </td>
</tr>
<tr>
<td> 编写语言 </td>
<td> C++ </td>
<td>  </td>
</tr>
<tr>
<td> License </td>
<td> Apache License, Version 2.0 </td>
<td>  </td>
</tr>
<tr>
<td> 项目创建时间 </td>
<td> 2014/12 </td>
<td>  </td>
</tr>
<tr>
<td> 最新版 </td>
<td> pre-release </td>
<td> 2015/10/18 </td>
</tr>
<tr>
<td> 活跃度 </td>
<td> 活跃 </td>
<td>  </td>
</tr>
<tr>
<td> 文档 </td>
<td> 简单 </td>
<td>  </td>
</tr>
</tbody>
</table>


<p>Akumuli名称来自accumulate，是一个数值型时间序列数据库，可以存储、处理时序列数据。</p>

<p>它的特点如下：</p>

<ul>
<li>基于日志结构的存储</li>
<li>支持无序数据</li>
<li>实时压缩</li>
<li>基于HTTP的JSON查询支持</li>
<li>支持面向行和面向列的存储</li>
<li>将最新数据放入内存存储</li>
<li>通过metric和tag组织时序列数据，并且可以通过tag进行join操作。</li>
<li>Resampling (PAA transform)，滑动窗口</li>
<li>通过基于TCP或UDP的协议接收数据（支持百万数据点每秒）</li>
<li>Continuous queries (streaming)</li>
</ul>


<p>Akumuli由两部分组成：存储引擎和服务程序。目前只有存储引擎被实现了，而且存储引擎可以在没有服务程序的情况下作为嵌入式数据库单独使用（类似sqlite），也就是说，你得通过自己编写程序使用它的API来实现数据读写。</p>

<p>Akumuli的数据协议基于Redis，它的数据格式也和前面看到的不太一样，比如：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>+balancers.memusage host=machine1 unit=Gb
</span><span class='line'>+20141210T074343.999999999
</span><span class='line'>:31</span></code></pre></td></tr></table></div></figure>


<p>每条数据由三部分组成，第一部分称为ID，可以是数值型（以“：”开始），或者是字符串（以“+”开始），比如这个例子中，<code>cpu host=machine1 region= europe</code>就是ID，它由两部分组成，<code>cpu</code>是metric，<code>host</code>和<code>region</code>则被称为key。</p>

<p>数据的第二部分可以是时间戳（:1418224205），这里的格式为ISO 8601（+20141210T074343.999999）</p>

<p>第三部分为值部分。</p>

<p>类似上面的数据结构，它的query也比较容易理解：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>    "where": {
</span><span class='line'>        "region": [ "europe", "us-east" ]
</span><span class='line'>    },
</span><span class='line'>    "metric": "cpu",
</span><span class='line'>    "range": {
</span><span class='line'>        "from": "20160102T123000.000000",
</span><span class='line'>        "to":   "20160102T123010.000000" }
</span><span class='line'>}
</span></code></pre></td></tr></table></div></figure>


<p>Akumuli目前还处于开发状态，不适合在生产环境下使用。</p>

<h2>12. Atlas</h2>

<table>
<thead>
<tr>
<th> - </th>
<th> - </th>
<th> - </th>
</tr>
</thead>
<tbody>
<tr>
<td> 主页 </td>
<td> <a href="https://github.com/Netflix/atlas">https://github.com/Netflix/atlas</a> </td>
<td>  </td>
</tr>
<tr>
<td> 编写语言 </td>
<td> Scala </td>
<td>  </td>
</tr>
<tr>
<td> License </td>
<td> Apache License Version 2.0 </td>
<td>  </td>
</tr>
<tr>
<td> 项目创建时间 </td>
<td> 2014/11 </td>
<td>  </td>
</tr>
<tr>
<td> 最新版 </td>
<td> v1.5.0-rc.4 </td>
<td> 2016/02 </td>
</tr>
<tr>
<td> 活跃度 </td>
<td> 活跃 </td>
<td> 来自于Netflix </td>
</tr>
<tr>
<td> 文档 </td>
<td> 详细 </td>
<td>  </td>
</tr>
</tbody>
</table>


<p>这个和波士顿动力的机器人Atlas，以及其他很多知名软件（HashiCorp、O'reilly）都重名了。</p>

<p>Atlas用于存储带维度信息的时序列数据，由Netflix开发，用于实时分析。Atlas使用了基于内存的存储，速度非常快。在2011年的时候，Netflix使用自己开发的Epic工具来管理时序列数据，这是一个采用perl、RRDTool和MySQL构建的系统，但是随着数据量的增大（2M->1.2B），他们创建了这个新项目。</p>

<p>如果说商业智能（business intelligence）是从数据基于时间分析出趋势的话，那么Atlas可以说是一种运维智能（operational intelligence），能给用户描述出当前系统所发生的所有情况。</p>

<p>Atlas的设计目标主要有3点：</p>

<ul>
<li>通用API</li>
<li>可扩展</li>
<li>维度支持</li>
</ul>


<p>Atlas具备和OpenTSDB以及InfluxDB类似的metric/datapoint/tag的概念，同时它也有自己独自的特性，比如增加了步长（step-size）的概念。</p>

<p>Atlas采用了类似RRDtool的查询语法，它们都通过一种对URL有好的语法来支持复杂的数据查询。</p>

<p>一句话点评：背靠大树好乘凉，可以试试。</p>

<h2>13. Blueflood</h2>

<table>
<thead>
<tr>
<th> - </th>
<th> - </th>
<th> - </th>
</tr>
</thead>
<tbody>
<tr>
<td> 主页 </td>
<td> <a href="http://blueflood.io/">http://blueflood.io/</a> </td>
<td>  </td>
</tr>
<tr>
<td> 编写语言 </td>
<td> Java </td>
<td>  </td>
</tr>
<tr>
<td> License </td>
<td> Apache License, Version 2.0 </td>
<td>  </td>
</tr>
<tr>
<td> 项目创建时间 </td>
<td> 2013 </td>
<td>  </td>
</tr>
<tr>
<td> 最新版 </td>
<td> 1.0.2123 </td>
<td> 2016/01/02 </td>
</tr>
<tr>
<td> 活跃度 </td>
<td> 活跃 </td>
<td> 来自Rackspace </td>
</tr>
<tr>
<td> 文档 </td>
<td> 比较详细 </td>
<td>  </td>
</tr>
</tbody>
</table>


<p>Blueflood由Rackspace的Cloud Monitoring团队创建，用于管理Cloud Monitoring系统产生的metric数据。如果你还不熟悉Rackspace这个公司的话，可以去网上了解一下，它也是比较大的云计算公司。</p>

<p>除了自己使用，Rackspace还提供了免费的Blueflood-as-a-Service，此外还有一些大公司也在准备使用Blueflood。</p>

<p>Blueflood特点如下：</p>

<ul>
<li>built on top of Cassandra</li>
<li>基于HTTP API/JSON的数据采集（ingest）和读取</li>
<li>支持数值、布尔和字符串metric data</li>
<li>多租户</li>
<li>水平扩展</li>
</ul>


<p>Blueflood主要由以下模块构成：</p>

<ul>
<li>Ingest - 采集/写入数据</li>
<li>Rollup - 聚合计算</li>
<li>Query - 处理用户查询</li>
</ul>


<p>不过遗憾的是Blueflood现在没有一个类似tag的多维度方案。</p>

<p>一句话点评：背靠大树好乘凉，可以试试。</p>

<h2>14. Gnocchi</h2>

<table>
<thead>
<tr>
<th> - </th>
<th> - </th>
<th> - </th>
</tr>
</thead>
<tbody>
<tr>
<td> 主页 </td>
<td> <a href="http://docs.openstack.org/developer/gnocchi/">http://docs.openstack.org/developer/gnocchi/</a> </td>
<td>  </td>
</tr>
<tr>
<td> 编写语言 </td>
<td> Python </td>
<td>  </td>
</tr>
<tr>
<td> License </td>
<td>  Apache License Version 2.0 </td>
<td>  </td>
</tr>
<tr>
<td> 项目创建时间 </td>
<td> 2014 </td>
<td>  </td>
</tr>
<tr>
<td> 最新版 </td>
<td> 2.0.0 </td>
<td>  </td>
</tr>
<tr>
<td> 活跃度 </td>
<td> 活跃 </td>
<td> 来自OpenStack </td>
</tr>
<tr>
<td> 文档 </td>
<td> 一般丰富 </td>
<td>  </td>
</tr>
</tbody>
</table>


<p>Gnocchi是OpenStack项目的一部分，但它也能独立工作。</p>

<p>Gnocchi是一个多租户的时间序列、metric和资源（resource）数据库。它提供了一组HTTP REST API来创建和管理数据。</p>

<p>Gnocchi以在云就算环境中存储大量metric信息为设计出发点，为用户提供metric和资源展示功能，同时它也很容易扩展。</p>

<p>Gnocchi特点如下：</p>

<ul>
<li>HTTP RES接口</li>
<li>水平扩展</li>
<li>Metri聚合</li>
<li>支持批处理</li>
<li>支持归档功能</li>
<li>按metric值查找（这个在TSDB很少见）</li>
<li>多租户支持</li>
<li>对Grafan的支持</li>
<li>支持Statsd协议</li>
</ul>


<p>Gnocchi后端存储支持一下4种方式：</p>

<ul>
<li>File</li>
<li>Swift</li>
<li>Ceph (推荐方式)</li>
<li>InfluxDB (实验功能)</li>
</ul>


<p>前三种方式基于一个名为Carbonara的库，这个库负责对时间序列数据的管理，因为这三种存储方案本身并不关心数据的特点。InfluxDB前面已经说过，本身就是一个TSDB。</p>

<h2>15. Newts</h2>

<table>
<thead>
<tr>
<th> - </th>
<th> - </th>
<th> - </th>
</tr>
</thead>
<tbody>
<tr>
<td> 主页 </td>
<td> <a href="https://github.com/OpenNMS/newts">https://github.com/OpenNMS/newts</a> </td>
<td>  </td>
</tr>
<tr>
<td> 编写语言 </td>
<td> Java </td>
<td>  </td>
</tr>
<tr>
<td> License </td>
<td> Apache License Version 2.0 </td>
<td>  </td>
</tr>
<tr>
<td> 项目创建时间 </td>
<td> 2014 </td>
<td> 1.0 release </td>
</tr>
<tr>
<td> 最新版 </td>
<td> 1.3.3 </td>
<td> 2016/01 </td>
</tr>
<tr>
<td> 活跃度 </td>
<td> 一般 </td>
<td>  </td>
</tr>
<tr>
<td> 文档 </td>
<td> 一般 </td>
<td>  </td>
</tr>
</tbody>
</table>


<p>Newts是基于Cassandra的时序列数据库。正如其名所示，它是一个“New-fangled Timeseries Data Store”。它的开发者是OpenNMS，这也是一个知名的开源网络监控和管理平台。</p>

<p>Newts基于Cassandra，对写优化、完全分布式，吞吐量非常高；通过将类似的metric分组存储，让写和读更高效。</p>

<h2>16. SiteWhere</h2>

<table>
<thead>
<tr>
<th> - </th>
<th> - </th>
<th> - </th>
</tr>
</thead>
<tbody>
<tr>
<td> 主页 </td>
<td> <a href="http://www.sitewhere.org/">http://www.sitewhere.org/</a> </td>
<td>  </td>
</tr>
<tr>
<td> 编写语言 </td>
<td> Java </td>
<td>  </td>
</tr>
<tr>
<td> License </td>
<td> CPAL 1.0 </td>
<td>  </td>
</tr>
<tr>
<td> 最新版 </td>
<td> 1.6.1 </td>
<td>  </td>
</tr>
<tr>
<td> 活跃度 </td>
<td> 活跃 </td>
<td>  </td>
</tr>
<tr>
<td> 文档 </td>
<td> 详细 </td>
<td>  </td>
</tr>
</tbody>
</table>


<p>SiteWhere是一个开源的IoT开放平台，帮助用户快速将IoT应用推向市场。SiteWhere提供了一套完整的设备管理解决方案，通过MQTT、AMQP、Stomp和其他协议连接设备，支持自注册、REST和批处理方式注册设备。</p>

<p>SiteWhere也提供了可扩展的大数据解决方案，底层采用经优化的MongoDB和HBase，为存储设备事件提供了时序列数据库，且经过Hortonworks和Cloudera的测试。</p>

<p>SiteWhere还内嵌了Siddhi用于Complex Event Processing （CEP），提供了Azure EventHub、Apache Solr以及Twilio的集成，以及Android和Arduino平台开发用的SDK。</p>

<p>SiteWhere的部署方式也很灵活，支持公有云、私有机房，Ubuntu Juju和Docker的部署方式。</p>

<p>SiteWhere也支持多租户，不同的租户数据分开存储，还能为不同的租户提供不同的处理引擎，租户的启动、停止互不影响。</p>

<p>SiteWhere的service provider interfaces（SPIs）提供了平台的核心对象模型，第三方可以对平台进行扩展。</p>

<p>一句话点评：开源、功能强大、一体化方案。作为IoT平台，SiteWhere算是这几个中不错的。</p>

<p>建议你接着看一下它的 <a href="http://documentation.sitewhere.org/overview.html">System Overview</a> 和 <a href="http://documentation.sitewhere.org/architecture.html">System Architecture</a> 以对这个系统有更深入的了解。</p>

<h2>17. TempoIQ</h2>

<table>
<thead>
<tr>
<th> - </th>
<th> - </th>
<th> - </th>
</tr>
</thead>
<tbody>
<tr>
<td> 主页 </td>
<td> <a href="https://www.tempoiq.com/">https://www.tempoiq.com/</a> </td>
<td>  </td>
</tr>
<tr>
<td> License </td>
<td> 商业 </td>
<td>  </td>
</tr>
</tbody>
</table>


<p>TempoIQ也是一个IoT平台服务，它能帮助用户快速、灵活的的创建IoT应用，提供了实时的数据分析、报警、仪表盘、报告功能。2014年7月从TempoDB改名为TempoIQ，它的很多组件都有IQ结尾，代表智商很高？</p>

<p>TempoIQ主要由以下几个部分组成：</p>

<ul>
<li>CloudIQ</li>
</ul>


<p>TempoIQ采用第四代CoDA（Context Delivery Architecture）架构，用户可以不必心系复杂的基础设施就可以部署IoT应用。</p>

<ul>
<li>ConnectIQ</li>
</ul>


<p>基于数据事件的API，用于连接任何设备，支持灵活的事件数据模型：REST API、HTTPs和MQTT。它不关心设备来源，可以及时进行数据流处理，不需要提前安装和配置。</p>

<ul>
<li>DataIQ</li>
</ul>


<p>对所有IoT数据和分析报告进行安全、持久的存储，并提供报告下载功能。</p>

<ul>
<li>AnalyzeIQ</li>
</ul>


<p>用户可以创建分析流（custom analytics streams）来洞悉IoT数据实时状态，自动将数据存储到DataIQ。并可以创建报警来持续监控分析流，当有超预期的变动或者达到致命条件时进行实时报警。</p>

<ul>
<li>ViewIQ</li>
</ul>


<p>用户使用ViewIQ可以创建实时的IoT仪表盘、应用和可视化组件，而且不需要任何编码工作。</p>

<h2>18. Riak TS</h2>

<table>
<thead>
<tr>
<th> - </th>
<th> - </th>
<th> - </th>
</tr>
</thead>
<tbody>
<tr>
<td> 主页 </td>
<td> <a href="http://basho.com/products/riak-ts/">http://basho.com/products/riak-ts/</a> </td>
<td>  </td>
</tr>
<tr>
<td> 编写语言 </td>
<td> Erlang </td>
<td>  </td>
</tr>
<tr>
<td> License </td>
<td> 商业 </td>
<td>  </td>
</tr>
<tr>
<td> 最新版 </td>
<td> 1.1.0 </td>
<td> 2016/01/14 </td>
</tr>
<tr>
<td> 活跃度 </td>
<td>  </td>
<td> 商业支持 </td>
</tr>
</tbody>
</table>


<p>Riak作为NoSQL和K/V存储可能更有名，而Riak TS是一个为时序列和为存储IoT数据进行了优化的NoSQL数据库软件。</p>

<p>在官方主页上写道：“Riak TS is engineered to be faster than Cassandra”。</p>

<p>由于其非开源性，网上（包括官网）详细资料都不是特别多。</p>

<h2>19. Cyanite</h2>

<table>
<thead>
<tr>
<th> - </th>
<th> - </th>
<th> - </th>
</tr>
</thead>
<tbody>
<tr>
<td> 主页 </td>
<td> <a href="http://cyanite.io/">http://cyanite.io/</a> </td>
<td>  </td>
</tr>
<tr>
<td> 编写语言 </td>
<td> Clojure </td>
<td>  </td>
</tr>
<tr>
<td> License </td>
<td> MIT </td>
<td>  </td>
</tr>
<tr>
<td> 项目创建时间 </td>
<td> 2013年 </td>
<td>  </td>
</tr>
<tr>
<td> 最新版 </td>
<td> </td>
<td> 还没有正式release </td>
</tr>
<tr>
<td> 活跃度 </td>
<td> 活跃 </td>
<td>  </td>
</tr>
<tr>
<td> 文档 </td>
<td> 详细 </td>
<td>  </td>
</tr>
</tbody>
</table>


<p>Cyanite是一个用于接收和存储时序列数据的守护进程，它的设计目标是兼容Graphite生态系统。</p>

<p>Cyanite默认使用Apache Cassandra来存储时序列数据，它的特点如下：</p>

<ul>
<li>可扩展性</li>
</ul>


<p>基于Cassandra，Cyanite可以实现高可用、具有弹性，以及低延迟的存储。</p>

<ul>
<li>兼容性</li>
</ul>


<p>由于Graphite已经成为事实上管理时序列数据的标准，不管是使用graphite-web还是Grafana。Cyanite将会尽可能的保持与这些生态系统的兼容以提供简单地交互模式。</p>

<p>Cyanite是一个典型的流式处理模型，它接收数据，对数据进行标准化，然后进行输出。它的交互图如下所示：</p>

<p><img src="http://liubin.github.io/images/2016/02/tsdb-series/cyanite_architecture.png" alt="" /></p>

<p>它的工作流程如下：</p>

<ul>
<li>每条输入都会产生规范化的metrics，并添加到消息队列</li>
<li>核心引擎从队列取出数据并处理。</li>
<li>通过存储和索引组件进行时序列数据的存储和metric名的索引</li>
<li>API组件用于处理引擎和其他查询、存储模块的交互</li>
</ul>


<p>Cyanite的输入模块支持Carbon（Graphite组件），而Kafka,和Pickle则还在计划中。</p>

<p>索引（Index）模块则用于对metric名进行索引和查询。这一模块有两种实现方式：</p>

<ul>
<li>memory用于在内存中存储反向索引</li>
<li>elasticsearch用于在elasticsearch中存储metric名（path-names）</li>
</ul>


<p>一句话总结：新生事物、值得关注。</p>

<h2>20. 总结</h2>

<p>这里只是简单的罗列了一些项目，及其简单说明。</p>

<p>在后续的文章中，我们还会选择一些常见的TSDB进行实例讲解。</p>

<h2>相关阅读</h2>

<p>这是本系列文章的其他部分：</p>

<ul>
<li><a href="http://liubin.github.io/blog/2016/02/18/tsdb-intro/">时序列数据库武斗大会之什么是TSDB</a></li>
<li><a href="http://liubin.github.io/blog/2016/02/25/tsdb-list-part-1/">时序列数据库武斗大会之TSDB名录 Part 1</a></li>
<li>时序列数据库武斗大会之TSDB名录 Part 2</li>
<li><a href="http://liubin.github.io/blog/2016/03/05/tsdb-opentsdb/">时序列数据库武斗大会之OpenTSDB篇</a></li>
<li><a href="http://liubin.github.io/blog/2016/03/12/tsdb-kairosdb/">时序列数据库武斗大会之KairosDB篇</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[2016年2月读书记录]]></title>
    <link href="http://liubin.github.io/blog/2016/02/26/2016-02-reading/"/>
    <updated>2016-02-26T22:56:54+08:00</updated>
    <id>http://liubin.github.io/blog/2016/02/26/2016-02-reading</id>
    <content type="html"><![CDATA[<p>2月看的书，基本都是在前15天完成的，其中过年几天回老家，无事可干，在微信读书上看完了《蒋经国传》、《日本商业四百年1》和《我们台湾这些年》，《一百年漂泊》是纸版，大概看了3、4个晚上。</p>

<p>基本上关于台湾的书占了大多数，对台湾、国民党以及现代台湾整治社会也算有了些更深入地理解。同时也对台湾越来越有好感，希望能早些去台湾看看。当然工作签证最好了 ：-）。</p>

<p>不多说了，下面逐条记录一下。</p>

<h2>《蒋经国传》</h2>

<p><img src="http://img3.douban.com/lpic/s11328585.jpg" alt="" /></p>

<p>推荐指数：★★★★★</p>

<p>这本书从蒋经国的出生，到逝世，最后以李登辉上台结尾。</p>

<p>蒋经国生母毛氏不受蒋介石待见，当然也影响到了幼年时代的蒋经国。在革命初期，国民党还在和苏联合作，蒋经国也到苏联留学，后来国、苏关系紧张，蒋经国以类似人质的方式滞留苏联12年，还差点死在苏联。</p>

<p>回国后，其父当政，蒋经国赴江西任职，在江西禁烟、禁赌、禁娼妓，整治社会风气、促进了经济发展，貌似成绩还不错。</p>

<p>后来二战结束后，法币贬值、经济崩溃之际，又去上海改革货币，但以失败告终，最终退守台湾。</p>

<p>蒋经国在其父逝世后开始执政，加速了台湾社会和经济的发展，尤其是在政治方面的改革，开放党禁、启用新人，让更多的人参与到整治、台湾的建设，让台湾的民主进程提高到了新的阶段。这是让人佩服和羡慕的。</p>

<p>或许，民主不是蒋经国带来的，只是历史必然潮流。。。</p>

<h2>《日本商业四百年》、《日本商业四百年2：从黑暗帝国到战后崛起》</h2>

<p><img src="http://img3.douban.com/lpic/s9018203.jpg" alt="" />
<img src="http://img3.doubanio.com/lpic/s10405009.jpg" alt="" /></p>

<p>推荐指数：★★★★★</p>

<p>日本商业四百年，现在看起来至少由1、2、3册构成，第一层出版于2011年，《日本商业四百年2：从黑暗帝国到战后崛起》出版于2015年1月，相信第三本应该很快就会出来了。</p>

<p>本书主要介绍了日本四大财团三井、三菱、住友、安田的创建、发展历史，总结一下其特点主要有：</p>

<ul>
<li>儒教 + 武士精神。仁义礼智信加上勇往直前、无所畏惧。</li>
<li>政商结合。政府依靠财团的资金和对经济的促进，财团依靠政府关系获得经营权和政策支持。</li>
<li>经理人制度。创始家族持股做老大，雇佣专门大管家管理公司。</li>
<li>向西方学习。不是一味的自闭和排外，而是积极学习，真正的“师夷长技以制夷”。</li>
</ul>


<p>第2册则加入了索尼、丰田、松下这样的公司，这些公司创立之初、发展之际，也都受到了大财团在资金、人脉上的资助。此外还讲述了一些二战的事情，算是额外附送的福利，也挺有趣。</p>

<p>期待第三本，应该会详细介绍现代企业家，比如稻盛和夫。</p>

<h2>《三双鞋》</h2>

<p><img src="https://img1.doubanio.com/lpic/s4499697.jpg" alt="" /></p>

<p>推荐指数：★★★★★</p>

<p>这本书还不太好买，京东、亚马逊、当当自营都没有，找了好几个第三方才买到。</p>

<p>原书为英文版《Delivering Happiness:A Path to Profits, Passion, and Purpose》，中文版由其父翻译。</p>

<p>本书是“美捷步”（Zappos）首席执行官谢家华创造奇迹的心路历程与商业哲学的精华萃取，分享了他在商场与生活中得到的宝贵经验与教训。谢家华毕业于哈佛大学，24岁时即将其创业公司Link Exchange以2.65亿美元卖给微软。</p>

<p>谢家华在卖掉Link Exchange，创建了一个基金“青蛙风险”，投资了Zappos。后来谢家华干脆做起了Zappos的CEO，本书很大一部分都是讲其在Zappos的奋斗史：如何买房子以维持Zappos的运营，如何自建仓库来提高销售额，如何为公司继续融资等。但其根本想表达的是，他想要创建一种什么样公司文化。</p>

<h2>《一百年漂泊》</h2>

<p><img src="https://img3.doubanio.com/lpic/s28375650.jpg" alt="" /></p>

<p>推荐指数：★★★★★</p>

<p>作者杨渡根据自己的记忆，书写的家庭自传，父亲、目前，奶奶，亲族。同时，也是一部台湾战后发展史，从日殖民时代，国民党控制之后的白色恐怖、从农业到工业社会的转变，民主政治发展。</p>

<p>作者父亲生下来就已经是日本殖民时代，从小接受日语教育，所以父辈互相称呼还用日语。而作者父亲作为锅炉行业的从业人员，看的技术书也都是日语的。</p>

<p>后来日本战败，国民党退守台湾，之后的进程，都像极了现在的大陆社会，只不过中间有30年的错位。大陆的工业化、改革开放，比台湾晚了近30年，台湾发展经历过的，我们也正在经历着。</p>

<ul>
<li>工业污染。童年时代的小何已经干涸，大河里堆满了垃圾，冒着各种颜色的液体，散发着各种刺鼻的味道。</li>
<li>人心浮躁。突然有了钱，人就不知道该怎么生活了，攀比、铺张浪费。</li>
<li>充满机会。这是一个最好的时代，恐怕以后都很难出现。各行业都在坡博发展，到处都是机会，任何人努力都可以成功。</li>
<li>女性解放。女性的地位越来越高，为家庭、为男人的事业付出的代价和发挥的作用都不可小觑。</li>
<li>故乡纽带。家庭、家族间，朋友间，乡里之间，都有一条纽带相连。我想这是亚洲人或者说中华民族特有的家族观念。</li>
</ul>


<p>所谓的叶落归根，每个人都在怀念童年，童年的时代不会再来，下一代理解不了上一带，对生活在60-70年代的人来说，年轻人应该很难体会什么叫“故乡”这种感觉。那时候的生活是简单的，天空蓝蓝，水里有鱼。而现在人和人的距离更近了，可以“面对面的通话”（作者父亲在看到电话后的畅想），而心和心的距离却越来越远。每个人都会怀念过去，想回到过去，记忆中的家乡就是精神的家乡，温暖地活下去的原点。</p>

<p>人生就是在漂泊，家就是漂泊的原点和终点。</p>

<h2>《我们台湾这些年》</h2>

<p><img src="http://img3.doubanio.com/lpic/s6088056.jpg" alt="" /></p>

<p>推荐指数：★★★★☆</p>

<p>这本书和上面的一本很类似，几乎就是一本个人的流水账，主要就是每年都发生了什么大事件，不管是整治、经济还是娱乐圈。</p>

<h2>《时间的朋友2015》</h2>

<p><img src="http://img3.douban.com/lpic/s28377483.jpg" alt="" /></p>

<p>推荐指数：★★★★☆</p>

<p>这是罗振宇2015跨年演讲，回顾了一下2015年，包括风险投资和资本寒冬、O2O合并大战、微信VS支付宝、华为VS小米、IP等热门现象，还分析了暴风影音和乐视两只妖股。推荐看一下。</p>

<p>一些文中摘录，值得体味一下：</p>

<ul>
<li>马克思曾说，人的本质就是社会关系的总和。</li>
<li>《乔布斯传》的作者艾萨克森说：“贝佐斯试图依靠增长速度，而不是利润来建构一个公司。这听起来有些不可思议。但这种理念无论是好是坏，无疑都已经改变了1999年之后的整个经济模式。”</li>
<li>我们这一代创业者，面对两个时代性的机会：一个是互联网科技大爆发，一个是中国中产阶级的崛起。</li>
<li>黄韬的说法，和马云的说法一样——未来阿里的本质，是一家大数据公司</li>
</ul>


<p>三月的计划是看完几本和京都相关的书，不过三月的话有一些比较重要且耗费时间的工作投入较大，可能会影响阅读的数量。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[时序列数据库武斗大会之TSDB名录 Part 1]]></title>
    <link href="http://liubin.github.io/blog/2016/02/25/tsdb-list-part-1/"/>
    <updated>2016-02-25T22:21:21+08:00</updated>
    <id>http://liubin.github.io/blog/2016/02/25/tsdb-list-part-1</id>
    <content type="html"><![CDATA[<p>通过上一章<a href="http://liubin.github.io/blog/2016/02/18/tsdb-intro/">《时序列数据库武斗大会之什么是TSDB》</a>的介绍，相信大家已经知道了什么是时序列数据库，以及它能干什么，有什么特点等有了一定的了解。</p>

<p>那么在这一篇文章中，我们将介绍一下目前都有哪些TSDB，以及它们的特点，并基于个人观点，给出一定的（喜好）评判。</p>

<p>由于个人能力所限，有些地方调查可能不到位，再加上一定的个人主观因素，所以跟其他人的结论可能不一样，不过这应该也正常。没有调查就没有发言权，只有真正的深度用户的发言，才具有说服务力，你可以权当这里就当是我抛砖了。</p>

<p>虽然也有人用ElasticSearch或者MongoDB来存储时序列数据，作为更适合分类为NOSQL的这两个数据库软件，我们这里就不对它们做介绍了。</p>

<h2>DB-Engines中时序列数据库排名</h2>

<p>我们先来看一下DB-Engines中关于时<a href="http://db-engines.com/en/ranking/time+series+dbms">序列数据库的排名</a></p>

<p>这是当前（2016年2月的）排名情况：</p>

<p><img src="http://liubin.github.io/images/2016/02/tsdb-series/tsdb-ranking.png" alt="" /></p>

<p>下面，我们就按照这个排名的顺序，简单介绍一下这些时序列数据库中的一些。下面要介绍的TSDB以开源的为主，如果是商业或者SaaS服务，也简单介绍一下其特点，让大家能对其他领域的事物也有所了解。</p>

<p>这里有一个例外，就是Pinot并不在这个排名里，但是我们也把它列在了这里。</p>

<h2>1. InfluxDB</h2>

<table>
<thead>
<tr>
<th> - </th>
<th> - </th>
<th> 备注 </th>
</tr>
</thead>
<tbody>
<tr>
<td> 主页 </td>
<td> <a href="https://influxdata.com/">https://influxdata.com/</a> </td>
<td>  </td>
</tr>
<tr>
<td> 编写语言 </td>
<td> Golang </td>
<td>  </td>
</tr>
<tr>
<td> License </td>
<td> MIT </td>
<td>  </td>
</tr>
<tr>
<td> 项目创建时间 </td>
<td> 2013 </td>
<td>  </td>
</tr>
<tr>
<td> 最新版 </td>
<td> v0.10.1 </td>
<td> 2016/2/18 </td>
</tr>
<tr>
<td> 活跃度 </td>
<td> 活跃 </td>
<td>  </td>
</tr>
<tr>
<td> 文档 </td>
<td> 详细 </td>
<td>  </td>
</tr>
</tbody>
</table>


<p>InfluxDB由Golang语言编写，也是由Golang编写的软件中比较著名的一个，在很多Golang的沙龙或者文章中可能都会把InfluxDB当标杆来介绍，这也间接帮助InfluxDB提高了知名度。</p>

<p>InfluxDB的主要特点包括下面这些：</p>

<ul>
<li>schemaless(无结构)，可以是任意数量的列</li>
<li>可扩展（集群）</li>
<li>方便、强大的查询语言</li>
<li>Native HTTP API</li>
<li>集成了数据采集、存储、可视化功能</li>
<li>实时数据Downsampling</li>
<li>高效存储，使用高压缩比算法，支持retention polices</li>
</ul>


<p>InfluxDB是TSDB中为数不多的进行了用户和角色方面实现的，提供了Cluster Admin、Database Admin和Database User三种角色。</p>

<p>InfluxDB的数据采集系统也支持多种协议和插件：</p>

<ul>
<li>行文本</li>
<li>UDP</li>
<li>Graphite</li>
<li>CollectD</li>
<li>OpenTSDB</li>
</ul>


<p>不过InfluxDB每次变动都较大，尤其是在存储和集群方面，追求平平安过日子，不想瞎折腾的可以考虑下。</p>

<p><strong>注意：</strong></p>

<p>由于InfluxDB开发太活跃了，很可能你在网上搜到的资料都是老的，会害到你，所以你需要<strong>以官方文档为主</strong>。</p>

<p>一句话总结：欣欣向荣、值得一试。</p>

<h2>2. RRDtool</h2>

<table>
<thead>
<tr>
<th> - </th>
<th> - </th>
<th> 备注 </th>
</tr>
</thead>
<tbody>
<tr>
<td> 主页 </td>
<td> <a href="http://oss.oetiker.ch/rrdtool/index.en.html">http://oss.oetiker.ch/rrdtool/index.en.html</a> </td>
<td>  </td>
</tr>
<tr>
<td> 编写语言 </td>
<td> C语言 </td>
<td>  </td>
</tr>
<tr>
<td> License </td>
<td> GNU GPL V2 </td>
<td>  or later </td>
</tr>
<tr>
<td> 项目创建时间 </td>
<td> 16-Jul-1999 </td>
<td> rrdtool-1.0.0 </td>
</tr>
<tr>
<td> 最新版 </td>
<td> rrdtool-1.5.5 </td>
<td> 10-Nov-2015 </td>
</tr>
<tr>
<td> 活跃度 </td>
<td> 活跃 </td>
<td>  </td>
</tr>
<tr>
<td> 文档 </td>
<td> 详细 </td>
<td>  </td>
</tr>
</tbody>
</table>


<p>RRDtool全称为<strong>Round Robin Database Tool</strong>，也就是用于操作RRD的工具，简单明了的软件名。</p>

<p>什么是RRD呢？简单来说它就是一个循环使用的固定大小的数据库文件（其实也不太像典型的数据库）。</p>

<p>大体来说，RRDtool提供的主要工具如下：</p>

<ul>
<li>创建RRD（rrdtool create）</li>
<li>更新RRD（rrdtool update）</li>
<li>画图（rrdtool graph）</li>
</ul>


<p>这其中，画图功能是最复杂也是最强大的，甚至支持下面这些图形，这是其他TSDB中少见的：</p>

<ul>
<li>指标比较，对两个指标值进行计算，描画出满足条件的区域</li>
<li>移动平均线</li>
<li>和历史数据进行对比</li>
<li>基于最小二乘法的线性预测</li>
<li>曲线预测</li>
</ul>


<p>总之，它的画图功能太丰富了。</p>

<p>一句话总结：老牌经典、艺多不压身。</p>

<h2>3. Graphite</h2>

<table>
<thead>
<tr>
<th> - </th>
<th> - </th>
<th> 备注 </th>
</tr>
</thead>
<tbody>
<tr>
<td> 主页 </td>
<td> <a href="http://graphite.readthedocs.org/en/latest/">http://graphite.readthedocs.org/en/latest/</a> </td>
<td> </td>
</tr>
<tr>
<td> 编写语言 </td>
<td> Python </td>
<td> </td>
</tr>
<tr>
<td> License </td>
<td> Apache 2.0</td>
<td> </td>
</tr>
<tr>
<td> 项目创建时间 </td>
<td> 2006年 </td>
<td> </td>
</tr>
<tr>
<td> 最新版 </td>
<td> 0.9.10</td>
<td> 2012/5/31 </td>
</tr>
<tr>
<td> 活跃度 </td>
<td> 活跃 </td>
<td>  </td>
</tr>
<tr>
<td> 文档 </td>
<td> 详细 </td>
<td>  </td>
</tr>
</tbody>
</table>


<p>Graphite由Orbitz, LLC 的 Chris Davis创立于2006年，它主要有两个功能：</p>

<ul>
<li>存储数值型时序列数据</li>
<li>根据请求对数据进行可视化（画图）</li>
</ul>


<p>相应的，它的特点为：</p>

<ul>
<li>分布式时序列数据存储，容易扩展</li>
<li>功能强大的画图Web API，提供了大量的函数和输出方式</li>
</ul>


<p>Graphite本身不带数据采集功能，但是你可以选择很多第三方插件，比如适用于collectd、Ganglia或Sensu的插件等。同时，Graphite也支持Plaintext、Pickle和AMQP这些数据输入方式。</p>

<p>Graphite主要由三个模块组成：</p>

<ul>
<li>whisper：创建、更新RRD文件</li>
<li>carbon：以守护进程的形式运行，接收数据写入请求

<ul>
<li>carbon-cache：数据存储</li>
<li>carbon-relay：分区和复制，位于carbon-cache之前，类似carbon-cache的负载均衡</li>
<li>carbon-aggregator：数据集计，用于减轻carbon-cache的负载</li>
</ul>
</li>
<li>graphite-web：用于读取、展示数据的Web应用</li>
</ul>


<p>whisper使用了类似RRDtool的RRD文件格式，它也不像C/S结构的软件一样，没有服务进程，只是作为Python library使用，提供对数据的create/update/fetch操作。</p>

<p>如果你对它的性能比较在意，这里有一份<a href="https://answers.launchpad.net/graphite/+question/178969">老的数据</a>可供参考。</p>

<p>Google、<a href="https://codeascraft.com/2010/12/08/track-every-release/">Etsy</a>、GitHub、豆瓣、Instagram、<a href="http://blog.evernote.com/tech/2013/07/29/graphite-at-evernote/">Evernote</a>和Uber等很多知名公司都是Graphite的<a href="https://graphite.readthedocs.org/en/latest/who-is-using.html">用户</a>。有此背景，其可信度又加一层，而且网上的资料也相当的多，值得评估一下。</p>

<p>一句话总结：群众基础好、可以参考。</p>

<h2>4. OpenTSDB</h2>

<table>
<thead>
<tr>
<th> - </th>
<th> - </th>
<th> 备注 </th>
</tr>
</thead>
<tbody>
<tr>
<td> 主页 </td>
<td> <a href="http://opentsdb.net/">http://opentsdb.net/</a> </td>
<td>  </td>
</tr>
<tr>
<td> 编写语言 </td>
<td> Java </td>
<td>  </td>
</tr>
<tr>
<td> License </td>
<td> LGPLv2.1+ GPLv3+ </td>
<td>  </td>
</tr>
<tr>
<td> 项目创建时间 </td>
<td> 2010 </td>
<td>  </td>
</tr>
<tr>
<td> 最新版 </td>
<td> 2.2 </td>
<td>  </td>
</tr>
<tr>
<td> 活跃度 </td>
<td> 活跃 </td>
<td>  </td>
</tr>
<tr>
<td> 文档 </td>
<td> 详细 </td>
<td>  </td>
</tr>
</tbody>
</table>


<p>OpenTSDB是一个分布式、可伸缩的时间序列数据库。它支持豪秒级数据采集所有metrics，支持永久存储（不需要downsampling），和InfluxDB类似，它也是无模式，以tag来实现维度的概念。</p>

<p>比如，这就是它的一个metric例子：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>mysql.bytes_received 1287333217 66666666 schema=foo host=db1</span></code></pre></td></tr></table></div></figure>


<p>OpenTSDB的节点称为TSD（Time Series Daemon (TSD)），它没有主、从之分，消除了单点隐患，非常容易扩展。它主要以HBase作为存储系统，现在也增加了对Cassandra和Bigtable（非云端）。</p>

<p>OpenTSDB以数据存储和查询为主，附带了一个简单地图形界面（依赖Gnuplot），共开发、调试使用。</p>

<p>一句话总结：好用，我们在用。</p>

<h2>5. KDB+</h2>

<table>
<thead>
<tr>
<th> - </th>
<th> - </th>
<th> 备注 </th>
</tr>
</thead>
<tbody>
<tr>
<td> 主页 </td>
<td> <a href="http://kx.com/">http://kx.com/</a> </td>
<td>  </td>
</tr>
<tr>
<td> License </td>
<td> 商业 </td>
<td>  </td>
</tr>
</tbody>
</table>


<p>所有TSDB中，估计就数这个最酷了，我说的是域名，只有两个字母，猥琐地想一下，域名就值很多钱 ：-）。</p>

<p><code>kdb+</code>是一个面向列的时序列数据库，以及专门为其设计的查询语言<code>q</code>（和他们的域名一样简短）。Kdb+混合使用了流、内存和实时分析，速度很快，支持分析10亿级别的记录以及快速访问TB级别的历史数据。</p>

<p>不过这是一个商业产品，但是也提供了免费版本（貌似还限制在32位）。</p>

<h2>6. KairosDB</h2>

<table>
<thead>
<tr>
<th> - </th>
<th> - </th>
<th> 备注 </th>
</tr>
</thead>
<tbody>
<tr>
<td> 主页 </td>
<td> <a href="http://kairosdb.github.io/">http://kairosdb.github.io/</a> </td>
<td>  </td>
</tr>
<tr>
<td> 编写语言 </td>
<td> Java </td>
<td>  </td>
</tr>
<tr>
<td> License </td>
<td> Apache License 2.0 </td>
<td>  </td>
</tr>
<tr>
<td> 项目创建时间 </td>
<td> 2013 </td>
<td>  </td>
</tr>
<tr>
<td> 最新版 </td>
<td> 1.1.1 </td>
<td> 2015/12/08 </td>
</tr>
<tr>
<td> 活跃度 </td>
<td> 活跃 </td>
<td>  </td>
</tr>
<tr>
<td> 文档 </td>
<td> 详细 </td>
<td>  </td>
</tr>
</tbody>
</table>


<p>KairosDB是一个OpenTSDB的fork，不过是基于Cassandra存储的。由于Cassandra的行比HBase宽，所以KairosDB的Cassandra的默认行大小为3星期，而OpenTSDB的HBase则为1小时。</p>

<p>KairosDB支持通过Telnet、Rest、Graphite等协议写入数据，你也可以通过编写插件自己实现数据写入。</p>

<p>KairosDB也提供了基于Web API的查询接口，支持数据聚合、持过滤和分组等功能。</p>

<p>同时KairosDB提供了一个供开发用的Web UI，图形绘制引擎使用了 <a href="http://www.flotcharts.org/">Flot</a>。</p>

<p>和OpenTSDB类似，KairosDB 也提供了插件机制，你可以使用插件完成如下工作：</p>

<ul>
<li>添加数据点（data point）监听器</li>
<li>添加新的数据存储服务</li>
<li>添加新的协议处理程序</li>
<li>添加自定义系统监视服务</li>
</ul>


<h2>7. Druid</h2>

<table>
<thead>
<tr>
<th> - </th>
<th> - </th>
<th> 备注 </th>
</tr>
</thead>
<tbody>
<tr>
<td> 主页 </td>
<td> <a href="http://druid.io/">http://druid.io/</a> </td>
<td>  </td>
</tr>
<tr>
<td> 编写语言 </td>
<td> Java </td>
<td>  </td>
</tr>
<tr>
<td> License </td>
<td> Apache License 2.0 </td>
<td>  </td>
</tr>
<tr>
<td> 项目创建时间 </td>
<td> 2011 </td>
<td>  </td>
</tr>
<tr>
<td> 最新版 </td>
<td> Druid 0.9.0-RC2 </td>
<td> 2016/02/23 </td>
</tr>
<tr>
<td> 活跃度 </td>
<td> 活跃 </td>
<td>  </td>
</tr>
<tr>
<td> 文档 </td>
<td> 详细 </td>
<td>  </td>
</tr>
</tbody>
</table>


<p>Druid是一个快速、近实时的海量数据OLAP系统，并且是开源的。Druid诞生于Metamarkets，后来一些核心人员创立了IMPLY公司，进行Druid相关的产品开发。</p>

<p>Druid会按时间来进行分区（segment），并且是面向列存储的。它的主要特性如下：</p>

<ul>
<li>支持嵌套数据的列式存储</li>
<li>层级查询</li>
<li>二级索引</li>
<li>实时数据摄取</li>
<li>分布式容错架构</li>
</ul>


<p>根据去年底druid.io的白皮书，现在生产环境下最大的集群规模如下：</p>

<ul>
<li>>3M EVENTS / SECOND SUSTAINED (200B+ EVENTS/DAY)</li>
<li>10 – 100K EVENTS / SECOND / CORE</li>
<li>>500TB OF SEGMENTS (>50 TRILLION RAW EVENTS)</li>
<li>>5000 CORES (>400 NODES, >100TB RAM)</li>
<li>QUERY LATENCY (500MS AVERAGE)</li>
<li>90% &lt; 1S 95% &lt; 2S 99% &lt; 10S</li>
<li>3+ trillion events/month</li>
<li>3M+ events/sec through Druid&rsquo;s real-time ingestion</li>
<li>100+ PB of raw data</li>
<li>50+ trillion events</li>
</ul>


<p> Druid企业用户比较多，比如<a href="http://www.oneapm.com/">OneAPM</a>、Netflix和Paypal等。具体可以参考 <a href="http://druid.io/druid-powered.html">http://druid.io/druid-powered.html</a> 。</p>

<p>Druid架构比较复杂，因此对部署和运维也有一定的负担，比如需要的机器多、机器配置要高（尤其是内存）。</p>

<p>一句话总结：好用，我们在用。</p>

<h2>8. Prometheus</h2>

<table>
<thead>
<tr>
<th> - </th>
<th> - </th>
<th> 备注 </th>
</tr>
</thead>
<tbody>
<tr>
<td> 主页 </td>
<td> <a href="http://prometheus.io/">http://prometheus.io/</a> </td>
<td>  </td>
</tr>
<tr>
<td> 编写语言 </td>
<td> Golang </td>
<td>  </td>
</tr>
<tr>
<td> License </td>
<td> Apache License 2.0 </td>
<td>  </td>
</tr>
<tr>
<td> 项目创建时间 </td>
<td> 2012 </td>
<td>  </td>
</tr>
<tr>
<td> 最新版 </td>
<td> 0.17.0rc2 </td>
<td> 2016-02-05 </td>
</tr>
<tr>
<td> 活跃度 </td>
<td> 活跃 </td>
<td>  </td>
</tr>
<tr>
<td> 文档 </td>
<td> 详细 </td>
<td>  </td>
</tr>
</tbody>
</table>


<p>Prometheus是一个开源的服务监控系统和时序列数据库，由社交音乐平台SoundCloud在2012年开发，最近也变得很流行，最新版本为0.17.0rc2。</p>

<p>Prometheus从各种输入源采集metric，进行计算后显示结果，或者根据指定条件出发报警。</p>

<p>和其他监控系统相比，Prometheus的特点包括：</p>

<ul>
<li>多维数据模型（时序列数据由metric名和一组key/value组成）</li>
<li>灵活的查询语言</li>
<li>不依赖分布式存储，单台服务器即可工作</li>
<li>通过基于HTTP的pull方式采集是序列数据</li>
<li>可以通过中间网关进行时序列数据推送</li>
<li>多种可视化和仪表盘支持</li>
</ul>


<p>由于Prometheus采用了类似OpenTSDB 和 InfluxDB的key/value维度机制，所以如果你对任一种TSDB有了解的话，学习起来会简单些。</p>

<p>一句话总结：貌似比较火，何不试一试？</p>

<h2>9. Pinot</h2>

<table>
<thead>
<tr>
<th> - </th>
<th> - </th>
<th> 备注 </th>
</tr>
</thead>
<tbody>
<tr>
<td> 主页 </td>
<td> <a href="https://github.com/linkedin/pinot/wiki">https://github.com/linkedin/pinot/wiki</a> </td>
<td>  </td>
</tr>
<tr>
<td> 编写语言 </td>
<td> Java </td>
<td>  </td>
</tr>
<tr>
<td> License </td>
<td> Apache License 2.0 </td>
<td>  </td>
</tr>
<tr>
<td> 项目创建时间 </td>
<td> 2014/08 </td>
<td>  </td>
</tr>
<tr>
<td> 最新版 </td>
<td> 0.016 </td>
<td>  </td>
</tr>
<tr>
<td> 活跃度 </td>
<td> 活跃 </td>
<td>  </td>
</tr>
<tr>
<td> 文档 </td>
<td> 详细 </td>
<td>  </td>
</tr>
</tbody>
</table>


<p>Pinot是一个开源的实时、分布式OLAP数据存储方案。它来自Linkedin，虽然Linkedin最近估价表现很差，但是他们创建的各种软件、中间件实在太多了。这一点我们做软件的都应该向Linkedin表示感谢。</p>

<p>Pinot就像是一个Druid的copy，不过两者的灵感都来源于SenseiDB（Sensei在日语里为老师的意思，写成汉字为“先生”）。</p>

<p>Pinot也像Druid一样，能加载offline数据（Hadoop文件）和实时数据（Kafka）。Pinot从设计上就面向水平扩展。</p>

<p>Pinot主要特点：</p>

<ul>
<li>面向列</li>
<li>插拔式索引引擎：排序索引、位图索引和反向索引</li>
<li>根据查询语句和segment信息对查询/执行计划进行优化</li>
<li>从Kafka实时数据摄取（ingestion）</li>
<li>从Hadoop进行批量摄取</li>
<li>类似SQL的查询语言，支持聚合、过滤、分组、排序和唯一处理。</li>
<li>支持多值字段</li>
<li>水平扩展和容错</li>
</ul>


<p>Pinot的特点和Druid很像，两者可互为参考。</p>

<p>一句话总结：背靠大树好乘凉。</p>

<h2>小结</h2>

<p>这里我们为大家介绍了几种常见TSDB，如不出意外，你可能会在这里选择某一种来使用。</p>

<p>尽管如此，我们还是会为大家介绍更多一些的项目，让大家能更多的了解一些不同的TSDB及其特点，也能帮助读者深入了解TSDB的各种场景，开阔思路。</p>

<p>在下一篇文章中，我们将会为各位再介绍几种时序列数据库。</p>

<h2>相关阅读</h2>

<p>这是本系列文章的其他部分：</p>

<ul>
<li><a href="http://liubin.github.io/blog/2016/02/18/tsdb-intro/">时序列数据库武斗大会之什么是TSDB</a></li>
<li>时序列数据库武斗大会之TSDB名录 Part 1</li>
<li><a href="http://liubin.github.io/blog/2016/03/01/tsdb-list-part-2/">时序列数据库武斗大会之TSDB名录 Part 2</a></li>
<li><a href="http://liubin.github.io/blog/2016/03/05/tsdb-opentsdb/">时序列数据库武斗大会之OpenTSDB篇</a></li>
<li><a href="http://liubin.github.io/blog/2016/03/12/tsdb-kairosdb/">时序列数据库武斗大会之KairosDB篇</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[时序列数据库武斗大会之什么是TSDB]]></title>
    <link href="http://liubin.github.io/blog/2016/02/18/tsdb-intro/"/>
    <updated>2016-02-18T00:49:27+08:00</updated>
    <id>http://liubin.github.io/blog/2016/02/18/tsdb-intro</id>
    <content type="html"><![CDATA[<p>由于工作上的关系，最近看了一些关于<a href="https://en.wikipedia.org/wiki/Time_series_database">时序列数据库</a>的东西，当然，我所看的也都是以开源方案为主。</p>

<p>趁着这股热劲还没退，希望能整理一些资料出来。如果正好你也有这方面的需求，那么希望这一系列的介绍能够帮助到你。</p>

<h2>1. 什么是时序列数据库（Time series database）？</h2>

<p>一听到时序列数据库，如果只是稍有耳闻的人，可能立刻会联想到运维和监控系统。</p>

<p>没错，确实是很多运维、监控系统都采用了TSDB作为数据库系统来存储海量的、严格按时间递增的、在一定程度来说结构非常简单的各种指标（英文可能为metric、measurement或者类似的其他单词）数据。</p>

<h3>1.1. 给TSDB一个定义</h3>

<p>这是维基百科上的解释：</p>

<blockquote><p>A time series database (TSDB) is a software system that is optimized for handling time series data, arrays of numbers indexed by time (a datetime or a datetime range).</p></blockquote>

<p>翻译过来就是“时序列数据库用来存储时序列（time-series）数据并以时间（点或区间）建立索引的软件。”</p>

<p>其中，时序列数据可以定义如下：</p>

<ul>
<li>可以唯一标识的序列名/ID（比如cpu.load.1）及meta-data；</li>
<li>一组数据点{timestamp, value}。timestamp是一个Unix时间戳，一般精度会比较高，比如influxdb里面是nano秒。一般来说这个精度都会在秒以上。</li>
</ul>


<p>一般时序列数据都具备如下两个特点：</p>

<ul>
<li>数据结构简单</li>
<li>数据量大</li>
</ul>


<p>所谓的结构简单，可以理解为某一度量指标在某一时间点只会有一个值，没有复杂的结构（嵌套、层次等）和关系（关联、主外键等）。</p>

<p>数据量大则是另一个重要特点，这是由于时序列数据由所监控的大量数据源来产生、收集和发送，比如主机、IoT设备、终端或App等。</p>

<h2>2. TSDB数据库特点</h2>

<p>TSDB作为一种专为时序列数据优化而设计的数据库，在很多方面都和传统的RDBMS和NoSQL数据库不太一样，比如它不关心范式和事务。</p>

<p>其他方面TSDB的特点主要有以下几点，这里简单罗列了一下。</p>

<h3>2.1. 数据写入</h3>

<p>TSDB在数据写入方面，具有如下特点：</p>

<ul>
<li>写多于读</li>
</ul>


<p>95%-99%的操作都是写操作</p>

<ul>
<li>顺序写</li>
</ul>


<p>由于是时间序列数据，因此数据多为追加式写入，而且几乎都是实时写入，很少会写入几天前的数据。</p>

<ul>
<li>很少更新</li>
</ul>


<p>数据写入之后，不会更新</p>

<ul>
<li>区块（bulk）删除</li>
</ul>


<p>基本没有随机删除，多数是从一个时间点开始到某一时间点结束的整段数据删除。比如删除上个月，或者7天前的数据。很少出现删除单独某个指标的数据，或者跳跃时间段的数据。</p>

<p>区块删除很容易进行优化，比如可以按区块来分开存储到不同的文件，这样删除一个区块只需要删除一个文件就可以了，成本会比较低。</p>

<h3>2.2. 数据读取（查询）</h3>

<p>相对于写入操作，TSDB的读取操作特点如下：</p>

<ul>
<li>顺序读</li>
</ul>


<p>基本都是按照时间顺序读取一段时间内的数据。</p>

<ul>
<li>基数大</li>
</ul>


<p>基本数据大，超过内存大小，要选取的只是其一小部分，且没有规律，缓存几乎不起任何作用。</p>

<p>即使读取操作相对写来说较少，但是读操作的响应时间要求很高，除非你是只做后台报表生成，否则一旦有交互性操作，必须要求快速响应。</p>

<p>为了提高读取的响应时间，有两种策略。</p>

<p>一是以写性能优先，不为读取做存储优化，但是通过分布式和并发读，来提高读取的速度。</p>

<p>二就是在写入的时候就考虑到读的性能问题，将统一指标、时间段的数据写入到同一数据块中，为读取进行写入优化。</p>

<h3>2.3. 分布式（集群）</h3>

<p>TSDB应该天生就要考虑到分布式和分区等特性，将存储和查询分发到不同的服务器，以支撑大规模的数据采集和查询请求。</p>

<p>同时，它也应该是能扩展和自动失败切换（Fault-tolerant）的。随着数据量的增长，所需服务器的台数也会增加，能动态的增减服务器则是一个基本要求。同时，随着服务器的增多，各种服务器软件或者网络故障发生的概率也会增大，这时候失败切换也显得很重要，不能因为一台机器的失效而导致整个集群不可工作。</p>

<h3>2.4. 基本数据分析支持</h3>

<p>TSDB的数据是用来分析的，所以TSDB还会提供做数据分析所必须的各种运算、变换函数。比如可以方便的对时序列数据进行求和、求平均值等操作，就像传统的RDBMS一样。</p>

<h2>3. 如何去选择开源时序列数据库</h2>

<p>虽然每个人的场景不太一样，不过我觉得以下的大部分因素，都值得大家好好考量一下。除了功能上能满足、性能上撑得住，运（售）维（后）等也是我们准备长期使用所必须面临的问题。</p>

<p>我自己总结的评价因素主要有如下几点：</p>

<h3>3.1. 性能</h3>

<p>主要就是读和写的性能，在前面TSDB的特点中我们已经讲过了。</p>

<p>通过前面的说明，我们也知道TSDB 99.9%都是读少写多，因此写入性能必须能跟得上、无延时，并且不能阻塞读操作，且读操作能快速返回最新的数据。</p>

<p>还有一点必须注意的是，现在很多用户的数据都跑在云主机上，那么IOPS则是一个你必须要注意的因素，超了Plan限制的话很难找出问题原因。</p>

<h3>3.2. 存储方案（或引擎）</h3>

<p>存储方案主要会影响到读写性能、集群扩展容易程度、以及运维的复杂度。典型的存储方案有HDFS、HBase、Cassandra、LevelDB等。</p>

<h3>3.3. 集群功能</h3>

<p>一般来说，集群主要集中为存储和查询的集群功能，也代表其可扩展性，因为时序列数据库的数据量很可能很大，并且增长趋势不可预测，尤其是随着大数据和物联网的兴起，GB已经算入门，TB也是刚起步。</p>

<h2>3.4. API（HTTP API和Client Library）</h2>

<p>如果你需要定制，或者只是使用TSDB做存储，自己写入数据并通过查询接口进行数据展示，那么API的完善程度将是一个很重要的评判因素。</p>

<p>还好大部分TSDB都提供了HTTP API，除了简单的文本格式，有很多还支持JSON格式的输入、输出。</p>

<p>Client Library也是一个加分项，有一个好用的、你熟悉的语言的SDK包的话应该会更方便你做开发。</p>

<h3>3.5. SQL-like Query Language</h3>

<p>如果能通过类似传统SQL的<code>select mean(value) from metric where role='user' and time &gt;= xxx and time &lt;= yyy group by dc</code>来查询metric的话，是不是刚接触到TSDB的人更容易上手和理解呢？</p>

<p>可能这看起来比较酷，不过对我来说这只能算是个加分项而已。因为我们只会通过API来读写数据，而且查询模式非常固定、数量不多。</p>

<p>但是很多经常出报表的人，可能更喜欢这一特点了，因为老板、运营可能会定期或者随时找他们出统计数据。</p>

<h3>3.6. 部署体验</h3>

<p>即是否容易部署，特别是作为产品的话，很多企业级产品在安装部署或者升级所耗费的时间绝对是占了大头的。所以是否容易部署就成了一个重要的指标，比如是否能一键部署、单机部署？是否有额外依赖组件等。</p>

<p>同时，部署的容易程度也几乎等于以后运维的复杂程度。</p>

<h3>3.7. 成熟度</h3>

<p>成熟度包括软件本身的成熟度和生态系统的成熟度。</p>

<h4>3.7.1. 生态系统</h4>

<p>生态系统主要是指围绕该软件的周边工具、插件的丰富程度，以及相应的社区的活跃程度。</p>

<p>一个软件的生态系统，跟它的开放机制、插件（扩展）机制关系很大，直接决定第三方是否能很方便的对系统进行扩展。</p>

<h4>3.7.2. 开发活跃度</h4>

<p>这个可以从TSDB项目的提交记录（比如从GitHub上能看到开发状况）、ISSUE的解决情况，Pull Request的merge情况、以及Release的频率来确认。</p>

<p>有一些TSDB项目甚至提供了ROADMAP，我们还可以通过路线图来了解该软件未来发展方向、特性支持。</p>

<h4>3.7.3. 社区包活跃度</h4>

<p>主要是文档的丰富性等，可以在Google搜索一下，看看相关的Blog是否足够多，也可以在StackOverFlow上看一下相关讨论内容。</p>

<p>最重要的评论观点就是在专业社区（比如在Ops相关讨论组或社区）中该TSDB出现的频次、大家的关注程度等。</p>

<h4>3.7.4. 应用案例</h4>

<p>是否有大规模、大公司真正的生产环境的部署案例？规模有多大，性能如何，有无问题等，都是重要考察因素。有大公司的信任背书，你在选择上也就多了份安心，少了些纠结。</p>

<p>比如，Druid就在主页列出了很多使用了Druid的公司： <a href="http://druid.io/druid-powered.html">http://druid.io/druid-powered.html</a></p>

<h3>3.8. 可视化和报警功能</h3>

<p>说到TSDB，容易联想到的两个功能就是可视化和报警。如果TSDB自带了功能强大的可视化组件和报警支持，则可能会省去很多开发的成本，更容易吸引用户。即使开发，也能方便开发过程中进行调试和验证。</p>

<p>ELK这么流行，跟其一揽子方案关系很大。除了强大的功能之外，部署简单、功能齐全是其吸引人的地方。</p>

<h3>3.9. 所采用技术栈</h3>

<p>主要是该方案采用了什么编程语言，有哪些第三方模块。比如有的用Java编写，有的用Golang；有的用HBase，有的用自己的存储方案；有的自带丰富的UI，有的则只提供了简单的调试界面。</p>

<p>技术栈为什么也是一个选型时需要考虑的因素呢，这是因为TSDB所采用的技术，会影响你们开发和运维的复杂程度，此外还会受到既有资产的影响。比如你们没有人熟悉HBase，又不熟悉Java语言，那么可能Influxdb就更适合你们了。</p>

<h3>3.10. 保留策略（Retention Policies，或自动删除、压缩）</h3>

<p>自动删除就是为数据设置TTL，过了指定的TTL则自动删除相关数据，以节省存储空间同时提高查询性能。</p>

<p>如果不删除数据，也可以对数据进行压缩，或者再采样（Resampling），比如对最近1天的数据我们可能需要精确到秒，而查询1年的数据时，我们只需要精确到天，这时候，海量的数据一年只需要365个点来存储，大大节省了存储空间。</p>

<h3>3.11. 背后主导公司</h3>

<p>有商业公司专职开发，可能是个双刃剑。</p>

<p>好处是其持续性可期，不用担心过两天项目没有人维护了，有了bug也有人会专门解决。</p>

<p>敝处就是你可能上了贼船下来需要成本较高。比如ElasticSearch，搭建起ELK比较简单，但是一涉及到具体的生产环境部署时需要考虑的权限等问题，要么自己去hack，要么就得买他们的产品，这是成本上需要考虑的。</p>

<h3>3.12. License</h3>

<p>这可能是影响最弱的一个因素了，但是如果你想拿来商业化的话，则又是一个非常重要甚至致命的因素。</p>

<h3>3.13. 多租户支持</h3>

<p>这部分需求可能会比较少，但是如果想基于TSDB为用户提供服务，比如SaaS类应用，能从物理上隔离当然是最理想的了，不过很遗憾目前好像还没有这方面的方案。要想支持多租户，只能从应用自身来设计，类似传统RDBMS那样，为每个实体加入<code>user_id=xxx</code>类似的属性。</p>

<h3>3.14. 安全性</h3>

<p>比如：权限管理、访问控制等。</p>

<p>关于安全性最基本的需求就是不要像ELK那样，暴露在公网上如果不设防火墙的话，谁都能使用，这就带来了很大的安全隐患。</p>

<p>所以说，安全上的最小实现就是支持基本的用户密码认证功能，而且是在两个层次支持，一是UI层，即管理界面或者控制面板等，另一方面就是API级别的用户认证。</p>

<h2>4. 参考文献</h2>

<ul>
<li><a href="http://www.xaprb.com/blog/2014/06/08/time-series-database-requirements/">Time-Series Database Requirements</a></li>
<li><a href="http://jmoiron.net/blog/thoughts-on-timeseries-databases">Thoughts on Time-series Databases</a></li>
<li><a href="http://db-engines.com/en/ranking/time+series+dbms">DB-Engines Ranking of Time Series DBMS(January 2016)</a></li>
</ul>


<h2>5. 相关阅读</h2>

<p>这是本系列文章的其他部分：</p>

<ul>
<li>时序列数据库武斗大会之什么是TSDB</li>
<li><a href="http://liubin.github.io/blog/2016/02/25/tsdb-list-part-1/">时序列数据库武斗大会之TSDB名录 Part 1</a></li>
<li><a href="http://liubin.github.io/blog/2016/03/01/tsdb-list-part-2/">时序列数据库武斗大会之TSDB名录 Part 2</a></li>
<li><a href="http://liubin.github.io/blog/2016/03/05/tsdb-opentsdb/">时序列数据库武斗大会之OpenTSDB篇</a></li>
<li><a href="http://liubin.github.io/blog/2016/03/12/tsdb-kairosdb/">时序列数据库武斗大会之KairosDB篇</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[2016年1月读书记录]]></title>
    <link href="http://liubin.github.io/blog/2016/02/04/2016-01-reading/"/>
    <updated>2016-02-04T14:39:42+08:00</updated>
    <id>http://liubin.github.io/blog/2016/02/04/2016-01-reading</id>
    <content type="html"><![CDATA[<p>1月份大概看了8本书，基本都是电子书，主要是微信读书搞活动，免费领的。不过现在看看，微信读书的书太少了。</p>

<h2>《孵化Twitter - 从蛮荒到IPO的狂野旅程》</h2>

<p><img src="http://img6.douban.com/lpic/s27141439.jpg" alt="" /></p>

<p>推荐指数：★★★★★</p>

<p>本书讲述的是Twitter从史前到上市一波三折的发展史，尤其是高层的斗争史。在金钱、权利面前，人的本性被剥的赤裸、直白，看完之后你会对多西和投资人们有一个新的认识：多西的小气记仇，投资人的冷血无情。</p>

<h2>《创业头条 - 16位硅谷科技新贵的成功法则》</h2>

<p><img src="http://img6.douban.com/lpic/s28106778.jpg" alt="" /></p>

<p>推荐指数：★★★★☆</p>

<p>硅谷创业者的个人故事：不同地区、不同背景、不同的人生发展道路，值得好好看看：</p>

<blockquote><p>《创业头条》一书由《福布斯》杂志编辑兰德尔•莱恩策划、编辑和整理更新，是业内第一本系统介绍新兴互联网亿万富豪及其快速成功途径的综合性图书，为读者带来关于Airbnb、Instagram、Oculus VR、Spotify、WhatsApp、Gopro、Dropbox、Box、Palantir、Snapchat、Tumblr、Houzz、Facebook、Twitter、SpaceX及特斯拉等公司创始人的深度幕后故事。</p></blockquote>

<h2>《解忧杂货店》</h2>

<p><img src="http://img6.douban.com/lpic/s27284878.jpg" alt="" /></p>

<p>推荐指数：★★★★☆</p>

<p>一部典型的基于“人之初，性本善”出发的一个作品，主线以近代和过去的时光交错，通过浪矢杂货店和丸光园，将不同年代、背景的人串起来，透露出的是人和人之间的温情与爱心。</p>

<h2>《日本最了不起的公司：永续经营的闪光之魂》</h2>

<p><img src="http://img6.douban.com/lpic/s4405433.jpg" alt="" /></p>

<p>推荐指数：★★★★☆</p>

<p>该书分两大部分，第一部分讨论公司为谁而存在，第二部分介绍了日本最了不起的五家企业。</p>

<p>第一部分，开篇作者即列出了其结论，公司需要负担对五个人的使命与责任：</p>

<ul>
<li>让员工和员工家人幸福</li>
<li>使合作伙伴（进货商等）的员工幸福</li>
<li>使顾客幸福</li>
<li>使地方社会幸福、繁荣</li>
<li>自然早就股东的幸福</li>
</ul>


<p>其中有一段寺院主持的话让人印象深刻：“所谓的幸福，一是被爱，二是受到赞美，三是对他人有所共享，四是为人所需要。这其中后三项，必须要借助工作才能享有。”</p>

<h2>《及时引爆 社交红利2.0》和《社交红利：修订升级版》</h2>

<p><img src="http://img6.douban.com/lpic/s28273010.jpg" alt="" /></p>

<p><img src="http://img6.douban.com/lpic/s27305505.jpg" alt="" /></p>

<p>推荐指数：★★★☆☆</p>

<p>说实话，徐老师写的几本书我都有点弄混了，现在回想不出来太多的东西。</p>

<h2>《零售的哲学：7-Eleven便利店创始人自述》</h2>

<p><img src="http://img6.douban.com/lpic/s27882050.jpg" alt="" /></p>

<p>推荐指数：★★★☆☆</p>

<p>如果你想经营一个便利店或者什么的，我觉得本书作用并不大。不过作为其一般论来说，却有很多观点值得学习：</p>

<ul>
<li>持续学习，满足用户需求</li>
<li>打破常规</li>
<li>主动</li>
<li>PDCA</li>
<li>打破尝试</li>
</ul>


<p>另外读完本书我才知道，原来7-11并非日本原创，而是从美国南方公司获得特许经营权，并最后发展壮大反过来收购了经验不佳的美国南方公司。</p>

<h2>《重来》</h2>

<p><img src="http://img6.douban.com/lpic/s4502451.jpg" alt="" /></p>

<p>推荐指数：★★☆☆☆</p>

<p>我只有两句话来总结：</p>

<ul>
<li>尽信书则无书</li>
<li>成功的人屁都是经验</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[一家名为久世福的商店]]></title>
    <link href="http://liubin.github.io/blog/2016/01/22/kuzefuku-shop/"/>
    <updated>2016-01-22T17:52:49+08:00</updated>
    <id>http://liubin.github.io/blog/2016/01/22/kuzefuku-shop</id>
    <content type="html"><![CDATA[<p><img src="http://liubin.github.io/images/2016/01/kuzefuku-shop/kuzefuku_logo.png" alt="" /></p>

<p>知道这个商店，也是通过一家日本设计公司的博客。打开的一瞬间，被其怀旧且温暖的风格所吸引。</p>

<p><img src="http://liubin.github.io/images/2016/01/kuzefuku-shop/kuzefuku_1.jpg" width="800"></p>

<p>不过如果只是如此，我们只需要看看图片就可以了。久世福商店主页的第一大段文字，讲的是其经商心得（对商业的理解）：</p>

<p><img src="http://liubin.github.io/images/2016/01/kuzefuku-shop/kuzefuku_kokoroe.png" alt="" /></p>

<p>翻译为中文如下：</p>

<ul>
<li>当代随一</li>
</ul>


<p>走遍世界各地，只挑选那些无与伦比的手工制造品</p>

<ul>
<li>唯一无二</li>
</ul>


<p>制作出此前世间无有，只有久世福商店才能制作的食材</p>

<ul>
<li>三位一体</li>
</ul>


<p>只挑选价格、味道和品质都最优的商品，进行能满足顾客、生成商（进货商）和社会三方的商业</p>

<p>而其价值观，则更能打动人（以下为部分摘抄）：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>久世福の心意気
</span><span class='line'>
</span><span class='line'>東に脂がのった鰯があると聞けば赴き、
</span><span class='line'>听说东边有肥厚的鰯鱼（貌似就是沙丁鱼），就赶到东边，
</span><span class='line'>
</span><span class='line'>西に甘い塩があると聞けば赴き、
</span><span class='line'>听说西边有甜的盐，就赶到西边，
</span><span class='line'>
</span><span class='line'>南に香りの高い焼酎があると聞けば赴き、
</span><span class='line'>听说南边有香醇的烧酒，就赶到南边，
</span><span class='line'>
</span><span class='line'>北に旨い昆布があると聞けば赴き、
</span><span class='line'>听说北边有美味的海带，就赶到北边，
</span><span class='line'>
</span><span class='line'>そうして久世福商店のオリジナル商品たちは生まれました。
</span><span class='line'>久世福商店自创的商品就是这样诞生的。</span></code></pre></td></tr></table></div></figure>


<p>巧的是，最近刚读完一本书，书名是《日本最了不起的公司：永续经营的闪光之魂》。</p>

<p>该书分两大部分，第一部分讨论公司为谁而存在，第二部分介绍了日本最了不起的五家企业。</p>

<p>该书的第一部分，开篇作者即列出了其结论，公司需要负担对五个人的使命与责任：</p>

<ul>
<li>让员工和员工家人幸福</li>
<li>使合作伙伴（进货商等）的员工幸福</li>
<li>使顾客幸福</li>
<li>使地方社会幸福、繁荣</li>
<li>自然早就股东的幸福</li>
</ul>


<p>其中有一段寺院主持的话让人印象深刻：“所谓的幸福，一是被爱，二是受到赞美，三是对他人有所共享，四是为人所需要。这其中后三项，必须要借助工作才能享有。”</p>

<p>“人需要通过工作而生存，而自力更生，而公司正式提供这种机会的地方，这就是企业的存在价值和社会使命。”</p>

<p>这也是原书的话，这个久世福商店的“三位一体”是一致的，不谋而合。</p>

<p>第二部分以5家公司为代表进行了介绍。光看书名，你可能觉得里面会有索尼、东芝、NEC之类的公司。</p>

<p>你想错了，这本书介绍的公司是小公司，非常没名，有做甜点的，有做假肢的，还有卖水果的。</p>

<p>这五家企业都有以下几个特点（不是全都有）：</p>

<ul>
<li>生产和人息息相关的产品</li>
<li>创造独一无二的东西</li>
<li>雇佣弱者（残疾人）</li>
<li>从员工幸福出发</li>
<li>贡献社会</li>
<li>将感情融入商品</li>
<li>……</li>
</ul>


<p>所谓的独一无二的商品，其实不是像iPhone那样生生造出来的需求，而是从很多传统行业发现的新机遇，从普通生活中挖掘出来的新需求而已。本着让他人幸福、服务社会的宗旨去做，是不是更容易创造出唯一的商品呢？</p>

<p>虽然我觉得百年企业从文化或者怀旧的角度上来说意义更大一点，但是日本这么多百年企业，虽然跟其子承父业的文化关系很大，但其经营理念绝对是值得学习的。</p>

<p>以史为镜，以彼为镜。反观我们现在企业的经营现状，欺骗客户、股东，压榨员工，破坏环境，恶意竞争，是不是有很多的东西需要反思一下？</p>

<p><img src="http://liubin.github.io/images/2016/01/kuzefuku-shop/kuzefuku_2.jpg" width="800"></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[这个程序员得有多无聊啊？]]></title>
    <link href="http://liubin.github.io/blog/2016/01/11/spaces-and-tabs/"/>
    <updated>2016-01-11T19:38:27+08:00</updated>
    <id>http://liubin.github.io/blog/2016/01/11/spaces-and-tabs</id>
    <content type="html"><![CDATA[<p>这是两个比较流行的编辑器的界面。</p>

<p><img class="center-image" src="http://liubin.github.io/images/2016/01/spaces-and-tabs/sublime.png" title="'这是sublime的'" ></p>

<p><em>这是sublime的。</em></p>

<p><img class="center-image" src="http://liubin.github.io/images/2016/01/spaces-and-tabs/eclipse.png" title="'这是eclipse的'" ></p>

<p><em>这是eclipse的。</em></p>

<p>如果你的编辑器也做了这样的设置，那么你可以继续往下看看。</p>

<p>如果在本地，我们可以通过设置编辑器，来决定如何显示空格、tab键等，带我们程序员都爱GitHub啊，怎么办？</p>

<p>这时候工作不饱满、闲得无聊、空格癖、嫌tab党的同学，决定小小的hack一下浏览器。</p>

<p>要做的东西其实很简单，就是一个Chrome插件，把GitHub里面的代码稍微格式化一下啦。</p>

<p>这就是格式化后的效果，主要会对空格和tab进行特殊处理，此外，还加入了回车的显示，不过貌似在GitHub上，回车不是问题。</p>

<p><img class="center-image" src="http://liubin.github.io/images/2016/01/spaces-and-tabs/editor-space-cover.png" title="'格式化后的效果'" ></p>

<p><em>格式化后的效果</em></p>

<p>当然，这个小插件还支持自定义特殊字符，即设置自己喜欢的tab、空格和回车，还能自定义颜色。</p>

<p><img class="center-image" src="http://liubin.github.io/images/2016/01/spaces-and-tabs/config.png" title="'配置选项'" ></p>

<p><em>配置选项</em></p>

<p>有兴趣的同学可以在GitHub上查看到<a href="https://github.com/liubin/github-source-view-plugin">很挫的源代码</a>。。。。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[读书记录 - 社交红利2.0、孵化Twitter、解忧杂货店]]></title>
    <link href="http://liubin.github.io/blog/2016/01/03/reading/"/>
    <updated>2016-01-03T20:38:21+08:00</updated>
    <id>http://liubin.github.io/blog/2016/01/03/reading</id>
    <content type="html"><![CDATA[<h1>1. 《及时引爆 社交红利2.0》</h1>

<p>本书主要分析了脸萌、围住神经猫、足迹、魔漫相机等国民级（我竟然一个都没用过！）应用爆发的过程、原因分析以及背后故事，而且辅以大量图表来解说，非常可视化、容易理解。</p>

<p>第一章主要讲社交引爆。文章有几个论点还是值得看一下的，比如“一九法则”，这可以理解为二八法则的升级版，即在社交网络中，一款快速增长的应用，在某一细分领域能占据90%的市场份额。老二以后只能望其项背吃土。</p>

<p>这也是作者总结的社交引爆四大定律，即：</p>

<ul>
<li>短定律：用户投入时间成本少；</li>
<li>新：玩法新、创意新；</li>
<li>好友定律：用户越投入，对好友影响越大；</li>
<li>快衰定律：使用时间越短，衰减速度越快。</li>
</ul>


<p>我个人总结一下很多应用火起来的原因，这些比较重要：简单上手、鼓励分享、消磨碎片时间、娱乐化。</p>

<p>第二章也涉及到了一些运营相关的内容。个人关系链和社群，是社交网络中最常见的两种形态，也就是微信中的好友和群。社群可以是兴趣爱好群、粉丝群等。社群是使产品快速发展时尝鲜而来的用户群，长期黏着、转化的最好方式之一。这里拿辣妈帮完全考志愿者组织各地年会的例子，来说明了运营社群的价值，以及如何去做运营。</p>

<p>同时，作者总结出了社群组织的四大原则：</p>

<ul>
<li>不是企业建社群，而是让用户自己来；</li>
<li>目标清晰，逐级实现，重点解决用户个体在社群中长期活跃问题；</li>
<li>个人目标清晰明了；</li>
<li>及时且正向的群体激励。大型、滞后的激励，比不上及时、细小的激励，企业主动的激励不如个人主动获得的激励。</li>
</ul>


<p>第三章作者主要讲了如何进行社交产品开发。</p>

<p>在开发模式上，作者也推崇自管理，鼓励小团队、放权模式，让产品不断试错，其中举的韩都衣舍的例子很不错，2-3人的小团队，快速推出产品、快速上市、以数据为决策基准、淘汰没有增长率的商品。</p>

<p>最后，分享一下给我留下比较深刻印象的一句话，我觉得可以为创业者带来一些灵感：“无价值的信息泛滥时，有价值的信息或服务会变得更加昂贵”。</p>

<p>不过老实说，这本书读得很慢，不是特别好理解，至少我读起来感觉条理性不强。</p>

<h1>2. 《孵化Twitter：从蛮荒到IPO的狂野旅程》</h1>

<p>如题所示，Twitter成长过程可以用一波三折、问题不断来形容，尤其是高管和投资人之间的斗争。</p>

<p>我先简单说一下大概过程。</p>

<p>开头小篇幅讲了埃文（Evan）把Blogger卖给Google，不过他受不了Google的氛围，没多久就从Google退休了。</p>

<p>接着他投资了邻居诺阿要做一款私人电台，成立Odeo公司。后来杰克多西加入Odeo（诺阿雇佣了杰克），不过这款私人电台软件很不成功，濒临倒闭之时，诺阿和杰克共通推出了Twitter这个点子，埃文也很看好这个项目。</p>

<p>不过，狗血剧情正式开始了：</p>

<ul>
<li>埃文和诺阿意见很难统一，下属也对诺阿怨声载道，甚至杰克说他和诺阿只能留一个；</li>
<li>诺阿被赶走，净身出门，Twitter变为埃文个人投资公司，给了杰克20%期权，杰克任CTO，加上比兹（Biz Stone）3个人成为联合创始人；</li>
<li>杰克管理水平被人诟病，宕机问题迟迟搞不定，CEO还下班准时去学裁缝；</li>
<li>埃文和投资人决定赶走杰克，但是比兹说如果杰克走，他也走，不得已，妥协方案是埃文当CEO，杰克保留一个董事席位，期权貌似也都没了，不过给了20w遣散费。没有彻底清理杰克，也是后来埃文出局的根本原因；</li>
<li>杰克联系了扎克伯格，但Facebook没有能给杰克提供一个合适的高管位置，杰克后来创建了移动支付公司Square；</li>
<li>埃文找来自己的好朋友迪克做COO，Twitter开始有收入；</li>
<li>Twitter方向不明，杰克抓住机会，暗地里联合一些高管、投资人（就是前面和埃文一起赶走杰克的那些人）决定赶走埃文</li>
<li>埃文退位，迪克任CEO；不久比兹也离开。</li>
</ul>


<p>故事到此结束，埃文貌似资产在20亿美元，诺阿生了个娃，不过还是个穷光蛋。</p>

<p>看完这本书，个人新认识如下：</p>

<ul>
<li>创始人技术水平一般般</li>
<li>投资人为了自己的目的不择手段；</li>
<li>杰克多西人品不行啊。</li>
</ul>


<p>作为一部“野”史，这本书挺精彩的，像悬疑小说一样，让人不停地读下去，尤其是杰克想法设法要向埃文“复仇”。</p>

<h1>3. 《解忧杂货店》</h1>

<p>简单来说，就是。。。三言两语还真不好说。</p>

<p>首先两个重要地点（建筑物）：浪矢杂货店和孤儿院丸光园。小说中的人物也都围绕着这两个建筑物，他们大都在孤儿院度过童年，都在浪矢杂货店咨询过烦恼。</p>

<p>浪矢杂货店的老板（浪矢雄治，大概1900-1979/9/13）是个穷小子，孤儿院丸光园的创始人（皆月晓子）是个富家小姐，两人本来相爱，无奈被皆月家族有钱，看不上一个普通的年轻人。两人本来相约私奔，但是并没有成功，皆月家族本来要狠狠恶打击浪矢雄治的，但是皆月晓子答应和浪矢断绝关系，以换得家里人放过浪矢。</p>

<p>浪矢后来回到了家乡，开了浪矢杂货店。皆月晓子则终身未嫁，在浪矢家乡附近，开设了孤儿院丸光园。</p>

<p>小说的展开，都围绕各主人公在这两者之间的关系来演进。</p>

<p>2012年9月12日半夜，三个小偷在抢劫了晴美（小狗公司的老板，1990年前炒股和房地产发财），逃到了浪矢杂货店躲避，然后开始了他们的解答烦恼的过程。</p>

<p>这其中，他们收到了晴美的咨询。晴美在孤儿院度过了几年，后来被亲戚收回，她一心报答亲戚的恩情，咨询是否一直做陪酒女下去。小偷三人组最后告诉了晴美发财的方法：买过票，买卖不动产，在1989年左右全抛（这时候小偷三人组收到的咨询信是几十年前的）。</p>

<p>果真，到了2012年，晴美发财了，并成了三个小偷抢劫的对象。而晴美之所以能有今天，却都是因为在2012年9约13日凌晨指点的结果。。。</p>

<p>而小偷三人组，也都曾在丸光园里成长。原文人物关系和情节比这丰富多了，每个人都有不同的家庭背景和成长经历。</p>

<p>总之，这部小说虽然算不上日系悬疑类，没有惊心动魄的大起大落，但是情节环环相扣，静静中透着爱、宽容和美好，闲暇时间推荐一读。</p>
]]></content>
  </entry>
  
</feed>
